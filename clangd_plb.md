```shell
V[13:46:31.682] <<< {"id":12,"jsonrpc":"2.0","method":"shutdown"}

I[13:46:31.682] <-- shutdown(12)
I[13:46:31.682] --> reply:shutdown(12) 0 ms
V[13:46:31.682] >>> {"id":12,"jsonrpc":"2.0","result":null}

V[13:46:31.694] <<< {"jsonrpc":"2.0","method":"exit"}

I[13:46:31.694] <-- exit
I[13:46:31.694] LSP finished, exiting with status 0
The flag `-cross-file-rename` is obsolete and ignored.
The flag `-clang-tidy-checks` is obsolete and ignored.
I[13:46:31.695] clangd version 18.1.3 (https://github.com/llvm/llvm-project c13b7485b87909fcf739f62cfa382b55407433c0)
I[13:46:31.695] Features: linux+grpc
I[13:46:31.695] PID: 105177
I[13:46:31.695] Working directory: /root/code/multi/nccl
I[13:46:31.695] argv[0]: /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/bin/clangd
I[13:46:31.695] argv[1]: --query-driver=/usr/bin/gcc,/usr/bin/g++
I[13:46:31.695] argv[2]: --log=verbose
I[13:46:31.695] argv[3]: --all-scopes-completion
I[13:46:31.695] argv[4]: --completion-style=bundled
I[13:46:31.695] argv[5]: --cross-file-rename
I[13:46:31.695] argv[6]: --header-insertion=iwyu
I[13:46:31.695] argv[7]: --header-insertion-decorators
I[13:46:31.695] argv[8]: --background-index
I[13:46:31.695] argv[9]: --clang-tidy
I[13:46:31.695] argv[10]: --clang-tidy-checks=cppcoreguidelines-*,performance-*,bugprone-*,portability-*,modernize-*,google-*
I[13:46:31.695] argv[11]: -j=64
I[13:46:31.695] argv[12]: --pch-storage=disk
I[13:46:31.695] argv[13]: --function-arg-placeholders=false
V[13:46:31.695] User config file is /root/.config/clangd/config.yaml
I[13:46:31.695] Starting LSP over stdin/stdout
V[13:46:31.696] <<< {"id":0,"jsonrpc":"2.0","method":"initialize","params":{"capabilities":{"general":{"markdown":{"parser":"marked","version":"1.1.0"},"positionEncodings":["utf-16"],"regularExpressions":{"engine":"ECMAScript","version":"ES2020"},"staleRequestSupport":{"cancel":true,"retryOnContentModified":["textDocument/semanticTokens/full","textDocument/semanticTokens/range","textDocument/semanticTokens/full/delta"]}},"notebookDocument":{"synchronization":{"dynamicRegistration":true,"executionSummarySupport":true}},"textDocument":{"callHierarchy":{"dynamicRegistration":true},"codeAction":{"codeActionLiteralSupport":{"codeActionKind":{"valueSet":["","quickfix","refactor","refactor.extract","refactor.inline","refactor.rewrite","source","source.organizeImports"]}},"dataSupport":true,"disabledSupport":true,"dynamicRegistration":true,"honorsChangeAnnotations":false,"isPreferredSupport":true,"resolveSupport":{"properties":["edit"]}},"codeLens":{"dynamicRegistration":true},"colorProvider":{"dynamicRegistration":true},"completion":{"completionItem":{"commitCharactersSupport":true,"deprecatedSupport":true,"documentationFormat":["markdown","plaintext"],"insertReplaceSupport":true,"insertTextModeSupport":{"valueSet":[1,2]},"labelDetailsSupport":true,"preselectSupport":true,"resolveSupport":{"properties":["documentation","detail","additionalTextEdits"]},"snippetSupport":true,"tagSupport":{"valueSet":[1]}},"completionItemKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]},"completionList":{"itemDefaults":["commitCharacters","editRange","insertTextFormat","insertTextMode"]},"contextSupport":true,"dynamicRegistration":true,"editsNearCursor":true,"insertTextMode":2},"declaration":{"dynamicRegistration":true,"linkSupport":true},"definition":{"dynamicRegistration":true,"linkSupport":true},"diagnostic":{"dynamicRegistration":true,"relatedDocumentSupport":false},"documentHighlight":{"dynamicRegistration":true},"documentLink":{"dynamicRegistration":true,"tooltipSupport":true},"documentSymbol":{"dynamicRegistration":true,"hierarchicalDocumentSymbolSupport":true,"labelSupport":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"tagSupport":{"valueSet":[1]}},"foldingRange":{"dynamicRegistration":true,"foldingRange":{"collapsedText":false},"foldingRangeKind":{"valueSet":["comment","imports","region"]},"lineFoldingOnly":true,"rangeLimit":5000},"formatting":{"dynamicRegistration":true},"hover":{"contentFormat":["markdown","plaintext"],"dynamicRegistration":true},"implementation":{"dynamicRegistration":true,"linkSupport":true},"inactiveRegionsCapabilities":{"inactiveRegions":true},"inlayHint":{"dynamicRegistration":true,"resolveSupport":{"properties":["tooltip","textEdits","label.tooltip","label.location","label.command"]}},"inlineValue":{"dynamicRegistration":true},"linkedEditingRange":{"dynamicRegistration":true},"onTypeFormatting":{"dynamicRegistration":true},"publishDiagnostics":{"codeDescriptionSupport":true,"dataSupport":true,"relatedInformation":true,"tagSupport":{"valueSet":[1,2]},"versionSupport":false},"rangeFormatting":{"dynamicRegistration":true},"references":{"dynamicRegistration":true},"rename":{"dynamicRegistration":true,"honorsChangeAnnotations":true,"prepareSupport":true,"prepareSupportDefaultBehavior":1},"selectionRange":{"dynamicRegistration":true},"semanticTokens":{"augmentsSyntaxTokens":true,"dynamicRegistration":true,"formats":["relative"],"multilineTokenSupport":false,"overlappingTokenSupport":false,"requests":{"full":{"delta":true},"range":true},"serverCancelSupport":true,"tokenModifiers":["declaration","definition","readonly","static","deprecated","abstract","async","modification","documentation","defaultLibrary"],"tokenTypes":["namespace","type","class","enum","interface","struct","typeParameter","parameter","variable","property","enumMember","event","function","method","macro","keyword","modifier","comment","string","number","regexp","operator","decorator"]},"signatureHelp":{"contextSupport":true,"dynamicRegistration":true,"signatureInformation":{"activeParameterSupport":true,"documentationFormat":["markdown","plaintext"],"parameterInformation":{"labelOffsetSupport":true}}},"synchronization":{"didSave":true,"dynamicRegistration":true,"willSave":true,"willSaveWaitUntil":true},"typeDefinition":{"dynamicRegistration":true,"linkSupport":true},"typeHierarchy":{"dynamicRegistration":true}},"window":{"showDocument":{"support":true},"showMessage":{"messageActionItem":{"additionalPropertiesSupport":true}},"workDoneProgress":true},"workspace":{"applyEdit":true,"codeLens":{"refreshSupport":true},"configuration":true,"diagnostics":{"refreshSupport":true},"didChangeConfiguration":{"dynamicRegistration":true},"didChangeWatchedFiles":{"dynamicRegistration":true,"relativePatternSupport":true},"executeCommand":{"dynamicRegistration":true},"fileOperations":{"didCreate":true,"didDelete":true,"didRename":true,"dynamicRegistration":true,"willCreate":true,"willDelete":true,"willRename":true},"inlayHint":{"refreshSupport":true},"inlineValue":{"refreshSupport":true},"semanticTokens":{"refreshSupport":true},"symbol":{"dynamicRegistration":true,"resolveSupport":{"properties":["location.range"]},"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"tagSupport":{"valueSet":[1]}},"workspaceEdit":{"changeAnnotationSupport":{"groupsOnLabel":true},"documentChanges":true,"failureHandling":"textOnlyTransactional","normalizesLineEndings":true,"resourceOperations":["create","rename","delete"]},"workspaceFolders":true}},"clientInfo":{"name":"Visual Studio Code","version":"1.91.1"},"initializationOptions":{"clangdFileStatus":true,"fallbackFlags":[]},"locale":"zh-cn","processId":104438,"rootPath":"/root/code/multi/nccl","rootUri":"file:///root/code/multi/nccl","trace":"off","workspaceFolders":[{"name":"nccl","uri":"file:///root/code/multi/nccl"}]}}

I[13:46:31.696] <-- initialize(0)
I[13:46:31.700] --> reply:initialize(0) 3 ms
V[13:46:31.700] >>> {"id":0,"jsonrpc":"2.0","result":{"capabilities":{"astProvider":true,"callHierarchyProvider":true,"clangdInlayHintsProvider":true,"codeActionProvider":{"codeActionKinds":["quickfix","refactor","info"]},"compilationDatabase":{"automaticReload":true},"completionProvider":{"resolveProvider":false,"triggerCharacters":[".","<",">",":","\"","/","*"]},"declarationProvider":true,"definitionProvider":true,"documentFormattingProvider":true,"documentHighlightProvider":true,"documentLinkProvider":{"resolveProvider":false},"documentOnTypeFormattingProvider":{"firstTriggerCharacter":"\n","moreTriggerCharacter":[]},"documentRangeFormattingProvider":true,"documentSymbolProvider":true,"executeCommandProvider":{"commands":["clangd.applyFix","clangd.applyTweak"]},"foldingRangeProvider":true,"hoverProvider":true,"implementationProvider":true,"inactiveRegionsProvider":true,"inlayHintProvider":true,"memoryUsageProvider":true,"referencesProvider":true,"renameProvider":{"prepareProvider":true},"selectionRangeProvider":true,"semanticTokensProvider":{"full":{"delta":true},"legend":{"tokenModifiers":["declaration","definition","deprecated","deduced","readonly","static","abstract","virtual","dependentName","defaultLibrary","usedAsMutableReference","usedAsMutablePointer","constructorOrDestructor","userDefined","functionScope","classScope","fileScope","globalScope"],"tokenTypes":["variable","variable","parameter","function","method","function","property","variable","class","interface","enum","enumMember","type","type","unknown","namespace","typeParameter","concept","type","macro","modifier","operator","bracket","label","comment"]},"range":false},"signatureHelpProvider":{"triggerCharacters":["(",")","{","}","<",">",","]},"standardTypeHierarchyProvider":true,"textDocumentSync":{"change":2,"openClose":true,"save":true},"typeDefinitionProvider":true,"typeHierarchyProvider":true,"workspaceSymbolProvider":true},"serverInfo":{"name":"clangd","version":"clangd version 18.1.3 (https://github.com/llvm/llvm-project c13b7485b87909fcf739f62cfa382b55407433c0) linux+grpc x86_64-unknown-linux-gnu"}}}

V[13:46:31.701] <<< {"jsonrpc":"2.0","method":"initialized","params":{}}

I[13:46:31.701] <-- initialized
V[13:46:31.707] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"/*************************************************************************\n * Copyright (c) 2018-2022, NVIDIA CORPORATION. All rights reserved.\n *\n * See LICENSE.txt for license information\n ************************************************************************/\n\n#include \"core.h\"\n#include \"graph.h\"\n#include \"topo.h\"\n#include \"comm.h\"\n#include \"net.h\"\n#include \"channel.h\"\n\n// Pre-compute GPU->NIC, GPU->GPU and NIC->GPU paths\n\nstruct ncclTopoNodeList {\n  struct ncclTopoNode* list[NCCL_TOPO_MAX_NODES];\n  int count;\n};\n\nstatic ncclResult_t getPath(struct ncclTopoSystem* system, struct ncclTopoNode* node, int t, int64_t id, struct ncclTopoLinkList** path) {\n  for (int i=0; i<system->nodes[t].count; i++) {\n    if (system->nodes[t].nodes[i].id == id) {\n      *path = node->paths[t]+i;\n      return ncclSuccess;\n    }\n  }\n  WARN(\"Could not find node of type %d id %lx\", t, id);\n  return ncclInternalError;\n}\n\nNCCL_PARAM(NvbDisable, \"NVB_DISABLE\", 0);\n\nstatic ncclResult_t ncclTopoSetPaths(struct ncclTopoNode* baseNode, struct ncclTopoSystem* system) {\n  if (baseNode->paths[baseNode->type] == NULL) {\n    NCCLCHECK(ncclCalloc(baseNode->paths+baseNode->type, system->nodes[baseNode->type].count));\n  }\n\n  // breadth-first search to set all paths to that node in the system\n  struct ncclTopoNodeList nodeList;\n  struct ncclTopoNodeList nextNodeList;\n  nodeList.count = 1; nodeList.list[0] = baseNode;\n  nextNodeList.count = 0;\n  struct ncclTopoLinkList* basePath;\n  NCCLCHECK(getPath(system, baseNode, baseNode->type, baseNode->id, &basePath));\n  basePath->count = 0;\n  basePath->bw = LOC_BW;\n  basePath->type = PATH_LOC;\n\n  while (nodeList.count) {\n    nextNodeList.count = 0;\n    for (int n=0; n<nodeList.count; n++) {\n      struct ncclTopoNode* node = nodeList.list[n];\n      struct ncclTopoLinkList* path;\n      NCCLCHECK(getPath(system, node, baseNode->type, baseNode->id, &path));\n      for (int l=0; l<node->nlinks; l++) {\n        struct ncclTopoLink* link = node->links+l;\n        struct ncclTopoNode* remNode = link->remNode;\n        if (remNode->paths[baseNode->type] == NULL) {\n          NCCLCHECK(ncclCalloc(remNode->paths+baseNode->type, system->nodes[baseNode->type].count));\n          for (int i=0; i<system->nodes[baseNode->type].count; i++) remNode->paths[baseNode->type][i].type = PATH_DIS;\n        }\n        struct ncclTopoLinkList* remPath;\n        NCCLCHECK(getPath(system, remNode, baseNode->type, baseNode->id, &remPath));\n        float bw = std::min(path->bw, link->bw);\n\n        // allow routing through a GPU only as 1 hop\n        if (node != baseNode && node->type == GPU &&\n            (ncclParamNvbDisable() || link->type != LINK_NVL || remNode->type != GPU || path->count > 1)) continue;\n\n        if ((remPath->bw == 0 || remPath->count > path->count) && remPath->bw < bw) {\n          // Find reverse link\n          for (int l=0; l<remNode->nlinks; l++) {\n            if (remNode->links[l].remNode == node && remNode->links[l].type == link->type) {\n              remPath->list[0] = remNode->links+l;\n              break;\n            }\n          }\n          if (remPath->list[0] == NULL) {\n            WARN(\"Failed to find reverse path from remNode %d/%lx nlinks %d to node %d/%lx\",\n                 remNode->type, remNode->id, remNode->nlinks, node->type, node->id);\n            return ncclInternalError;\n          }\n          // Copy the rest of the path\n          for (int i=0; i<path->count; i++) remPath->list[i+1] = path->list[i];\n          remPath->count = path->count + 1;\n          remPath->bw = bw;\n\n          // Start with path type = link type. PATH and LINK types are supposed to match.\n          // Don't consider LINK_NET as we only care about the NIC->GPU path.\n          int type = link->type == LINK_NET ? LINK_LOC : link->type;\n          // Differentiate between one and multiple PCI switches\n          if (node->type == PCI && remNode->type == PCI) type = PATH_PXB;\n          // Consider a path going through the CPU as PATH_PHB\n          if (link->type == LINK_PCI && (node->type == CPU || link->remNode->type == CPU)) type = PATH_PHB;\n          // Set 1 hop NVLink as NVB\n          if (node->type == GPU && path->type == PATH_NVL && type == PATH_NVL && remPath->count > 1) type = PATH_NVB;\n\n          remPath->type = std::max(path->type, type);\n\n          // Add to the list for the next iteration if not already in the list\n          int i;\n          for (i=0; i<nextNodeList.count; i++) if (nextNodeList.list[i] == remNode) break;\n          if (i == nextNodeList.count) nextNodeList.list[nextNodeList.count++] = remNode;\n        }\n      }\n    }\n    memcpy(&nodeList, &nextNodeList, sizeof(nodeList));\n  }\n  return ncclSuccess;\n}\n\nstatic void printNodePaths(struct ncclTopoSystem* system, struct ncclTopoNode* node) {\n  const int linesize = 1024;\n  char line[linesize];\n#ifdef ENABLE_TRACE\n  INFO(NCCL_GRAPH, \"Paths from %s/%lX :\", topoNodeTypeStr[node->type], node->id);\n#else\n  snprintf(line, linesize, \"%s/%lX :\", topoNodeTypeStr[node->type], node->id);\n  int offset = strlen(line);\n#endif\n  for (int t=0; t<NCCL_TOPO_NODE_TYPES; t++) {\n    if (node->paths[t] == NULL) continue;\n    for (int n = 0; n<system->nodes[t].count; n++) {\n#ifdef ENABLE_TRACE\n      line[0] = 0;\n      int offset = 0;\n      for (int i=0; i<node->paths[t][n].count; i++) {\n        struct ncclTopoLink* link = node->paths[t][n].list[i];\n        struct ncclTopoNode* remNode = link->remNode;\n        snprintf(line+offset, linesize-offset, \"--%s(%g)->%s/%lx-%lx\", topoLinkTypeStr[link->type], link->bw, topoNodeTypeStr[remNode->type], NCCL_TOPO_ID_SYSTEM_ID(remNode->id), NCCL_TOPO_ID_LOCAL_ID(remNode->id));\n        offset = strlen(line);\n      }\n      INFO(NCCL_GRAPH, \"%s (%f)\", line, node->paths[t][n].bw);\n#else\n      snprintf(line+offset, linesize-offset, \"%s/%lx-%lx (%d/%.1f/%s) \", topoNodeTypeStr[t], NCCL_TOPO_ID_SYSTEM_ID(system->nodes[t].nodes[n].id), NCCL_TOPO_ID_LOCAL_ID(system->nodes[t].nodes[n].id), node->paths[t][n].count, node->paths[t][n].bw, topoPathTypeStr[node->paths[t][n].type]);\n      offset = strlen(line);\n#endif\n    }\n  }\n#ifndef ENABLE_TRACE\n  INFO(NCCL_GRAPH, \"%s\", line);\n#endif\n}\n\nncclResult_t ncclTopoPrintPaths(struct ncclTopoSystem* system) {\n  for (int i=0; i<system->nodes[GPU].count; i++) {\n    printNodePaths(system, system->nodes[GPU].nodes+i);\n  }\n  for (int i=0; i<system->nodes[NET].count; i++) {\n    printNodePaths(system, system->nodes[NET].nodes+i);\n  }\n  return ncclSuccess;\n}\n\nstatic ncclResult_t getLocalCpu(struct ncclTopoSystem* system, int gpu, int* retCpu) {\n  // Find the closest CPU to a GPU\n  int minHops = 0;\n  int localCpu = -1;\n  struct ncclTopoLinkList* paths = system->nodes[GPU].nodes[gpu].paths[CPU];\n  for (int c=0; c<system->nodes[CPU].count; c++) {\n    int hops = paths[c].count;\n    if (minHops == 0 || hops < minHops) {\n      localCpu = c;\n      minHops = hops;\n    }\n  }\n  if (localCpu == -1) {\n    WARN(\"Error : could not find CPU close to GPU %d\", gpu);\n    return ncclInternalError;\n  }\n  *retCpu = localCpu;\n  return ncclSuccess;\n}\n\nstatic ncclResult_t addInterStep(struct ncclTopoSystem* system, int tx, int ix, int t1, int i1, int t2, int i2) {\n  struct ncclTopoNode* cpuNode = system->nodes[tx].nodes+ix;\n  struct ncclTopoNode* srcNode = system->nodes[t1].nodes+i1;\n\n  int l=0;\n  // Node 1 -> CPU\n  for (int i=0; i<srcNode->paths[tx][ix].count; i++) srcNode->paths[t2][i2].list[l++] = srcNode->paths[tx][ix].list[i];\n  // CPU -> Node 2\n  for (int i=0; i<cpuNode->paths[t2][i2].count; i++) srcNode->paths[t2][i2].list[l++] = cpuNode->paths[t2][i2].list[i];\n\n  // Update path characteristics\n  srcNode->paths[t2][i2].count = l;\n  srcNode->paths[t2][i2].type = std::max(srcNode->paths[tx][ix].type, cpuNode->paths[t2][i2].type);\n  if (tx == GPU) srcNode->paths[t2][i2].type = PATH_PXN;\n  srcNode->paths[t2][i2].bw = std::min(srcNode->paths[tx][ix].bw, cpuNode->paths[t2][i2].bw);\n  return ncclSuccess;\n}\n\n// Remove/free paths for a given type\nstatic void ncclTopoRemovePathType(struct ncclTopoSystem* system, int nodeType) {\n  for (int t=0; t<NCCL_TOPO_NODE_TYPES; t++) {\n    // Remove links _to_ the given type\n    for (int n=0; n<system->nodes[t].count; n++) {\n      struct ncclTopoNode* node = system->nodes[t].nodes+n;\n      free(node->paths[nodeType]);\n      node->paths[nodeType] = NULL;\n    }\n    // Remove links _from_ the given type\n    for (int n=0; n<system->nodes[nodeType].count; n++) {\n      struct ncclTopoNode* node = system->nodes[nodeType].nodes+n;\n      free(node->paths[t]);\n      node->paths[t] = NULL;\n    }\n  }\n}\n\nstatic const int levelsOldToNew[] = { PATH_LOC, PATH_PIX, PATH_PXB, PATH_PHB, PATH_SYS, PATH_SYS };\nncclResult_t ncclGetLevel(int* level, const char* disableEnv, const char* levelEnv) {\n  if (*level == -1) {\n    int l = -1;\n    if (disableEnv) {\n      const char* str = ncclGetEnv(disableEnv);\n      if (str) {\n        int disable = strtol(str, NULL, 0);\n        if (disable == 1) l = 0;\n      }\n    }\n    if (l == -1) {\n      const char* str = ncclGetEnv(levelEnv);\n      if (str) {\n        for (int i=0; i<=PATH_SYS; i++) {\n          if (strcmp(str, topoPathTypeStr[i]) == 0) {\n            l = i;\n            break;\n          }\n        }\n        // Old style numbering\n        // levelsOldToNew to is an array with each index corresponding to the\n        // \"old level\" int, and each value mapping to the correct value defined in topo.h\n        // maxOldLevel is a quick check to handle out of bounds (based on the length of levelsOldToNew)\n        if (l == -1 && str[0] >= '0' && str[0] <= '9') {\n          int oldLevel = strtol(str, NULL, 0);\n          const int maxOldLevel = sizeof(levelsOldToNew)/sizeof(int) - 1;\n          if (oldLevel > maxOldLevel) oldLevel = maxOldLevel;\n          l = levelsOldToNew[oldLevel];\n        }\n      }\n    }\n    if (l >= 0) INFO(NCCL_ALL, \"%s set by environment to %s\", levelEnv, topoPathTypeStr[l]);\n    *level = l >= 0 ? l : -2;\n  }\n  return ncclSuccess;\n}\n\nNCCL_PARAM(IgnoreDisabledP2p, \"IGNORE_DISABLED_P2P\", 0);\n\nint ncclTopoUserP2pLevel = -1;\nncclResult_t ncclTopoCheckP2p(struct ncclTopoSystem* system, int64_t id1, int64_t id2, int* p2p, int *read, int* intermediateRank) {\n  *p2p = 0;\n  if (read) *read = 0;\n  if (intermediateRank) *intermediateRank = -1;\n\n  // Get GPUs from topology\n  int g1, g2;\n  NCCLCHECK(ncclTopoIdToIndex(system, GPU, id1, &g1));\n  struct ncclTopoNode* gpu1 = system->nodes[GPU].nodes+g1;\n  if (ncclTopoIdToIndex(system, GPU, id2, &g2) == ncclInternalError) {\n    // GPU not found, we can't use p2p.\n    return ncclSuccess;\n  }\n\n  int intermediateIndex = -1;\n  // Set intermediate GPU rank, if routing through an intermediate GPU.\n  struct ncclTopoLinkList* path = gpu1->paths[GPU]+g2;\n  if (path->count == 2) {\n    struct ncclTopoNode* intermediateNode = path->list[0]->remNode;\n    if (intermediateNode->type == GPU) {\n      intermediateIndex = intermediateNode - system->nodes[GPU].nodes;\n      if (intermediateRank) *intermediateRank = intermediateNode->gpu.rank;\n    }\n  }\n\n  // In general, use P2P whenever we can.\n  int p2pLevel = PATH_SYS;\n\n  // User override\n  if (ncclTopoUserP2pLevel == -1)\n    NCCLCHECK(ncclGetLevel(&ncclTopoUserP2pLevel, \"NCCL_P2P_DISABLE\", \"NCCL_P2P_LEVEL\"));\n  if (ncclTopoUserP2pLevel != -2) {\n    p2pLevel = ncclTopoUserP2pLevel;\n    goto compare;\n  }\n\n  // Don't use P2P through ARM CPUs\n  int arch, vendor, model;\n  NCCLCHECK(ncclTopoCpuType(system, &arch, &vendor, &model));\n  if (arch == NCCL_TOPO_CPU_ARCH_ARM) p2pLevel = PATH_PXB;\n  if (arch == NCCL_TOPO_CPU_ARCH_X86 && vendor == NCCL_TOPO_CPU_VENDOR_INTEL) {\n    p2pLevel = PATH_PXB;\n  }\n  if (arch == NCCL_TOPO_CPU_ARCH_X86 && vendor == NCCL_TOPO_CPU_VENDOR_ZHAOXIN) {\n    p2pLevel = PATH_PXB;\n  }\n\ncompare:\n  // Compute the PCI distance and compare with the p2pLevel.\n  if (path->type <= p2pLevel) *p2p = 1;\n\n  if (*p2p == 1) {\n    // NCCL_IGNORE_DISABLED_P2P=2 is used by unit tests that don't want to\n    // validate against NVML at all since they are pretending to be on other hw.\n    if (g1 != g2 && ncclParamIgnoreDisabledP2p() != 2) {\n      int indexes[3] = {-1,-1,-1};\n      int verticeN = 0;\n      NCCLCHECK(ncclNvmlEnsureInitialized());\n\n      indexes[verticeN++] = system->nodes[GPU].nodes[g1].gpu.dev;\n      if (intermediateIndex != -1) indexes[verticeN++] = system->nodes[GPU].nodes[intermediateIndex].gpu.dev;\n      indexes[verticeN++] = system->nodes[GPU].nodes[g2].gpu.dev;\n\n      for (int i=1; i < verticeN; i++) {\n        nvmlGpuP2PStatus_t status;\n        status = ncclNvmlDevicePairs[indexes[i-1]][indexes[i-0]].p2pStatusRead;\n        bool good = status == NVML_P2P_STATUS_OK;\n        status = ncclNvmlDevicePairs[indexes[i-1]][indexes[i-0]].p2pStatusWrite;\n        good &= status == NVML_P2P_STATUS_OK;\n        if (!good) {\n          if (!ncclParamIgnoreDisabledP2p()) {\n            if (path->type <= PATH_NVB) {\n              WARN(\"P2P is disabled between NVLINK connected GPUs %d and %d. This should not be the case given their connectivity, and is probably due to a hardware issue. If you still want to proceed, you can set NCCL_IGNORE_DISABLED_P2P=1.\", indexes[i-1], indexes[i-0]);\n              return ncclUnhandledCudaError;\n            } else if (path->type < PATH_SYS) {\n              INFO(NCCL_INIT, \"P2P is disabled between connected GPUs %d and %d. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\", indexes[i-1], indexes[i-0]);\n            }\n          }\n          *p2p = 0;\n        }\n      }\n    }\n  }\n\n  if (path->type == PATH_NVL) {\n    struct ncclTopoNode* gpu2 = system->nodes[GPU].nodes+g2;\n    // Enable P2P Read for Ampere/NVLink only\n    if (read && (gpu1->gpu.cudaCompCap == gpu2->gpu.cudaCompCap) && (gpu1->gpu.cudaCompCap == 80)) *read = 1;\n  }\n\n  return ncclSuccess;\n}\n\n// MNNVL: Check whether peers are in the same fabric cluster and clique\nncclResult_t ncclTopoCheckMNNVL(struct ncclTopoSystem* system, struct ncclPeerInfo* info1, struct ncclPeerInfo* info2, int* ret) {\n  *ret = 0;\n\n  nvmlGpuFabricInfoV_t *fabricInfo1 = &info1->fabricInfo;\n  nvmlGpuFabricInfoV_t *fabricInfo2 = &info2->fabricInfo;\n  // A zero UUID means we don't have MNNVL fabric info\n  if ((((long *)&fabricInfo2->clusterUuid)[0]|((long *)fabricInfo2->clusterUuid)[1]) == 0) return ncclSuccess;\n  if ((memcmp(fabricInfo1->clusterUuid, fabricInfo2->clusterUuid, NVML_GPU_FABRIC_UUID_LEN) == 0) &&\n      (fabricInfo1->cliqueId == fabricInfo2->cliqueId)) {\n    INFO(NCCL_NET, \"MNNVL matching peer 0x%lx UUID %lx.%lx cliqueId 0x%x\",\n         info2->busId, ((long *)fabricInfo2->clusterUuid)[0], ((long *)fabricInfo2->clusterUuid)[1], fabricInfo2->cliqueId);\n    *ret = 1;\n  }\n  return ncclSuccess;\n}\n\nNCCL_PARAM(NetGdrRead, \"NET_GDR_READ\", -2);\nint ncclTopoUserGdrLevel = -1;\n\nncclResult_t ncclTopoCheckGdr(struct ncclTopoSystem* system, int64_t busId, int64_t netId, int read, int* useGdr) {\n  *useGdr = 0;\n\n  // Get GPU and NET\n  int n, g;\n  NCCLCHECK(ncclTopoIdToIndex(system, NET, netId, &n));\n  struct ncclTopoNode* net = system->nodes[NET].nodes+n;\n  NCCLCHECK(ncclTopoIdToIndex(system, GPU, busId, &g));\n  struct ncclTopoNode* gpu = system->nodes[GPU].nodes+g;\n\n  // Check that both the NIC and GPUs support it\n  if (net->net.gdrSupport == 0) return ncclSuccess;\n  if (gpu->gpu.gdrSupport == 0) return ncclSuccess;\n\n  if (read) { // For reads (sends) only enable under certain conditions\n    int gdrReadParam = ncclParamNetGdrRead();\n    if (gdrReadParam == 0) return ncclSuccess;\n    // Disable GDR Reads pre-Ampere when we have other PCI flows\n    if (gdrReadParam < 0 && gpu->gpu.cudaCompCap < 80) {\n      int nvlink = 0;\n      // Since we don't know whether there are other communicators,\n      // it's better to keep things local if we have a single GPU.\n      if (system->nodes[GPU].count == 1) nvlink = 1;\n      for (int i=0; i<system->nodes[GPU].count; i++) {\n        if (i == g) continue;\n        if (gpu->paths[GPU][i].type == PATH_NVL) {\n          nvlink = 1;\n          break;\n        }\n      }\n      if (!nvlink) return ncclSuccess;\n    }\n  }\n\n  // Check if we are close enough that it makes sense to enable GDR\n  int netGdrLevel = PATH_PXB;\n  NCCLCHECK(ncclGetLevel(&ncclTopoUserGdrLevel, NULL, \"NCCL_NET_GDR_LEVEL\"));\n  if (ncclTopoUserGdrLevel != -2) netGdrLevel = ncclTopoUserGdrLevel;\n  int distance = gpu->paths[NET][n].type;\n  if (distance == PATH_PXN) {\n    // In case of PXN, use the intermediate GPU distance instead\n    int proxyRank, g;\n    NCCLCHECK(ncclTopoGetIntermediateRank(system, gpu->gpu.rank, netId, &proxyRank));\n    NCCLCHECK(ncclTopoRankToIndex(system, proxyRank, &g));\n    struct ncclTopoNode* proxyGpu = system->nodes[GPU].nodes+g;\n    distance = proxyGpu->paths[NET][n].type;\n  }\n  if (distance > netGdrLevel) {\n    INFO(NCCL_NET,\"GPU Direct RDMA Disabled for GPU %lx / HCA %lx (distance %d > %d)\", busId, netId, distance, netGdrLevel);\n    return ncclSuccess;\n  }\n\n  *useGdr = 1;\n  INFO(NCCL_NET,\"GPU Direct RDMA Enabled for GPU %lx / HCA %lx (distance %d <= %d), read %d\", busId, netId, distance, netGdrLevel, read);\n  return ncclSuccess;\n}\n\n// Set to 0 to disable the flush on Hopper when using GDR\nNCCL_PARAM(NetForceFlush, \"NET_FORCE_FLUSH\", 0);\n\n// Determine whether we need to flush the GDR recv buffers\nncclResult_t ncclTopoNeedFlush(struct ncclTopoSystem* system, int64_t busId, int* flush) {\n  int g;\n  NCCLCHECK(ncclTopoIdToIndex(system, GPU, busId, &g));\n  struct ncclTopoNode* gpu = system->nodes[GPU].nodes+g;\n  // Flush is required on Ampere and earlier\n  *flush = gpu->gpu.cudaCompCap < 90 ? 1 : ncclParamNetForceFlush();\n  return ncclSuccess;\n}\n\nNCCL_PARAM(NetDisableIntra, \"NET_DISABLE_INTRA\", 0);\n\n// Check whether going through the network would be faster than going through P2P/SHM.\nncclResult_t ncclTopoCheckNet(struct ncclTopoSystem* system, int64_t id1, int64_t id2, int* net) {\n  if (ncclParamNetDisableIntra() == 1) {\n    *net = 0;\n    return ncclSuccess;\n  }\n  *net = 1;\n  // First check the current GPU-to-GPU speed.\n  int g1, g2;\n  if (ncclTopoIdToIndex(system, GPU, id1, &g1) != ncclSuccess ||\n      ncclTopoIdToIndex(system, GPU, id2, &g2) != ncclSuccess) {\n    return ncclSuccess;\n  }\n\n  struct ncclTopoNode* gpu1 = system->nodes[GPU].nodes+g1;\n  struct ncclTopoNode* gpu2 = system->nodes[GPU].nodes+g2;\n  float speed = gpu1->paths[GPU][g2].bw;\n\n  // Now check the speed each GPU can access the network through PXB or better\n  float netSpeed1 = 0, netSpeed2 = 0;\n  for (int n=0; n<system->nodes[NET].count; n++) {\n    struct ncclTopoLinkList* path = gpu1->paths[NET]+n;\n    if (path->type <= PATH_PXB && path->bw > netSpeed1) netSpeed1 = path->bw;\n    path = gpu2->paths[NET]+n;\n    if (path->type <= PATH_PXB && path->bw > netSpeed2) netSpeed2 = path->bw;\n  }\n\n  if (netSpeed1 > speed && netSpeed2 > speed) return ncclSuccess;\n  *net = 0;\n  return ncclSuccess;\n}\n\nncclResult_t ncclTopoGetIntermediateRank(struct ncclTopoSystem* system, int rank, int64_t netId, int* intermediateRank) {\n  // Get GPU and NET\n  int n, g;\n  NCCLCHECK(ncclTopoIdToIndex(system, NET, netId, &n));\n  NCCLCHECK(ncclTopoRankToIndex(system, rank, &g));\n  struct ncclTopoNode* gpu = system->nodes[GPU].nodes+g;\n  struct ncclTopoLinkList* path = gpu->paths[NET]+n;\n  if (path->type == PATH_PXN) {\n    struct ncclTopoNode* node;\n    int type = NVS;\n    for (int i=0; i<path->count && type == NVS; i++) {\n      node = path->list[i]->remNode;\n      type = node->type;\n    }\n    if (type != GPU) {\n      WARN(\"Could not find intermediate GPU between GPU rank %d and NIC %lx\", rank, netId);\n      return ncclInternalError;\n    }\n    *intermediateRank = node->gpu.rank;\n  } else {\n    *intermediateRank = rank;\n  }\n  return ncclSuccess;\n}\n\nNCCL_PARAM(PxnDisable, \"PXN_DISABLE\", 0);\n\n// Net v4 plugins don't have non-blocking connect/accept. We can't therefore use\n// remote proxies without risking deadlocks\nint ncclPxnDisable(struct ncclComm* comm) {\n  static int pxnDisable = -1;\n  if (pxnDisable == -1) {\n    if (comm && ncclNetVersion(comm) == 4) {\n      INFO(NCCL_INIT, \"PXN Disabled as plugin is v4\");\n      pxnDisable = 1;\n    } else {\n      pxnDisable = ncclParamPxnDisable();\n    }\n  }\n  return pxnDisable;\n}\n\nncclResult_t ncclTopoGetPxnRanks(struct ncclComm* comm, int** intermediateRanks, int* nranks) {\n  struct ncclTopoSystem* system = comm->topo;\n  *nranks = 0;\n  *intermediateRanks = NULL;\n  if (system->nodes[NET].count == 0) return ncclSuccess;\n\n  int nr = 0;\n  int* ranks = NULL;\n  for (int rank=0; rank<comm->nRanks; rank++) {\n    int64_t netId;\n    int proxyRank;\n    NCCLCHECK(ncclTopoGetNetDev(comm, comm->rank, NULL, 0, rank, &netId, NULL, &proxyRank));\n    if (proxyRank == comm->rank) continue;\n    int useGdr;\n    NCCLCHECK(ncclTopoCheckGdr(comm->topo, comm->busId, netId, 1, &useGdr));\n    if (useGdr == 0) continue;\n    int found = 0;\n    for (int r=0; r<nr; r++) {\n      if (ranks[r] == proxyRank) found = 1;\n    }\n    if (!found) {\n      NCCLCHECK(ncclRealloc(&ranks, nr, nr+1));\n      ranks[nr++] = proxyRank;\n    }\n  }\n  *nranks = nr;\n  *intermediateRanks = ranks;\n  return ncclSuccess;\n}\n\nncclResult_t ncclTopoComputePaths(struct ncclTopoSystem* system, struct ncclComm* comm) {\n  // Precompute paths between GPUs/NICs.\n\n  // Remove everything in case we're re-computing\n  for (int t=0; t<NCCL_TOPO_NODE_TYPES; t++) ncclTopoRemovePathType(system, t);\n\n  // Set direct paths to CPUs. We need them in many cases.\n  for (int c=0; c<system->nodes[CPU].count; c++) {\n    NCCLCHECK(ncclTopoSetPaths(system->nodes[CPU].nodes+c, system));\n  }\n\n  // Set direct paths to GPUs.\n  for (int g=0; g<system->nodes[GPU].count; g++) {\n    NCCLCHECK(ncclTopoSetPaths(system->nodes[GPU].nodes+g, system));\n  }\n\n  // Set direct paths to NICs.\n  for (int n=0; n<system->nodes[NET].count; n++) {\n    NCCLCHECK(ncclTopoSetPaths(system->nodes[NET].nodes+n, system));\n  }\n\n  // Set direct paths to NVSwitches.\n  for (int n=0; n<system->nodes[NVS].count; n++) {\n    NCCLCHECK(ncclTopoSetPaths(system->nodes[NVS].nodes+n, system));\n  }\n\n  // Update path for GPUs when we don't want to / can't use GPU Direct P2P\n  for (int g=0; g<system->nodes[GPU].count; g++) {\n    for (int p=0; p<system->nodes[GPU].count; p++) {\n      int p2p;\n      NCCLCHECK(ncclTopoCheckP2p(system, system->nodes[GPU].nodes[p].id, system->nodes[GPU].nodes[g].id, &p2p, NULL, NULL));\n      if (p2p == 0) {\n        // Divert all traffic through the CPU\n        int cpu;\n        NCCLCHECK(getLocalCpu(system, g, &cpu));\n        NCCLCHECK(addInterStep(system, CPU, cpu, GPU, p, GPU, g));\n      }\n    }\n\n    if (comm == NULL) continue;\n    // Remove GPUs we can't (or don't want to) communicate with through P2P or SHM\n    struct ncclPeerInfo* dstInfo = comm->peerInfo+system->nodes[GPU].nodes[g].gpu.rank;\n    for (int p=0; p<system->nodes[GPU].count; p++) {\n      if (p == g) continue;\n      struct ncclPeerInfo* srcInfo = comm->peerInfo+system->nodes[GPU].nodes[p].gpu.rank;\n      int p2p;\n      NCCLCHECK(ncclTransports[TRANSPORT_P2P]->canConnect(&p2p, system, NULL, srcInfo, dstInfo));\n      if (p2p == 0) {\n        int shm;\n        NCCLCHECK(ncclTransports[TRANSPORT_SHM]->canConnect(&shm, system, NULL, srcInfo, dstInfo));\n        if (shm == 0) {\n          // Mark this peer as inaccessible. We'll trim it later.\n          system->nodes[GPU].nodes[p].paths[GPU][g].type = PATH_NET;\n        }\n      }\n    }\n  }\n\n  // Update paths for NICs (no GPU Direct, PXN, ...)\n  for (int n=0; n<system->nodes[NET].count; n++) {\n    struct ncclTopoNode* netNode = system->nodes[NET].nodes+n;\n\n    for (int g=0; g<system->nodes[GPU].count; g++) {\n      // Check whether we can access the NIC through another NVLink-connected GPU (PXN)\n      struct ncclTopoNode* gpu = system->nodes[GPU].nodes+g;\n      if (ncclPxnDisable(comm) != 1) {\n        int localGpuIndex;\n        NCCLCHECK(ncclTopoGetLocalGpu(system, netNode->id, &localGpuIndex));\n        if (localGpuIndex != g && localGpuIndex != -1) {\n          // PXN = PCI + NVLink.\n          struct ncclTopoNode* peerNode = system->nodes[GPU].nodes+localGpuIndex;\n          // Only use PXN for NIC n if remote GPU p ...\n          if (peerNode->paths[NET][n].type <= PATH_PXB && // Is connected to the NIC through PCI\n              peerNode->paths[GPU][g].type <= PATH_NVL && // Is connected to us through NVLink\n              NCCL_TOPO_ID_SYSTEM_ID(peerNode->id) == NCCL_TOPO_ID_SYSTEM_ID(gpu->id) && // Is on the same node as us\n              (peerNode->paths[NET][n].bw > gpu->paths[NET][n].bw || // Has either higher BW to that NIC\n               gpu->paths[NET][n].type > PATH_PXB))                  // or avoids going through a CPU\n          // We can use that GPU as relay to communicate with that NIC.\n          // Only enabling it in the GPU->NIC direction for now to favor\n          // receiving locally and sending remotely (consistent with net.cc)\n          NCCLCHECK(addInterStep(system, GPU, localGpuIndex, GPU, g, NET, n));\n        }\n      }\n      if (gpu->paths[NET][n].type < PATH_PHB) {\n        // Update path when we dont want to / can't use GPU Direct RDMA.\n        int gdr;\n        NCCLCHECK(ncclTopoCheckGdr(system, system->nodes[GPU].nodes[g].id, netNode->id, 0, &gdr));\n        if (gdr == 0) {\n          // We cannot use GPU Direct RDMA, divert all traffic through the CPU local to the GPU\n          int localCpu;\n          NCCLCHECK(getLocalCpu(system, g, &localCpu));\n          NCCLCHECK(addInterStep(system, CPU, localCpu, NET, n, GPU, g));\n          NCCLCHECK(addInterStep(system, CPU, localCpu, GPU, g, NET, n));\n        }\n      }\n    }\n  }\n  return ncclSuccess;\n}\n\nncclResult_t ncclTopoTrimSystem(struct ncclTopoSystem* system, struct ncclComm* comm) {\n  int *domains;\n  int64_t *ids;\n  NCCLCHECK(ncclCalloc(&domains, system->nodes[GPU].count));\n  NCCLCHECK(ncclCalloc(&ids, system->nodes[GPU].count));\n  int myDomain = 0;\n  for (int g=0; g<system->nodes[GPU].count; g++) {\n    struct ncclTopoNode* gpu = system->nodes[GPU].nodes+g;\n    domains[g] = g;\n    ids[g] = gpu->id;\n    for (int p=0; p<g; p++) {\n      if (gpu->paths[GPU][p].type < PATH_NET) {\n        domains[g] = std::min(domains[g], domains[p]);\n      }\n    }\n    if (gpu->gpu.rank == comm->rank) myDomain = domains[g];\n  }\n\n  int ngpus = system->nodes[GPU].count;\n  for (int i=0; i<ngpus; i++) {\n    if (domains[i] == myDomain) continue;\n    struct ncclTopoNode* gpu = NULL;\n    int g;\n    for (g=0; g<system->nodes[GPU].count /* This one varies over the loops */; g++) {\n      gpu = system->nodes[GPU].nodes+g;\n      if (gpu->id == ids[i]) break; else gpu=NULL;\n    }\n    if (gpu == NULL) {\n      WARN(\"Could not find id %lx\", ids[i]);\n      free(domains);\n      free(ids);\n      return ncclInternalError;\n    }\n    NCCLCHECK(ncclTopoRemoveNode(system, GPU, g));\n  }\n\n  if (system->nodes[GPU].count == comm->nRanks) {\n    for (int n=system->nodes[NET].count-1; n>=0; n--)\n      NCCLCHECK(ncclTopoRemoveNode(system, NET, n));\n  }\n  free(domains);\n  free(ids);\n  return ncclSuccess;\n}\n\nvoid ncclTopoFree(struct ncclTopoSystem* system) {\n  for (int t=0; t<NCCL_TOPO_NODE_TYPES; t++) ncclTopoRemovePathType(system, t);\n  free(system);\n}\n\nNCCL_PARAM(NChannelsPerNetPeer, \"NCHANNELS_PER_NET_PEER\", -1);\n\nstatic ncclResult_t ncclTopoGetNchannels(struct ncclComm* comm, int g /*local gpu index*/, int peerRank, int* nChannels) {\n  int peer;\n  struct ncclTopoSystem* system = comm->topo;\n  struct ncclTopoLinkList* path = NULL;\n  if (ncclTopoRankToIndex(system, peerRank, &peer) == ncclSuccess) {\n    // Same rank\n    if (g == peer) {\n      *nChannels = -1;\n      return ncclSuccess;\n    }\n    // Local rank\n    path = system->nodes[GPU].nodes[peer].paths[GPU]+g;\n    if (path->type == PATH_NVL) {\n      float nvlBw = ncclTopoNVLinkBw(system->nodes[GPU].nodes[g].gpu.cudaCompCap);\n      *nChannels = 2*std::max(1, (int)(path->bw / nvlBw));\n    } else {\n      *nChannels = 2;\n    }\n  } else {\n    // Remote rank, use network\n    int nNetChannels = ncclParamNChannelsPerNetPeer();\n    if (nNetChannels == -1) {\n       //start from 2 channels per NIC and reduce with scale\n       nNetChannels = 2;\n\n       // check if we need to use more than one NIC, hence more than one channel\n       int netCountByBw = 1, nChannelsMax = nNetChannels;\n       NCCLCHECK(getLocalNetCountByBw(system, g, &netCountByBw));\n       // Avoid overloading channels with 8+ operations as we loose the sync warp, hence a bit of bandwidth.\n       while (nChannelsMax*comm->nRanks > comm->p2pnChannels*4 && nChannelsMax > 1) nChannelsMax /= 2;\n\n       //allow upto channels requires to drive the NICs\n       nNetChannels = std::max(netCountByBw, nChannelsMax);\n    }\n    *nChannels = nNetChannels;\n  }\n  return ncclSuccess;\n}\n\nNCCL_PARAM(MinP2pNChannels, \"MIN_P2P_NCHANNELS\", 1);\nNCCL_PARAM(MaxP2pNChannels, \"MAX_P2P_NCHANNELS\", MAXCHANNELS);\n\nstatic int nextPow2(int v) {\n  int pow2 = 1;\n  while (pow2 < v) pow2 <<= 1;\n  return pow2;\n}\n\nncclResult_t ncclTopoComputeP2pChannels(struct ncclComm* comm) {\n  /* here we already honor comm->max/minCTAs for p2pnChannels. */\n  if (comm->sharedRes->owner != comm) {\n    comm->p2pnChannels = std::min(comm->nChannels, (int)ncclParamMaxP2pNChannels());\n    comm->p2pnChannels = std::min(std::max(comm->p2pnChannels, (int)ncclParamMinP2pNChannels()), comm->sharedRes->tpP2pNChannels);\n  } else {\n    comm->p2pnChannels = std::min(comm->nChannels, (int)ncclParamMaxP2pNChannels());\n    comm->p2pnChannels = std::max(comm->p2pnChannels, (int)ncclParamMinP2pNChannels());\n  }\n\n  int minChannels = comm->p2pnChannels;\n  // We need to loop through all local GPUs to have a global picture\n  for (int g=0; g<comm->topo->nodes[GPU].count; g++) {\n    for (int r=0; r<comm->nRanks; r++) {\n      int nChannels;\n      NCCLCHECK(ncclTopoGetNchannels(comm, g, r, &nChannels));\n      if (nChannels >= 0) minChannels = std::min(minChannels, nChannels);\n    }\n  }\n\n  // Round to next pow2 nChannelsPerPeer and nChannels\n  comm->p2pnChannelsPerPeer = nextPow2(minChannels);\n  comm->p2pnChannels = nextPow2(comm->p2pnChannels);\n\n  // Init channels that weren't used so far\n  for (int c=comm->nChannels; c<comm->p2pnChannels; c++) NCCLCHECK(initChannel(comm, c));\n\n  // We want to spread channels used when there aren't many and progressively\n  // fill the whole space of nChannels. To do so we mirror the bits in the\n  // nChannels space.\n  for (int c=0; c<comm->p2pnChannels; c++) {\n    comm->p2pChannels[c] = mirrorBits(c, comm->p2pnChannels);\n  }\n  return ncclSuccess;\n}\n\nncclResult_t ncclTopoGetNvbGpus(struct ncclTopoSystem* system, int rank, int* nranks, int** ranks) {\n  int ngpus = system->nodes[GPU].count;\n  NCCLCHECK(ncclCalloc(ranks, ngpus));\n  int nvbGpus = 0;\n  for (int g=0; g<ngpus; g++) {\n    struct ncclTopoNode* gpu = system->nodes[GPU].nodes+g;\n    if (gpu->gpu.rank != rank) continue;\n    for (int p=0; p<ngpus; p++) {\n      if (gpu->paths[GPU][p].type == PATH_NVB) {\n        (*ranks)[nvbGpus++] = system->nodes[GPU].nodes[p].gpu.rank;\n      }\n    }\n  }\n  *nranks = nvbGpus;\n  return ncclSuccess;\n}\n\nint ncclTopoPathAllNVLink(struct ncclTopoSystem* system) {\n  int minPath = PATH_DIS;\n  for (int i=0; i<system->nodes[GPU].count; i++) {\n    struct ncclTopoLinkList* paths = system->nodes[GPU].nodes[i].paths[GPU];\n    for (int j=0; j<system->nodes[GPU].count; j++) {\n      if (i == j) continue;\n      minPath = std::min(minPath, paths[j].type);\n    }\n  }\n  return minPath >= PATH_PIX ? 0 : 1;\n}\n","uri":"file:///root/code/multi/nccl/src/graph/paths.cc","version":3}}}

I[13:46:31.708] <-- textDocument/didOpen
E[13:46:31.708] System include extraction: driver clang not found in PATH
V[13:46:31.708] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"/*************************************************************************\n * Copyright (c) 2015-2023, NVIDIA CORPORATION. All rights reserved.\n *\n * See LICENSE.txt for license information\n ************************************************************************/\n\n#include \"argcheck.h\" // Need some checks here since we access comm\n#include \"collectives.h\"\n#include \"enqueue.h\"\n#include \"nccl.h\"\n\nNCCL_API(ncclResult_t, ncclAllGather, const void* sendbuff, void* recvbuff, size_t sendcount,\n    ncclDataType_t datatype, ncclComm_t comm, cudaStream_t stream);\nncclResult_t ncclAllGather(const void* sendbuff, void* recvbuff, size_t sendcount,\n    ncclDataType_t datatype, ncclComm_t comm, cudaStream_t stream) {\n  // Just pass the size of one message and not the total bytes sent/received.\n  constexpr nvtxPayloadSchemaEntry_t AllGatherSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_SIZE, \"Message size [bytes]\"}\n  };\n  size_t msgsize = sendcount * ncclTypeSize(datatype);\n  NVTX3_FUNC_WITH_PARAMS(AllGather, AllGatherSchema, msgsize)\n\n  struct ncclInfo info = { ncclFuncAllGather, \"AllGather\",\n    sendbuff, recvbuff, sendcount, datatype, ncclSum, 0, comm, stream, /* Args */\n    ALLGATHER_CHUNKSTEPS, ALLGATHER_SLICESTEPS };\n  NCCLCHECK(ncclEnqueueCheck(&info));\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclAllReduce, const void* sendbuff, void* recvbuff, size_t count,\n    ncclDataType_t datatype, ncclRedOp_t op, ncclComm* comm, cudaStream_t stream);\nncclResult_t ncclAllReduce(const void* sendbuff, void* recvbuff, size_t count,\n    ncclDataType_t datatype, ncclRedOp_t op, ncclComm* comm, cudaStream_t stream) {\n  struct NvtxParamsAllReduce {\n    size_t bytes;\n    ncclRedOp_t op;\n  };\n  // Just pass the size of one message and not the total bytes sent/received.\n  static constexpr nvtxPayloadSchemaEntry_t AllReduceSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_SIZE, \"Message size [bytes]\"},\n    {0, NVTX_PAYLOAD_ENTRY_NCCL_REDOP, \"Reduction operation\", nullptr, 0,\n      offsetof(NvtxParamsAllReduce, op)}\n  };\n  NvtxParamsAllReduce payload{count * ncclTypeSize(datatype), op};\n  NVTX3_FUNC_WITH_PARAMS(AllReduce, AllReduceSchema, payload)\n\n  struct ncclInfo info = { ncclFuncAllReduce, \"AllReduce\",\n    sendbuff, recvbuff, count, datatype, op, 0, comm, stream, /* Args */\n    ALLREDUCE_CHUNKSTEPS, ALLREDUCE_SLICESTEPS };\n  NCCLCHECK(ncclEnqueueCheck(&info));\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclBroadcast, const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t datatype, int root,\n    ncclComm_t comm, cudaStream_t stream);\nncclResult_t ncclBroadcast(const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t datatype, int root,\n    ncclComm_t comm, cudaStream_t stream) {\n  struct NvtxParamsBroadcast {\n    size_t bytes;\n    int root;\n  };\n  constexpr nvtxPayloadSchemaEntry_t BroadcastSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_SIZE, \"Bytes\"},\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"Root\", nullptr, 0, offsetof(NvtxParamsBroadcast, root)}\n  };\n  NvtxParamsBroadcast payload{count * ncclTypeSize(datatype), root};\n  NVTX3_FUNC_WITH_PARAMS(Broadcast, BroadcastSchema, payload)\n\n  struct ncclInfo info = { ncclFuncBroadcast, \"Broadcast\",\n    sendbuff, recvbuff, count, datatype, ncclSum, root, comm, stream, /* Args */\n    BROADCAST_CHUNKSTEPS, BROADCAST_SLICESTEPS };\n  NCCLCHECK(ncclEnqueueCheck(&info));\n  return ncclSuccess;\n}\n/* Deprecated original \"in place\" function, similar to MPI */\nNCCL_API(ncclResult_t, ncclBcast, void* buff, size_t count, ncclDataType_t datatype, int root,\n    ncclComm_t comm, cudaStream_t stream);\nncclResult_t ncclBcast(void* buff, size_t count, ncclDataType_t datatype, int root,\n    ncclComm_t comm, cudaStream_t stream) {\n  NCCLCHECK(ncclBroadcast(buff, buff, count, datatype, root, comm, stream));\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclReduce, const void* sendbuff, void* recvbuff, size_t count,\n    ncclDataType_t datatype, ncclRedOp_t op, int root, ncclComm_t comm, cudaStream_t stream);\nncclResult_t ncclReduce(const void* sendbuff, void* recvbuff, size_t count,\n    ncclDataType_t datatype, ncclRedOp_t op, int root, ncclComm_t comm, cudaStream_t stream) {\n  struct NvtxParamsReduce {\n    size_t bytes;\n    int root;\n    ncclRedOp_t op;\n  };\n  constexpr nvtxPayloadSchemaEntry_t ReduceSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_SIZE, \"Message size [bytes]\"},\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"Root\", nullptr, 0, offsetof(NvtxParamsReduce, root)},\n    {0, NVTX_PAYLOAD_ENTRY_NCCL_REDOP, \"Reduction operation\", nullptr, 0,\n      offsetof(NvtxParamsReduce, op)}\n  };\n  NvtxParamsReduce payload{count * ncclTypeSize(datatype), root, op};\n  NVTX3_FUNC_WITH_PARAMS(Reduce, ReduceSchema, payload)\n\n  struct ncclInfo info = { ncclFuncReduce, \"Reduce\",\n    sendbuff, recvbuff, count, datatype, op, root, comm, stream, /* Args */\n    REDUCE_CHUNKSTEPS, REDUCE_SLICESTEPS };\n  NCCLCHECK(ncclEnqueueCheck(&info));\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclReduceScatter, const void* sendbuff, void* recvbuff, size_t recvcount,\n    ncclDataType_t datatype, ncclRedOp_t op, ncclComm* comm, cudaStream_t stream);\nncclResult_t ncclReduceScatter(const void* sendbuff, void* recvbuff, size_t recvcount,\n    ncclDataType_t datatype, ncclRedOp_t op, ncclComm* comm, cudaStream_t stream) {\n  struct NvtxParamsReduceScatter {\n    size_t bytes;\n    ncclRedOp_t op;\n  };\n  constexpr nvtxPayloadSchemaEntry_t ReduceScatterSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_SIZE, \"Message size [bytes]\"},\n    {0, NVTX_PAYLOAD_ENTRY_NCCL_REDOP, \"Reduction operation\", nullptr, 0,\n      offsetof(NvtxParamsReduceScatter, op)}\n  };\n  NvtxParamsReduceScatter payload{recvcount * ncclTypeSize(datatype), op};\n  NVTX3_FUNC_WITH_PARAMS(ReduceScatter, ReduceScatterSchema, payload)\n\n  struct ncclInfo info = { ncclFuncReduceScatter, \"ReduceScatter\",\n    sendbuff, recvbuff, recvcount, datatype, op, 0, comm, stream, /* Args */\n    REDUCESCATTER_CHUNKSTEPS, REDUCESCATTER_SLICESTEPS };\n  NCCLCHECK(ncclEnqueueCheck(&info));\n  return ncclSuccess;\n}\n\nstruct NvtxParamsSendRecv {\n    size_t bytes;\n    int peer;\n};\nconstexpr const nvtxPayloadSchemaEntry_t SendRecvSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_SIZE, \"Bytes\"},\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"Peer rank\", nullptr, 0, offsetof(NvtxParamsSendRecv, peer)}\n};\n\nNCCL_API(ncclResult_t, ncclSend, const void* sendbuff, size_t count, ncclDataType_t datatype, int peer,\n    ncclComm_t comm, cudaStream_t stream);\nncclResult_t ncclSend(const void* sendbuff, size_t count, ncclDataType_t datatype, int peer,\n    ncclComm_t comm, cudaStream_t stream) {\n  NvtxParamsSendRecv payload{count * ncclTypeSize(datatype), peer};\n  NVTX3_FUNC_WITH_PARAMS(Send, SendRecvSchema, payload)\n\n  struct ncclInfo info = { ncclFuncSend, \"Send\",\n    NULL, (void*)sendbuff, count, datatype, ncclSum, peer, comm, stream, /* Args */\n    1, 1 };\n  ncclResult_t ret;\n  NCCLCHECK(ncclGroupStart());\n  NCCLCHECKGOTO(ncclEnqueueCheck(&info), ret, exit);\nexit:\n  NCCLCHECK(ncclGroupEnd());\n  return ret;\n}\n\nNCCL_API(ncclResult_t, ncclRecv, void* recvbuff, size_t count, ncclDataType_t datatype, int peer,\n    ncclComm_t comm, cudaStream_t stream);\nncclResult_t ncclRecv(void* recvbuff, size_t count, ncclDataType_t datatype, int peer,\n    ncclComm_t comm, cudaStream_t stream) {\n  NvtxParamsSendRecv payload{count * ncclTypeSize(datatype), peer};\n  NVTX3_FUNC_WITH_PARAMS(Recv, SendRecvSchema, payload)\n\n  struct ncclInfo info = { ncclFuncRecv, \"Recv\",\n    NULL, recvbuff, count, datatype, ncclSum, peer, comm, stream, /* Args */\n    1, 1 };\n  ncclResult_t ret;\n  NCCLCHECK(ncclGroupStart());\n  NCCLCHECKGOTO(ncclEnqueueCheck(&info), ret, exit);\nexit:\n  NCCLCHECK(ncclGroupEnd());\n  return ret;\n}\n","uri":"file:///root/code/multi/nccl/src/collectives.cc","version":1}}}

I[13:46:31.708] <-- textDocument/didOpen
V[13:46:31.709] config note at /root/code/multi/nccl/.clangd:1:0: Parsing config fragment
V[13:46:31.709] config note at /root/code/multi/nccl/.clangd:1:0: Parsed 1 fragments from file
V[13:46:31.709] Config fragment: compiling /root/code/multi/nccl/.clangd:1 -> 0x00007F2BCC0023C0 (trusted=false)
V[13:46:31.709] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"/*************************************************************************\n * Copyright (c) 2016-2022, NVIDIA CORPORATION. All rights reserved.\n *\n * See LICENSE.txt for license information\n ************************************************************************/\n\n#ifndef NCCL_TOPO_H_\n#define NCCL_TOPO_H_\n\n#include \"graph.h\"\n#include \"core.h\"\n\n#define LOC_BW 5000.0\n#define SM60_NVLINK_BW 18.0\n#define SM70_NVLINK_BW 20.0\n#define SM80_NVLINK_BW 20.0\n#define SM90_NVLINK_BW 20.6\n#define SM86_NVLINK_BW 12.0\n#define PCI_BW 12.0           // PCI Gen3 x16\n#define QPI_BW 6.0\n#define AMD_BW 16.0\n#define SKL_QPI_BW 10.0\n#define ZPI_BW 6.0\n#define YONGFENG_ZPI_BW 9.0\n#define P9_BW 32.0\n#define ARM_BW 6.0\n#define NET_BW 12.0           // 100Gbit\n\n// Intel CPU convert GPU P2P traffic into 64B PCI TLPs, so GPU\n// to GPU traffic consumes more PCI bandwidth.\n#define INTEL_P2P_OVERHEAD(bw) (bw*6/5)\n\n#define NCCL_TOPO_NODE_TYPES 7\n#define GPU 0\n#define PCI 1\n#define NVS 2\n#define CPU 3 // Actually NUMA domains\n#define NIC 4\n#define NET 5\nextern const char* topoNodeTypeStr[];\n\n// We want link types and path types to match as much as possible\n#define LINK_LOC 0\n#define LINK_NVL 1\n// Skipping 2 for PATH_NVB\n#define LINK_PCI 3\n// Skipping 4 for PATH_PXB\n// Skipping 5 for PATH_PXN\n// Skipping 6 for PATH_PHB\n#define LINK_SYS 7\n#define LINK_NET 8\nextern const char* topoLinkTypeStr[];\n\n// Local (myself)\n#define PATH_LOC 0\n\n// Connection traversing NVLink\n#define PATH_NVL 1\n\n// Connection through NVLink using an intermediate GPU\n#define PATH_NVB 2\n\n// Connection traversing at most a single PCIe bridge\n#define PATH_PIX 3\n\n// Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n#define PATH_PXB 4\n\n// Connection between a GPU and a NIC using an intermediate GPU. Used to enable rail-local, aggregated network send/recv operations.\n#define PATH_PXN 5\n\n// Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n#define PATH_PHB 6\n\n// Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n#define PATH_SYS 7\n\n// Connection through the network\n#define PATH_NET 8\n\n// Disconnected\n#define PATH_DIS 9\nextern const char* topoPathTypeStr[];\n\nstruct ncclTopoNode;\nstruct ncclTopoLink {\n  int type;\n  float bw;\n  struct ncclTopoNode* remNode;\n};\n#define NCCL_TOPO_MAX_LINKS 128\n#define NCCL_TOPO_MAX_HOPS (NCCL_TOPO_MAX_NODES*NCCL_TOPO_NODE_TYPES)\n\nstruct ncclTopoLinkList {\n  struct ncclTopoLink* list[NCCL_TOPO_MAX_HOPS];\n  int count;\n  float bw;\n  int type;\n};\n\n#define NCCL_TOPO_CPU_INTEL_BDW 1\n#define NCCL_TOPO_CPU_INTEL_SKL 2\n\n#define NCCL_TOPO_UNDEF (-1)\n\n#define NCCL_TOPO_ID_SYSTEM_ID(id) (id >> 56)\n#define NCCL_TOPO_ID_LOCAL_ID(id) (id & 0x00ffffffffffffff)\n#define NCCL_TOPO_ID(systemid, localid) (((int64_t)systemid << 56) + localid)\n\nstruct ncclTopoNode {\n  int type;\n  int64_t id;\n  // Type specific data\n  union {\n    struct {\n      int dev; // NVML dev number\n      int rank;\n      int cudaCompCap;\n      int gdrSupport;\n    }gpu;\n    struct {\n      int dev; // Plugin dev number\n      uint64_t asic;\n      int port;\n      float bw;\n      float latency;\n      int gdrSupport;\n      int collSupport;\n      int maxChannels;\n    }net;\n    struct {\n      int arch;\n      int vendor;\n      int model;\n      cpu_set_t affinity;\n    }cpu;\n    struct {\n      uint64_t device;\n    }pci;\n  };\n  int nlinks;\n  struct ncclTopoLink links[NCCL_TOPO_MAX_LINKS];\n  // Pre-computed paths to GPUs and NICs\n  struct ncclTopoLinkList* paths[NCCL_TOPO_NODE_TYPES];\n  // Used during search\n  uint64_t used;\n};\n\nstruct ncclTopoNodeSet {\n  int count;\n  struct ncclTopoNode nodes[NCCL_TOPO_MAX_NODES];\n};\n\nstruct ncclTopoSystem {\n  int systemId;\n  uint64_t hostHashes[NCCL_TOPO_MAX_NODES];\n  int nHosts;\n  struct ncclTopoNodeSet nodes[NCCL_TOPO_NODE_TYPES];\n  float maxBw;\n  float totalBw;\n};\n\nncclResult_t ncclTopoGetNode(struct ncclTopoSystem* system, struct ncclTopoNode** node, int type, uint64_t id);\nncclResult_t ncclTopoCreateNode(struct ncclTopoSystem* system, struct ncclTopoNode** node, int type, uint64_t id);\nncclResult_t ncclTopoRemoveNode(struct ncclTopoSystem* system, int type, int id);\nncclResult_t ncclTopoConnectNodes(struct ncclTopoNode* node, struct ncclTopoNode* remNode, int type, float bw);\nncclResult_t ncclTopoPrintPaths(struct ncclTopoSystem* system);\nncclResult_t ncclTopoLoadSystem(const char* xmlTopoFile, struct ncclTopoSystem* system);\nncclResult_t ncclTopoGetIntermediateRank(struct ncclTopoSystem* system, int rank, int64_t netId, int* intermediateRank);\n\n#define NCCL_TOPO_XML_MAX_NODES 256\n#define NCCL_GRAPH_XML_MAX_NODES 4096\nncclResult_t ncclTopoGetSystemFromXml(struct ncclXml* xml, struct ncclTopoSystem** topoSystem, uint64_t localHostHash);\nncclResult_t ncclTopoGetGraphFromXml(struct ncclXmlNode *xmlGraphs, struct ncclTopoSystem* system, struct ncclTopoGraph* graph, int* nChannels);\nncclResult_t ncclTopoGetXmlFromGraphs(int ngraphs, struct ncclTopoGraph** graphs, struct ncclTopoSystem* system, struct ncclXml *xml);\n\nncclResult_t ncclTopoGetCompCap(struct ncclTopoSystem* system, int* ccMin, int* ccMax);\n\nstatic ncclResult_t ncclTopoIdToIndex(struct ncclTopoSystem* system, int type, int64_t id, int* index) {\n  *index = -1;\n  for (int i=0; i<system->nodes[type].count; i++) {\n    if (system->nodes[type].nodes[i].id == id) {\n      *index = i;\n      return ncclSuccess;\n    }\n  }\n  return ncclInternalError;\n}\n\nstatic ncclResult_t ncclTopoRankToIndex(struct ncclTopoSystem* system, int rank, int* index) {\n  *index = -1;\n  for (int i=0; i<system->nodes[GPU].count; i++) {\n    if (system->nodes[GPU].nodes[i].gpu.rank == rank) {\n      *index = i;\n      return ncclSuccess;\n    }\n  }\n  return ncclInternalError;\n}\n\nstatic ncclResult_t ncclTopoDevToRank(struct ncclTopoSystem* system, int dev, int* rank) {\n  *rank = -1;\n  for (int i=0; i<system->nodes[GPU].count; i++) {\n    if (NCCL_TOPO_ID_SYSTEM_ID(system->nodes[GPU].nodes[i].id) != system->systemId) continue; // Only consider GPUs on our node\n    if (system->nodes[GPU].nodes[i].gpu.dev == dev) {\n      *rank = system->nodes[GPU].nodes[i].gpu.rank;\n      return ncclSuccess;\n    }\n  }\n  return ncclInternalError;\n}\n\nstatic ncclResult_t ncclTopoIdToNetDev(struct ncclTopoSystem* system, int64_t id, int* netDev) {\n  *netDev = -1;\n  for (int i=0; i<system->nodes[NET].count; i++) {\n    if (system->nodes[NET].nodes[i].id == id) {\n      *netDev = system->nodes[NET].nodes[i].net.dev;\n      return ncclSuccess;\n    }\n  }\n  WARN(\"Could not find NET with id %lx\\n\", id);\n  return ncclInternalError;\n}\n\n// Returns NVLink bw in GB/s\nstatic float ncclTopoNVLinkBw(int cudaCompCap) {\n  return\n    cudaCompCap >= 90 ? SM90_NVLINK_BW :\n    cudaCompCap == 86 ? SM86_NVLINK_BW :\n    cudaCompCap >= 80 ? SM80_NVLINK_BW :\n    cudaCompCap >= 70 ? SM70_NVLINK_BW :\n    cudaCompCap >= 60 ? SM60_NVLINK_BW :\n    SM80_NVLINK_BW;\n}\n\n// Mirror bits\nstatic bool isPow2(int val) {\n  return (val & (val-1)) == 0;\n}\nstatic int mirrorBits(int val, int pow2) {\n  int mirror = 0;\n  for (int b=1, mb=(pow2>>1); b<pow2; b<<=1, mb>>=1) if (val & b) mirror |= mb;\n  return mirror;\n}\n#endif\n","uri":"file:///root/code/multi/nccl/src/graph/topo.h","version":1}}}

I[13:46:31.709] <-- textDocument/didOpen
E[13:46:31.709] System include extraction: driver clang not found in PATH
V[13:46:31.709] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"#include <lttng/tracelog.h>\n#include <sys/time.h>\n#include <x86intrin.h>\n\n#include \"nccl.h\"\n#include \"alloc.h\"\n#include \"checks.h\"\n#include \"nccl_tp.h\"\n\nextern const char* ncclDevFuncTableStr[];\nextern size_t ncclDevFuncTableStrCount;\n\nvoid getAllDevFuncStr() {\n  int i;\n  for(i=0; i<ncclDevFuncTableStrCount; i++) {\n    if (ncclDevFuncTableStr[i]) {\n      tracepoint(nccl, devFunc, i, ncclDevFuncTableStr[i]);\n    }\n  }\n}\n\nstatic ncclKrRing_t* ncclKrRing = NULL;\nstatic pthread_t ncclScanKernelThread;\nstatic void* scanKrRing(void* args);\nvoid getAllDevFuncStr();\n\nstatic pthread_mutex_t initLock = PTHREAD_MUTEX_INITIALIZER;\nstatic bool initialized = false;\n\nstatic int64_t freq = -1;\nstatic void calibrate() {\n    struct timeval tv;\n    gettimeofday(&tv, NULL);\n    uint64_t timeCycles = __rdtsc();\n    double time = - tv.tv_sec*1E6 - tv.tv_usec;\n    uint64_t total = 0ULL;\n    for (int i=0; i<10000; i++) total += __rdtsc();\n    gettimeofday(&tv, NULL);\n    timeCycles = __rdtsc() - timeCycles;\n    time += tv.tv_sec*1E6 + tv.tv_usec;\n    freq = int64_t(timeCycles*1E6/time);\n}\n\nstatic void initKernelRecord() {\n  char hostname[1024];\n  if (gethostname(hostname, sizeof(hostname)) != 0) {\n    strncpy(hostname, \"unknown\", sizeof(hostname));\n  }\n  int cudaDev = -1;\n  cudaGetDevice(&cudaDev);\n  tracepoint(nccl, startTrace, hostname, freq);\n\n  getAllDevFuncStr();\n  ncclResult_t res = ncclCudaHostCalloc(&ncclKrRing, 1);\n  assert(res==ncclSuccess);\n  int rc = pthread_mutex_init(&ncclKrRing->mutex, nullptr);\n  assert(rc==0);\n  pthread_create(&ncclScanKernelThread, NULL, scanKrRing, NULL);\n}\n\nncclKernelRecord_t * allocKrRingSlot(uint64_t commHash, int rank, int funcIndex, int channels, int channelUbound, uint64_t channelMask) {\n  long long start;\n  long long end;\n  pthread_mutex_lock(&ncclKrRing->mutex);\n  start = ncclKrRing->start;\n  end = ncclKrRing->end;\n  if (end - start == ncclKrRingSize) {\n    pthread_mutex_unlock(&ncclKrRing->mutex);\n    lttng_ust_tracelog(LTTNG_UST_TRACEPOINT_LOGLEVEL_INFO, \\\n      \"KernelRecord Alloc Failed: No slot to alloc for funcIndex=%d, channels=%d, start=%lld, end=%lld\", funcIndex, channels, start, end);\n    return NULL;\n  }\n  pthread_mutex_unlock(&ncclKrRing->mutex);\n\n  ncclKernelRecord_t *slot = &ncclKrRing->records[end%ncclKrRingSize];\n  memset(slot, 0, sizeof(ncclKernelRecord_t));\n  slot->rank = rank;\n  slot->funcIndex = funcIndex;\n  slot->nChannels = channels;\n  slot->channelUbound = channelUbound;\n  slot->channelMask = channelMask;\n  slot->id = end;\n  tracepoint(nccl, allocKr, slot->id, commHash, rank, funcIndex, channels, channelUbound, channelMask);\n\n  pthread_mutex_lock(&ncclKrRing->mutex);\n  ncclKrRing->end++;\n  pthread_mutex_unlock(&ncclKrRing->mutex);\n  return slot;\n}\n\nstatic void* scanKrRing(void* args) {\n  while(true) {\n    long long start;\n    long long end;\n    long long ix;\n    long long doneIx;\n    pthread_mutex_lock(&ncclKrRing->mutex);\n    start = ncclKrRing->start;\n    end = ncclKrRing->end;\n    pthread_mutex_unlock(&ncclKrRing->mutex);\n    doneIx=start-1;\n    for(ix=start; ix<end; ix++) {\n      ncclKernelRecord_t *slot = &ncclKrRing->records[ix%ncclKrRingSize];\n      int started=0;\n      int ended=0;\n      int c=0;\n      for(c=0; c<slot->channelUbound; c++) {\n        if(!(slot->channelMask & (1ull<<c))) {\n          continue;\n        }\n        if(slot->channels[c].start_clock!=0) {\n          started++;\n        }\n        if(slot->channels[c].end_clock!=0) {\n          ended++;\n        }\n        if(slot->channels[c].start_clock>0) {\n          tracepoint(nccl, startChannel, slot->id, c, slot->channels[c].start_clock, slot->channels[c].collBytes);\n          slot->channels[c].start_clock = 0-slot->channels[c].start_clock; // Avoid duplicate output.\n        }\n        if(slot->channels[c].end_clock>0) {\n          tracepoint(nccl, endChannel, slot->id, c, slot->channels[c].end_clock-(0-slot->channels[c].start_clock));\n          slot->channels[c].end_clock = 0-slot->channels[c].end_clock; // Avoid duplicate output.\n        }\n      }\n      if (slot->started != started || slot->ended != ended) {\n        tracepoint(nccl, scanKr, slot->id, started, ended);\n        slot->started = started;\n        slot->ended = ended;\n      }\n      if(doneIx==ix-1 && ended==slot->nChannels) {\n#ifdef ENABLE_SLOW\n        tracepoint(nccl, reduceCopy, slot->id, slot->rs.redcopy_cost, slot->channelUbound);\n#endif\n        doneIx = ix;\n        memset(slot, 0, sizeof(*slot));\n      }\n    }\n\n    if(doneIx!=start-1) {\n      pthread_mutex_lock(&ncclKrRing->mutex);\n      ncclKrRing->start = doneIx+1;\n      pthread_mutex_unlock(&ncclKrRing->mutex);\n      tracepoint(nccl, moveKr, doneIx+1);\n    }\n\n    usleep(10*1000);\n  }\n}\n\nvoid initProfileOnce() {\n  if (__atomic_load_n(&initialized, __ATOMIC_ACQUIRE)) return;\n  pthread_mutex_lock(&initLock);\n  if (!initialized) {\n    calibrate();\n    initKernelRecord();\n    __atomic_store_n(&initialized, true, __ATOMIC_RELEASE);\n  }\n  pthread_mutex_unlock(&initLock);\n}\n\n#define KWAI_NCCL_API(ret, func, args...) \\\n    __attribute__ ((visibility(\"default\"))) \\\n    ret func (args); \\\n    __attribute__ ((visibility(\"default\"))) \\\n    ret func (args) {  \\\n            initProfileOnce(); \\\n            tracepoint(nccl, enterFunc, #func); \\\n            ret res = p##func(\n\n#define KWAI_NCCL_API2(func, args...) \\\n            args); \\\n            tracepoint(nccl, exitFunc, #func); \\\n            return res; \\\n    }\n\nextern \"C\" {\n\n/*\nKWAI_NCCL_API(ncclResult_t, ncclRedOpCreatePreMulSum, ncclRedOp_t *op, void *scalar, ncclDataType_t datatype, ncclScalarResidence_t residence, ncclComm_t comm)\nKWAI_NCCL_API2(op, scalar, datatype, residence, comm);\n\nKWAI_NCCL_API(ncclResult_t, ncclRedOpDestroy, ncclRedOp_t op, ncclComm_t comm)\nKWAI_NCCL_API2(op, comm);\n*/\n\nKWAI_NCCL_API(ncclResult_t, ncclReduce, const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t datatype,\n    ncclRedOp_t op, int root, ncclComm_t comm, cudaStream_t stream)\nKWAI_NCCL_API2(ncclReduce, sendbuff, recvbuff, count, datatype, op, root, comm, stream);\n\n\nKWAI_NCCL_API(ncclResult_t, ncclBroadcast, const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t datatype, int root,\n    ncclComm_t comm, cudaStream_t stream)\nKWAI_NCCL_API2(ncclBroadcast, sendbuff, recvbuff, count, datatype, root, comm, stream);\n\nKWAI_NCCL_API(ncclResult_t, ncclAllReduce, const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t datatype, ncclRedOp_t op, ncclComm* comm, cudaStream_t stream)\nKWAI_NCCL_API2(ncclAllReduce, sendbuff,  recvbuff,  count,  datatype,  op,  comm,  stream);\n\nKWAI_NCCL_API(ncclResult_t, ncclReduceScatter, const void* sendbuff, void* recvbuff, size_t recvcount, ncclDataType_t datatype, ncclRedOp_t op, ncclComm_t comm, cudaStream_t stream)\nKWAI_NCCL_API2(ncclReduceScatter, sendbuff, recvbuff, recvcount, datatype, op, comm, stream);\n\nKWAI_NCCL_API(ncclResult_t, ncclAllGather, const void* sendbuff, void* recvbuff, size_t sendcount,\n    ncclDataType_t datatype, ncclComm_t comm, cudaStream_t stream)\nKWAI_NCCL_API2(ncclAllGather, sendbuff, recvbuff, sendcount, datatype, comm, stream);\n\n/*\nKWAI_NCCL_API(ncclResult_t, ncclSend, const void* sendbuff, size_t count, ncclDataType_t datatype, int peer,\n    ncclComm_t comm, cudaStream_t stream)\nKWAI_NCCL_API2(sendbuff, count, datatype, peer, comm, stream);\n\nKWAI_NCCL_API(ncclResult_t, ncclRecv, void* recvbuff, size_t count, ncclDataType_t datatype, int peer,\n    ncclComm_t comm, cudaStream_t stream)\nKWAI_NCCL_API2(recvbuff, count, datatype, peer, comm, stream);\n*/\n\nKWAI_NCCL_API(ncclResult_t, ncclGroupStart)\nKWAI_NCCL_API2(ncclGroupStart);\n\nKWAI_NCCL_API(ncclResult_t, ncclGroupEnd)\nKWAI_NCCL_API2(ncclGroupEnd);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommRegister, const ncclComm_t comm, void* buff, size_t size, void** handle)\nKWAI_NCCL_API2(ncclCommRegister, comm, buff, size, handle);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommDeregister, const ncclComm_t comm, void* handle)\nKWAI_NCCL_API2(ncclCommDeregister, comm, handle);\n\nKWAI_NCCL_API(ncclResult_t, ncclGetVersion, int* version)\nKWAI_NCCL_API2(ncclGetVersion, version);\n\nKWAI_NCCL_API(ncclResult_t, ncclGetUniqueId, ncclUniqueId* out)\nKWAI_NCCL_API2(ncclGetUniqueId, out);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommInitRank, ncclComm_t* newcomm, int nranks, ncclUniqueId commId, int myrank)\nKWAI_NCCL_API2(ncclCommInitRank, newcomm,  nranks,  commId,  myrank);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommInitAll, ncclComm_t* comms, int ndev, const int* devlist)\nKWAI_NCCL_API2(ncclCommInitAll, comms,  ndev,  devlist);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommInitRankConfig, ncclComm_t* comm, int nranks, ncclUniqueId commId, int myrank, ncclConfig_t *config)\nKWAI_NCCL_API2(ncclCommInitRankConfig, comm, nranks,  commId,  myrank,  config);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommFinalize, ncclComm_t comm)\nKWAI_NCCL_API2(ncclCommFinalize, comm);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommDestroy, ncclComm_t comm)\nKWAI_NCCL_API2(ncclCommDestroy, comm);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommAbort, ncclComm_t comm)\nKWAI_NCCL_API2(ncclCommAbort, comm);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommSplit, ncclComm_t comm, int color, int key, ncclComm_t *newcomm, ncclConfig_t *config)\nKWAI_NCCL_API2(ncclCommSplit, comm,  color,  key, newcomm, config);\n\nKWAI_NCCL_API(const char*, ncclGetErrorString, ncclResult_t code)\nKWAI_NCCL_API2(ncclGetErrorString, code);\n\nKWAI_NCCL_API(const char*, ncclGetLastError, const ncclComm_t comm)\nKWAI_NCCL_API2(ncclGetLastError, comm);\n\n//KWAI_NCCL_API(ncclResult_t, ncclCommGetAsyncError, ncclComm_t comm, ncclResult_t *asyncError)\n//KWAI_NCCL_API2( comm, asyncError);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommCount, const ncclComm_t comm, int* count)\nKWAI_NCCL_API2(ncclCommCount, comm,  count);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommCuDevice, const ncclComm_t comm, int* devid)\nKWAI_NCCL_API2(ncclCommCuDevice, comm,  devid);\n\nKWAI_NCCL_API(ncclResult_t, ncclCommUserRank, const ncclComm_t comm, int* rank)\nKWAI_NCCL_API2(ncclCommUserRank, comm,  rank);\n\n}\n","uri":"file:///root/code/multi/nccl/src/profile.cc","version":1}}}

I[13:46:31.709] <-- textDocument/didOpen
V[13:46:31.710] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"/* Copyright (C) 2008-2019 Free Software Foundation, Inc.\n\n   This file is part of GCC.\n\n   GCC is free software; you can redistribute it and/or modify\n   it under the terms of the GNU General Public License as published by\n   the Free Software Foundation; either version 3, or (at your option)\n   any later version.\n\n   GCC is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   Under Section 7 of GPL version 3, you are granted additional\n   permissions described in the GCC Runtime Library Exception, version\n   3.1, as published by the Free Software Foundation.\n\n   You should have received a copy of the GNU General Public License and\n   a copy of the GCC Runtime Library Exception along with this program;\n   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n   <http://www.gnu.org/licenses/>.  */\n\n#ifndef _X86INTRIN_H_INCLUDED\n#define _X86INTRIN_H_INCLUDED\n\n#include <ia32intrin.h>\n\n#ifndef __iamcu__\n\n/* For including AVX instructions */\n#include <immintrin.h>\n\n#include <mm3dnow.h>\n\n#include <fma4intrin.h>\n\n#include <xopintrin.h>\n\n#include <lwpintrin.h>\n\n#include <tbmintrin.h>\n\n#include <popcntintrin.h>\n\n#include <mwaitxintrin.h>\n\n#include <clzerointrin.h>\n\n#endif /* __iamcu__ */\n\n#endif /* _X86INTRIN_H_INCLUDED */\n","uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h","version":1}}}

I[13:46:31.710] <-- textDocument/didOpen
V[13:46:31.710] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"/* ===-------- ia32intrin.h ---------------------------------------------------===\n *\n * Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n * See https://llvm.org/LICENSE.txt for license information.\n * SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n *\n *===-----------------------------------------------------------------------===\n */\n\n#ifndef __X86INTRIN_H\n#error \"Never use <ia32intrin.h> directly; include <x86intrin.h> instead.\"\n#endif\n\n#ifndef __IA32INTRIN_H\n#define __IA32INTRIN_H\n\n/* Define the default attributes for the functions in this file. */\n#define __DEFAULT_FN_ATTRS __attribute__((__always_inline__, __nodebug__))\n#define __DEFAULT_FN_ATTRS_CRC32 __attribute__((__always_inline__, __nodebug__, __target__(\"crc32\")))\n\n#if defined(__cplusplus) && (__cplusplus >= 201103L)\n#define __DEFAULT_FN_ATTRS_CAST __attribute__((__always_inline__)) constexpr\n#define __DEFAULT_FN_ATTRS_CONSTEXPR __DEFAULT_FN_ATTRS constexpr\n#else\n#define __DEFAULT_FN_ATTRS_CAST __attribute__((__always_inline__))\n#define __DEFAULT_FN_ATTRS_CONSTEXPR __DEFAULT_FN_ATTRS\n#endif\n\n/// Find the first set bit starting from the lsb. Result is undefined if\n///    input is 0.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSF instruction or the\n///    \\c TZCNT instruction.\n///\n/// \\param __A\n///    A 32-bit integer operand.\n/// \\returns A 32-bit integer containing the bit number.\n/// \\see _bit_scan_forward\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n__bsfd(int __A) {\n  return __builtin_ctz((unsigned int)__A);\n}\n\n/// Find the first set bit starting from the msb. Result is undefined if\n///    input is 0.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSR instruction or the\n///    \\c LZCNT instruction and an \\c XOR.\n///\n/// \\param __A\n///    A 32-bit integer operand.\n/// \\returns A 32-bit integer containing the bit number.\n/// \\see _bit_scan_reverse\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n__bsrd(int __A) {\n  return 31 - __builtin_clz((unsigned int)__A);\n}\n\n/// Swaps the bytes in the input, converting little endian to big endian or\n///    vice versa.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSWAP instruction.\n///\n/// \\param __A\n///    A 32-bit integer operand.\n/// \\returns A 32-bit integer containing the swapped bytes.\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n__bswapd(int __A) {\n  return (int)__builtin_bswap32((unsigned int)__A);\n}\n\n/// Swaps the bytes in the input, converting little endian to big endian or\n///    vice versa.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSWAP instruction.\n///\n/// \\param __A\n///    A 32-bit integer operand.\n/// \\returns A 32-bit integer containing the swapped bytes.\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n_bswap(int __A) {\n  return (int)__builtin_bswap32((unsigned int)__A);\n}\n\n/// Find the first set bit starting from the lsb. Result is undefined if\n///    input is 0.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// int _bit_scan_forward(int A);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c BSF instruction or the\n///    \\c TZCNT instruction.\n///\n/// \\param A\n///    A 32-bit integer operand.\n/// \\returns A 32-bit integer containing the bit number.\n/// \\see __bsfd\n#define _bit_scan_forward(A) __bsfd((A))\n\n/// Find the first set bit starting from the msb. Result is undefined if\n///    input is 0.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// int _bit_scan_reverse(int A);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c BSR instruction or the\n///    \\c LZCNT instruction and an \\c XOR.\n///\n/// \\param A\n///    A 32-bit integer operand.\n/// \\returns A 32-bit integer containing the bit number.\n/// \\see __bsrd\n#define _bit_scan_reverse(A) __bsrd((A))\n\n#ifdef __x86_64__\n/// Find the first set bit starting from the lsb. Result is undefined if\n///    input is 0.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSF instruction or the\n///    \\c TZCNT instruction.\n///\n/// \\param __A\n///    A 64-bit integer operand.\n/// \\returns A 32-bit integer containing the bit number.\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n__bsfq(long long __A) {\n  return (long long)__builtin_ctzll((unsigned long long)__A);\n}\n\n/// Find the first set bit starting from the msb. Result is undefined if\n///    input is 0.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSR instruction or the\n///    \\c LZCNT instruction and an \\c XOR.\n///\n/// \\param __A\n///    A 64-bit integer operand.\n/// \\returns A 32-bit integer containing the bit number.\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n__bsrq(long long __A) {\n  return 63 - __builtin_clzll((unsigned long long)__A);\n}\n\n/// Swaps the bytes in the input. Converting little endian to big endian or\n///    vice versa.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c BSWAP instruction.\n///\n/// \\param __A\n///    A 64-bit integer operand.\n/// \\returns A 64-bit integer containing the swapped bytes.\n/// \\see _bswap64\nstatic __inline__ long long __DEFAULT_FN_ATTRS_CONSTEXPR\n__bswapq(long long __A) {\n  return (long long)__builtin_bswap64((unsigned long long)__A);\n}\n\n/// Swaps the bytes in the input. Converting little endian to big endian or\n///    vice versa.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// long long _bswap64(long long A);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c BSWAP instruction.\n///\n/// \\param A\n///    A 64-bit integer operand.\n/// \\returns A 64-bit integer containing the swapped bytes.\n/// \\see __bswapq\n#define _bswap64(A) __bswapq((A))\n#endif /* __x86_64__ */\n\n/// Counts the number of bits in the source operand having a value of 1.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c POPCNT instruction or a\n///    a sequence of arithmetic and logic ops to calculate it.\n///\n/// \\param __A\n///    An unsigned 32-bit integer operand.\n/// \\returns A 32-bit integer containing the number of bits with value 1 in the\n///    source operand.\n/// \\see _popcnt32\nstatic __inline__ int __DEFAULT_FN_ATTRS_CONSTEXPR\n__popcntd(unsigned int __A)\n{\n  return __builtin_popcount(__A);\n}\n\n/// Counts the number of bits in the source operand having a value of 1.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// int _popcnt32(int A);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c POPCNT instruction or a\n///    a sequence of arithmetic and logic ops to calculate it.\n///\n/// \\param A\n///    An unsigned 32-bit integer operand.\n/// \\returns A 32-bit integer containing the number of bits with value 1 in the\n///    source operand.\n/// \\see __popcntd\n#define _popcnt32(A) __popcntd((A))\n\n#ifdef __x86_64__\n/// Counts the number of bits in the source operand having a value of 1.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c POPCNT instruction or a\n///    a sequence of arithmetic and logic ops to calculate it.\n///\n/// \\param __A\n///    An unsigned 64-bit integer operand.\n/// \\returns A 64-bit integer containing the number of bits with value 1 in the\n///    source operand.\n/// \\see _popcnt64\nstatic __inline__ long long __DEFAULT_FN_ATTRS_CONSTEXPR\n__popcntq(unsigned long long __A)\n{\n  return __builtin_popcountll(__A);\n}\n\n/// Counts the number of bits in the source operand having a value of 1.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// long long _popcnt64(unsigned long long A);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c POPCNT instruction or a\n///    a sequence of arithmetic and logic ops to calculate it.\n///\n/// \\param A\n///    An unsigned 64-bit integer operand.\n/// \\returns A 64-bit integer containing the number of bits with value 1 in the\n///    source operand.\n/// \\see __popcntq\n#define _popcnt64(A) __popcntq((A))\n#endif /* __x86_64__ */\n\n#ifdef __x86_64__\n/// Returns the program status and control \\c RFLAGS register with the \\c VM\n///    and \\c RF flags cleared.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c PUSHFQ + \\c POP instruction sequence.\n///\n/// \\returns The 64-bit value of the RFLAGS register.\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS\n__readeflags(void)\n{\n  return __builtin_ia32_readeflags_u64();\n}\n\n/// Writes the specified value to the program status and control \\c RFLAGS\n///    register. Reserved bits are not affected.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c PUSH + \\c POPFQ instruction sequence.\n///\n/// \\param __f\n///    The 64-bit value to write to \\c RFLAGS.\nstatic __inline__ void __DEFAULT_FN_ATTRS\n__writeeflags(unsigned long long __f)\n{\n  __builtin_ia32_writeeflags_u64(__f);\n}\n\n#else /* !__x86_64__ */\n/// Returns the program status and control \\c EFLAGS register with the \\c VM\n///    and \\c RF flags cleared.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c PUSHFD + \\c POP instruction sequence.\n///\n/// \\returns The 32-bit value of the EFLAGS register.\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS\n__readeflags(void)\n{\n  return __builtin_ia32_readeflags_u32();\n}\n\n/// Writes the specified value to the program status and control \\c EFLAGS\n///    register. Reserved bits are not affected.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c PUSH + \\c POPFD instruction sequence.\n///\n/// \\param __f\n///    The 32-bit value to write to \\c EFLAGS.\nstatic __inline__ void __DEFAULT_FN_ATTRS\n__writeeflags(unsigned int __f)\n{\n  __builtin_ia32_writeeflags_u32(__f);\n}\n#endif /* !__x86_64__ */\n\n/// Cast a 32-bit float value to a 32-bit unsigned integer value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c VMOVD / \\c MOVD instruction in x86_64,\n///    and corresponds to the \\c VMOVL / \\c MOVL instruction in ia32.\n///\n/// \\param __A\n///    A 32-bit float value.\n/// \\returns a 32-bit unsigned integer containing the converted value.\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS_CAST\n_castf32_u32(float __A) {\n  return __builtin_bit_cast(unsigned int, __A);\n}\n\n/// Cast a 64-bit float value to a 64-bit unsigned integer value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c VMOVQ / \\c MOVQ instruction in x86_64,\n///    and corresponds to the \\c VMOVL / \\c MOVL instruction in ia32.\n///\n/// \\param __A\n///    A 64-bit float value.\n/// \\returns a 64-bit unsigned integer containing the converted value.\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS_CAST\n_castf64_u64(double __A) {\n  return __builtin_bit_cast(unsigned long long, __A);\n}\n\n/// Cast a 32-bit unsigned integer value to a 32-bit float value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c VMOVQ / \\c MOVQ instruction in x86_64,\n///    and corresponds to the \\c FLDS instruction in ia32.\n///\n/// \\param __A\n///    A 32-bit unsigned integer value.\n/// \\returns a 32-bit float value containing the converted value.\nstatic __inline__ float __DEFAULT_FN_ATTRS_CAST\n_castu32_f32(unsigned int __A) {\n  return __builtin_bit_cast(float, __A);\n}\n\n/// Cast a 64-bit unsigned integer value to a 64-bit float value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c VMOVQ / \\c MOVQ instruction in x86_64,\n///    and corresponds to the \\c FLDL instruction in ia32.\n///\n/// \\param __A\n///    A 64-bit unsigned integer value.\n/// \\returns a 64-bit float value containing the converted value.\nstatic __inline__ double __DEFAULT_FN_ATTRS_CAST\n_castu64_f64(unsigned long long __A) {\n  return __builtin_bit_cast(double, __A);\n}\n\n/// Adds the unsigned integer operand to the CRC-32C checksum of the\n///     unsigned char operand.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c CRC32B instruction.\n///\n/// \\param __C\n///    An unsigned integer operand to add to the CRC-32C checksum of operand\n///    \\a  __D.\n/// \\param __D\n///    An unsigned 8-bit integer operand used to compute the CRC-32C checksum.\n/// \\returns The result of adding operand \\a __C to the CRC-32C checksum of\n///    operand \\a __D.\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS_CRC32\n__crc32b(unsigned int __C, unsigned char __D)\n{\n  return __builtin_ia32_crc32qi(__C, __D);\n}\n\n/// Adds the unsigned integer operand to the CRC-32C checksum of the\n///    unsigned short operand.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c CRC32W instruction.\n///\n/// \\param __C\n///    An unsigned integer operand to add to the CRC-32C checksum of operand\n///    \\a  __D.\n/// \\param __D\n///    An unsigned 16-bit integer operand used to compute the CRC-32C checksum.\n/// \\returns The result of adding operand \\a __C to the CRC-32C checksum of\n///    operand \\a __D.\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS_CRC32\n__crc32w(unsigned int __C, unsigned short __D)\n{\n  return __builtin_ia32_crc32hi(__C, __D);\n}\n\n/// Adds the unsigned integer operand to the CRC-32C checksum of the\n///    second unsigned integer operand.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c CRC32D instruction.\n///\n/// \\param __C\n///    An unsigned integer operand to add to the CRC-32C checksum of operand\n///    \\a  __D.\n/// \\param __D\n///    An unsigned 32-bit integer operand used to compute the CRC-32C checksum.\n/// \\returns The result of adding operand \\a __C to the CRC-32C checksum of\n///    operand \\a __D.\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS_CRC32\n__crc32d(unsigned int __C, unsigned int __D)\n{\n  return __builtin_ia32_crc32si(__C, __D);\n}\n\n#ifdef __x86_64__\n/// Adds the unsigned integer operand to the CRC-32C checksum of the\n///    unsigned 64-bit integer operand.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c CRC32Q instruction.\n///\n/// \\param __C\n///    An unsigned integer operand to add to the CRC-32C checksum of operand\n///    \\a  __D.\n/// \\param __D\n///    An unsigned 64-bit integer operand used to compute the CRC-32C checksum.\n/// \\returns The result of adding operand \\a __C to the CRC-32C checksum of\n///    operand \\a __D.\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS_CRC32\n__crc32q(unsigned long long __C, unsigned long long __D)\n{\n  return __builtin_ia32_crc32di(__C, __D);\n}\n#endif /* __x86_64__ */\n\n/// Reads the specified performance monitoring counter. Refer to your\n///    processor's documentation to determine which performance counters are\n///    supported.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c RDPMC instruction.\n///\n/// \\param __A\n///    The performance counter to read.\n/// \\returns The 64-bit value read from the performance counter.\n/// \\see _rdpmc\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS\n__rdpmc(int __A) {\n  return __builtin_ia32_rdpmc(__A);\n}\n\n/// Reads the processor's time stamp counter and the \\c IA32_TSC_AUX MSR\n///    \\c (0xc0000103).\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c RDTSCP instruction.\n///\n/// \\param __A\n///    Address of where to store the 32-bit \\c IA32_TSC_AUX value.\n/// \\returns The 64-bit value of the time stamp counter.\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS\n__rdtscp(unsigned int *__A) {\n  return __builtin_ia32_rdtscp(__A);\n}\n\n/// Reads the processor's time stamp counter.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned long long _rdtsc();\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c RDTSC instruction.\n///\n/// \\returns The 64-bit value of the time stamp counter.\n#define _rdtsc() __rdtsc()\n\n/// Reads the specified performance monitoring counter. Refer to your\n///    processor's documentation to determine which performance counters are\n///    supported.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned long long _rdpmc(int A);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c RDPMC instruction.\n///\n/// \\param A\n///    The performance counter to read.\n/// \\returns The 64-bit value read from the performance counter.\n/// \\see __rdpmc\n#define _rdpmc(A) __rdpmc(A)\n\nstatic __inline__ void __DEFAULT_FN_ATTRS\n_wbinvd(void) {\n  __builtin_ia32_wbinvd();\n}\n\n/// Rotates an 8-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param __X\n///    The unsigned 8-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\nstatic __inline__ unsigned char __DEFAULT_FN_ATTRS_CONSTEXPR\n__rolb(unsigned char __X, int __C) {\n  return __builtin_rotateleft8(__X, __C);\n}\n\n/// Rotates an 8-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param __X\n///    The unsigned 8-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\nstatic __inline__ unsigned char __DEFAULT_FN_ATTRS_CONSTEXPR\n__rorb(unsigned char __X, int __C) {\n  return __builtin_rotateright8(__X, __C);\n}\n\n/// Rotates a 16-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param __X\n///    The unsigned 16-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see _rotwl\nstatic __inline__ unsigned short __DEFAULT_FN_ATTRS_CONSTEXPR\n__rolw(unsigned short __X, int __C) {\n  return __builtin_rotateleft16(__X, __C);\n}\n\n/// Rotates a 16-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param __X\n///    The unsigned 16-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see _rotwr\nstatic __inline__ unsigned short __DEFAULT_FN_ATTRS_CONSTEXPR\n__rorw(unsigned short __X, int __C) {\n  return __builtin_rotateright16(__X, __C);\n}\n\n/// Rotates a 32-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param __X\n///    The unsigned 32-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see _rotl\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS_CONSTEXPR\n__rold(unsigned int __X, int __C) {\n  return __builtin_rotateleft32(__X, (unsigned int)__C);\n}\n\n/// Rotates a 32-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param __X\n///    The unsigned 32-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see _rotr\nstatic __inline__ unsigned int __DEFAULT_FN_ATTRS_CONSTEXPR\n__rord(unsigned int __X, int __C) {\n  return __builtin_rotateright32(__X, (unsigned int)__C);\n}\n\n#ifdef __x86_64__\n/// Rotates a 64-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param __X\n///    The unsigned 64-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS_CONSTEXPR\n__rolq(unsigned long long __X, int __C) {\n  return __builtin_rotateleft64(__X, (unsigned long long)__C);\n}\n\n/// Rotates a 64-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param __X\n///    The unsigned 64-bit value to be rotated.\n/// \\param __C\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\nstatic __inline__ unsigned long long __DEFAULT_FN_ATTRS_CONSTEXPR\n__rorq(unsigned long long __X, int __C) {\n  return __builtin_rotateright64(__X, (unsigned long long)__C);\n}\n#endif /* __x86_64__ */\n\n#ifndef _MSC_VER\n/* These are already provided as builtins for MSVC. */\n/* Select the correct function based on the size of long. */\n#ifdef __LP64__\n/// Rotates a 64-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned long long _lrotl(unsigned long long a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param a\n///    The unsigned 64-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rolq\n#define _lrotl(a,b) __rolq((a), (b))\n\n/// Rotates a 64-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned long long _lrotr(unsigned long long a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param a\n///    The unsigned 64-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rorq\n#define _lrotr(a,b) __rorq((a), (b))\n#else // __LP64__\n/// Rotates a 32-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned int _lrotl(unsigned int a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param a\n///    The unsigned 32-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rold\n#define _lrotl(a,b) __rold((a), (b))\n\n/// Rotates a 32-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned int _lrotr(unsigned int a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param a\n///    The unsigned 32-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rord\n#define _lrotr(a,b) __rord((a), (b))\n#endif // __LP64__\n\n/// Rotates a 32-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned int _rotl(unsigned int a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param a\n///    The unsigned 32-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rold\n#define _rotl(a,b) __rold((a), (b))\n\n/// Rotates a 32-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned int _rotr(unsigned int a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param a\n///    The unsigned 32-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rord\n#define _rotr(a,b) __rord((a), (b))\n#endif // _MSC_VER\n\n/* These are not builtins so need to be provided in all modes. */\n/// Rotates a 16-bit value to the left by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned short _rotwl(unsigned short a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROL instruction.\n///\n/// \\param a\n///    The unsigned 16-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rolw\n#define _rotwl(a,b) __rolw((a), (b))\n\n/// Rotates a 16-bit value to the right by the specified number of bits.\n///    This operation is undefined if the number of bits exceeds the size of\n///    the value.\n///\n/// \\headerfile <x86intrin.h>\n///\n/// \\code\n/// unsigned short _rotwr(unsigned short a, int b);\n/// \\endcode\n///\n/// This intrinsic corresponds to the \\c ROR instruction.\n///\n/// \\param a\n///    The unsigned 16-bit value to be rotated.\n/// \\param b\n///    The number of bits to rotate the value.\n/// \\returns The rotated value.\n/// \\see __rorw\n#define _rotwr(a,b) __rorw((a), (b))\n\n#undef __DEFAULT_FN_ATTRS\n#undef __DEFAULT_FN_ATTRS_CAST\n#undef __DEFAULT_FN_ATTRS_CRC32\n#undef __DEFAULT_FN_ATTRS_CONSTEXPR\n\n#endif /* __IA32INTRIN_H */\n","uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h","version":1}}}

I[13:46:31.711] <-- textDocument/didOpen
I[13:46:31.710] Failed to find compilation database for /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h
I[13:46:31.711] ASTWorker building file /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h version 1 with command clangd fallback
[/usr/lib/gcc/x86_64-linux-gnu/9/include]
/usr/bin/clang -xobjective-c++-header -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h
I[13:46:31.711] --> textDocument/publishDiagnostics
V[13:46:31.711] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[],"uri":"file:///root/code/multi/nccl/.clangd"}}

V[13:46:31.712] <<< {"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"languageId":"cpp","text":"/*************************************************************************\n * Copyright (c) 2015-2022, NVIDIA CORPORATION. All rights reserved.\n *\n * See LICENSE.txt for license information\n ************************************************************************/\n\n#include \"nccl.h\"\n#include \"channel.h\"\n#include \"nvmlwrap.h\"\n#include \"gdrwrap.h\"\n#include \"bootstrap.h\"\n#include \"transport.h\"\n#include \"group.h\"\n#include \"net.h\"\n#include \"coll_net.h\"\n#include \"enqueue.h\"\n#include \"graph.h\"\n#include \"argcheck.h\"\n#include \"tuner.h\"\n#include <fcntl.h>\n#include <string.h>\n#include <errno.h>\n#include <assert.h>\n#include <dlfcn.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <unistd.h>\n#include \"param.h\"\n\n#include \"nccl_tp.h\"\n\n#define STR2(v) #v\n#define STR(v) STR2(v)\n\n#if CUDART_VERSION >= 9020\n#define NCCL_GROUP_CUDA_STREAM 0 // CGMD: CUDA 9.2,10.X Don't need to use an internal CUDA stream\n#else\n#define NCCL_GROUP_CUDA_STREAM 1 // CGMD: CUDA 9.0,9.1 Need to use an internal CUDA stream\n#endif\n\nconst char* ncclFuncStr[NCCL_NUM_FUNCTIONS] = { \"Broadcast\", \"Reduce\", \"AllGather\", \"ReduceScatter\", \"AllReduce\" };\nconst char* ncclAlgoStr[NCCL_NUM_ALGORITHMS] = { \"Tree\", \"Ring\", \"CollNetDirect\", \"CollNetChain\", \"NVLS\", \"NVLSTree\" };\nconst char* ncclProtoStr[NCCL_NUM_PROTOCOLS] = { \"LL\", \"LL128\", \"Simple\" };\n\nNCCL_PARAM(GroupCudaStream, \"GROUP_CUDA_STREAM\", NCCL_GROUP_CUDA_STREAM);\n\nNCCL_PARAM(CheckPointers, \"CHECK_POINTERS\", 0);\nNCCL_PARAM(CommBlocking, \"COMM_BLOCKING\", NCCL_CONFIG_UNDEF_INT);\n\nstatic ncclResult_t commReclaim(ncclComm_t comm);\n\nstatic uint64_t hashUniqueId(ncclUniqueId const &id) {\n  char const *bytes = (char const*)&id;\n  uint64_t h = 0xdeadbeef;\n  for(int i=0; i < (int)sizeof(ncclUniqueId); i++) {\n    h ^= h >> 32;\n    h *= 0x8db3db47fa2994ad;\n    h += bytes[i];\n  }\n  return h;\n}\n\n// GDRCOPY support: Off by default\nNCCL_PARAM(GdrCopyEnable, \"GDRCOPY_ENABLE\", 0);\n\n// GDRCOPY support\ngdr_t ncclGdrCopy = NULL;\n\nncclResult_t initGdrCopy() {\n  if (ncclParamGdrCopyEnable() == 1) {\n    ncclGdrCopy = ncclGdrInit();\n  }\n  return ncclSuccess;\n}\n\npthread_mutex_t initLock = PTHREAD_MUTEX_INITIALIZER;\nstatic bool initialized = false;\n\nstatic ncclResult_t ncclInit() {\n  if (__atomic_load_n(&initialized, __ATOMIC_ACQUIRE)) return ncclSuccess;\n  pthread_mutex_lock(&initLock);\n  if (!initialized) {\n    initEnv();\n    initGdrCopy();\n    // Always initialize bootstrap network\n    NCCLCHECK(bootstrapNetInit());\n    NCCLCHECK(ncclNetPluginInit());\n\n    initNvtxRegisteredEnums();\n    __atomic_store_n(&initialized, true, __ATOMIC_RELEASE);\n  }\n  pthread_mutex_unlock(&initLock);\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclGetVersion, int* version);\nncclResult_t ncclGetVersion(int* version) {\n  if (version == NULL) return ncclInvalidArgument;\n  *version = NCCL_VERSION_CODE;\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclGetUniqueId, ncclUniqueId* out);\nncclResult_t ncclGetUniqueId(ncclUniqueId* out) {\n  NCCLCHECK(ncclInit());\n  NCCLCHECK(PtrCheck(out, \"GetUniqueId\", \"out\"));\n  ncclResult_t res = bootstrapGetUniqueId((struct ncclBootstrapHandle*)out);\n  TRACE_CALL(\"ncclGetUniqueId(0x%llx)\", (unsigned long long)hashUniqueId(*out));\n  return res;\n}\n\n// Prevent compiler from optimizing out these operations\n#ifdef __clang__\n#define NCCL_NO_OPTIMIZE __attribute__((optnone))\n#else\n#define NCCL_NO_OPTIMIZE __attribute__((optimize(\"O0\")))\n#endif\n\nvoid NCCL_NO_OPTIMIZE commPoison(ncclComm_t comm) {\n  // Important that this does not trash intraComm0.\n  comm->rank = comm->cudaDev = comm->busId = comm->nRanks = -1;\n  comm->startMagic = comm->endMagic = 0;\n}\n\n#undef NCCL_NO_OPTIMIZE\n\n\nstatic ncclResult_t ncclDestructorFnFree(struct ncclDestructor* dtor) {\n  free(dtor->obj);\n  return ncclSuccess;\n}\nvoid ncclCommPushFree(struct ncclComm* comm, void* obj) {\n  struct ncclDestructor* dtor = ncclMemoryStackAlloc<struct ncclDestructor>(&comm->memPermanent);\n  dtor->fn = ncclDestructorFnFree;\n  dtor->obj = obj;\n  dtor->next = comm->destructorHead;\n  comm->destructorHead = dtor;\n}\n\nstatic ncclResult_t ncclDestructorFnCudaFree(struct ncclDestructor* dtor) {\n  NCCLCHECK(ncclCudaFree(dtor->obj));\n  return ncclSuccess;\n}\nvoid ncclCommPushCudaFree(struct ncclComm* comm, void* obj) {\n  struct ncclDestructor* dtor = ncclMemoryStackAlloc<struct ncclDestructor>(&comm->memPermanent);\n  dtor->fn = ncclDestructorFnCudaFree;\n  dtor->obj = obj;\n  dtor->next = comm->destructorHead;\n  comm->destructorHead = dtor;\n}\n\nstatic ncclResult_t ncclDestructorFnCudaHostFree(struct ncclDestructor* dtor) {\n  CUDACHECK(cudaFreeHost(dtor->obj));\n  return ncclSuccess;\n}\nvoid ncclCommPushCudaHostFree(struct ncclComm* comm, void* obj) {\n  struct ncclDestructor* dtor = ncclMemoryStackAlloc<struct ncclDestructor>(&comm->memPermanent);\n  dtor->fn = ncclDestructorFnCudaHostFree;\n  dtor->obj = obj;\n  dtor->next = comm->destructorHead;\n  comm->destructorHead = dtor;\n}\n\nstatic ncclResult_t ncclDestructorFnCudaGdrFree(struct ncclDestructor* dtor) {\n  NCCLCHECK(ncclGdrCudaFree(dtor->obj));\n  return ncclSuccess;\n}\nvoid ncclCommPushCudaGdrFree(struct ncclComm* comm, void* handle) {\n  struct ncclDestructor* dtor = ncclMemoryStackAlloc<struct ncclDestructor>(&comm->memPermanent);\n  dtor->fn = ncclDestructorFnCudaGdrFree;\n  dtor->obj = handle;\n  dtor->next = comm->destructorHead;\n  comm->destructorHead = dtor;\n}\n\nstatic ncclResult_t commFree(ncclComm_t comm) {\n  /* commFree() should not involve any sync among ranks. */\n  if (comm == NULL)\n    return ncclSuccess;\n\n  /* in commReclaim, we have guaranteed only last rank which calls ncclCommDestroy() will\n   * free all intra-process communicators; therefore, we only need to focus on local\n   * resource cleanup in commFree(). */\n  if (comm->proxyState && comm->proxyRefCountOld == 0 && comm->proxyState->thread) {\n    pthread_join(comm->proxyState->thread, nullptr);\n    if (comm->proxyState->threadUDS) {\n      // UDS support\n      pthread_join(comm->proxyState->threadUDS, nullptr);;\n    }\n  }\n\n  delete[] comm->userRedOps;\n\n  free(comm->connectSend);\n  free(comm->connectRecv);\n\n  free(comm->peerInfo);\n  if (comm->topo)\n    ncclTopoFree(comm->topo);\n  if (comm->nodeRanks) {\n    for (int n=0; n<comm->nNodes; n++) free(comm->nodeRanks[n].localRankToRank);\n    free(comm->nodeRanks);\n  }\n  free(comm->rankToNode);\n  free(comm->rankToLocalRank);\n  free(comm->collNetHeads);\n\n  if (comm->bootstrap)\n    NCCLCHECK(bootstrapClose(comm->bootstrap));\n\n  for (int channel=0; channel<MAXCHANNELS; channel++)\n    NCCLCHECK(freeChannel(comm->channels+channel, comm->nRanks, 1, comm->localRanks));\n\n  if (comm->sharedRes) {\n    if (ncclAtomicRefCountDecrement(&comm->sharedRes->refCount) == 0) {\n      for (int c=0; c<MAXCHANNELS; c++) {\n        if (comm->sharedRes->peers[c]) free(comm->sharedRes->peers[c]);\n        if (comm->sharedRes->devPeers[c]) ncclCudaFree(comm->sharedRes->devPeers[c]);\n      }\n      free(comm->sharedRes->tpRankToLocalRank);\n      NCCLCHECK(ncclStrongStreamDestruct(&comm->sharedRes->hostStream));\n      NCCLCHECK(ncclStrongStreamDestruct(&comm->sharedRes->deviceStream));\n      NCCLCHECK(ncclProxyDestroy(comm));\n      free(comm->sharedRes);\n    }\n  }\n\n  if (comm->nvlsSupport) NCCLCHECK(ncclNvlsFree(comm));\n\n  struct ncclDestructor* dtor = comm->destructorHead;\n  while (dtor != nullptr) {\n    NCCLCHECK(dtor->fn(dtor));\n    dtor = dtor->next;\n  }\n\n  ncclMemoryStackDestruct(&comm->memScoped);\n  ncclMemoryStackDestruct(&comm->memPermanent);\n\n  if (ncclAtomicRefCountDecrement(comm->abortFlagRefCount) == 0) {\n    NCCLCHECK(ncclCudaHostFree((void *)comm->abortFlag));\n    free(comm->abortFlagRefCount);\n  }\n  free((void*)comm->config.netName);\n\n  free(comm->topParentRanks);\n  free(comm->topParentLocalRanks);\n\n  NCCLCHECK(ncclRegCleanup(comm));\n\n  commPoison(comm); // poison comm before free to avoid comm reuse.\n  free(comm);\n\n  return ncclSuccess;\n}\n\nNCCL_PARAM(DisableGraphHelper, \"GRAPH_HELPER_DISABLE\", 0);\n// GDRCOPY support: FIFO_ENABLE when enabled locates a workFifo in CUDA memory\nNCCL_PARAM(GdrCopyFifoEnable, \"GDRCOPY_FIFO_ENABLE\", 1);\nNCCL_PARAM(WorkFifoDepth, \"WORK_FIFO_DEPTH\", 64<<10);\nenum ncclLaunchMode ncclParamLaunchMode;\n\nNCCL_PARAM(DmaBufEnable, \"DMABUF_ENABLE\", 1);\n\n// Detect DMA-BUF support\nstatic ncclResult_t dmaBufSupported(struct ncclComm* comm) {\n  if (ncclParamDmaBufEnable() == 0 || comm->ncclNet->regMrDmaBuf == NULL || ncclCudaLibraryInit() != ncclSuccess) return ncclInternalError;\n#if CUDA_VERSION >= 11070\n  int flag = 0;\n  CUdevice dev;\n  int cudaDriverVersion;\n  CUDACHECK(cudaDriverGetVersion(&cudaDriverVersion));\n  if (CUPFN(cuDeviceGet) == NULL || cudaDriverVersion < 11070) return ncclInternalError;\n  CUCHECK(cuDeviceGet(&dev, comm->cudaDev));\n  // Query device to see if DMA-BUF support is available\n  (void) CUPFN(cuDeviceGetAttribute(&flag, CU_DEVICE_ATTRIBUTE_DMA_BUF_SUPPORTED, dev));\n  if (flag == 0) return ncclInternalError;\n  INFO(NCCL_INIT, \"DMA-BUF is available on GPU device %d\", comm->cudaDev);\n  return ncclSuccess;\n#endif\n  return ncclInternalError;\n}\n\nncclResult_t ncclCommEnsureReady(ncclComm_t comm) {\n  /* comm must be ready, or error will be reported */\n  ncclResult_t ret = ncclSuccess;\n  if (__atomic_load_n(comm->abortFlag, __ATOMIC_RELAXED)) {\n    ncclGroupJobAbort(comm->groupJob);\n  } else {\n    NCCLCHECK(ncclCommGetAsyncError(comm, &ret));\n    if (ret != ncclSuccess) {\n      /* if ret is not ncclInProgress, we just keep it. */\n      WARN(\"Attempt to use communicator before the previous operation returned ncclSuccess\");\n      if (ret == ncclInProgress) ret = ncclInvalidArgument;\n      goto exit;\n    }\n    /* if there is linked group job, we should complete it. */\n    if (comm->groupJob) {\n      NCCLCHECK(ncclGroupJobComplete(comm->groupJob));\n      comm->groupJob = NULL;\n    }\n  }\n\nexit:\n  return ret;\n}\n\nstatic ncclResult_t commAlloc(struct ncclComm* comm, struct ncclComm* parent, int ndev, int rank) {\n  if (ndev < 1) {\n    WARN(\"invalid device count (%d) requested\", ndev);\n    return ncclInvalidArgument;\n  }\n  if (rank >= ndev || rank < 0) {\n    WARN(\"rank %d exceeds ndev=%d\", rank, ndev);\n    return ncclInvalidArgument;\n  }\n\n  ncclMemoryStackConstruct(&comm->memPermanent);\n  ncclMemoryStackConstruct(&comm->memScoped);\n  comm->destructorHead = nullptr;\n  comm->rank = rank;\n  comm->nRanks = ndev;\n\n  NCCLCHECK(ncclNetInit(comm));\n  INFO(NCCL_INIT, \"Using network %s\", comm->ncclNet->name);\n\n  if (parent && parent->config.splitShare) {\n    if (parent->ncclNet != comm->ncclNet) {\n      WARN(\"Split shares resources, but parent comm netName %s is different from child comm netName %s\", parent->ncclNet->name, comm->ncclNet->name);\n      return ncclInvalidUsage;\n    }\n  }\n  // Try to create a CUDA object right away. If there is something wrong with\n  // the device we're on (failure cause #1) , better know it early.\n  CUDACHECK(cudaGetDevice(&comm->cudaDev));\n\n  NCCLCHECK(getBusId(comm->cudaDev, &comm->busId));\n  nvmlDevice_t nvmlDev;\n  char busId[NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE];\n  NCCLCHECK(int64ToBusId(comm->busId, busId));\n  NCCLCHECK(ncclNvmlDeviceGetHandleByPciBusId(busId, &nvmlDev));\n  NCCLCHECK(ncclNvmlDeviceGetIndex(nvmlDev, (unsigned int*)&comm->nvmlDev));\n\n  comm->compCap = ncclCudaCompCap();\n  TRACE(NCCL_INIT,\"comm %p rank %d nranks %d cudaDev %d busId %lx compCap %d\", comm, rank, ndev, comm->cudaDev, comm->busId, comm->compCap);\n\n  comm->checkPointers = ncclParamCheckPointers() == 1 ? true : false;\n  comm->dmaBufSupport = (dmaBufSupported(comm) == ncclSuccess) ? true : false;\n\n  comm->collNetSupport = 0;\n  memset(comm->collNetSupportMatrix, 0, sizeof(comm->collNetSupportMatrix));\n\n  ncclMemoryPoolConstruct(&comm->memPool_ncclKernelPlan);\n  ncclMemoryPoolConstruct(&comm->memPool_ncclProxyOp);\n  ncclMemoryPoolConstruct(&comm->memPool_ncclPointerList);\n  ncclMemoryPoolConstruct(&comm->memPool_ncclNvlsHandleList);\n  ncclMemoryPoolConstruct(&comm->memPool_ncclCollnetHandleList);\n\n  comm->groupNext = reinterpret_cast<struct ncclComm*>(0x1);\n  comm->preconnectNext = reinterpret_cast<struct ncclComm*>(0x1);\n\n  static_assert(MAXCHANNELS <= sizeof(*comm->connectSend)*8, \"comm->connectSend must have enough bits for all channels\");\n  static_assert(MAXCHANNELS <= sizeof(*comm->connectRecv)*8, \"comm->connectRecv must have enough bits for all channels\");\n  NCCLCHECK(ncclCalloc(&comm->connectSend, comm->nRanks));\n  NCCLCHECK(ncclCalloc(&comm->connectRecv, comm->nRanks));\n\n  // Mark channels as non initialized.\n  for (int c=0; c < MAXCHANNELS; c++) comm->channels[c].id = -1;\n\n  if (parent == NULL || !parent->config.splitShare) {\n    struct ncclSharedResources* sharedRes = NULL;\n    NCCLCHECK(ncclCalloc(&sharedRes, 1));\n    /* most of attributes are assigned later in initTransportsRank(). */\n    sharedRes->owner = comm;\n    sharedRes->tpNRanks = comm->nRanks;\n    NCCLCHECK(ncclCalloc(&sharedRes->tpRankToLocalRank, comm->nRanks));\n    NCCLCHECK(ncclStrongStreamConstruct(&sharedRes->deviceStream));\n    NCCLCHECK(ncclStrongStreamConstruct(&sharedRes->hostStream));\n    comm->sharedRes = sharedRes;\n    sharedRes->refCount = 1;\n  } else {\n    comm->sharedRes = parent->sharedRes;\n    ncclAtomicRefCountIncrement(&parent->sharedRes->refCount);\n  }\n\n  if (comm->topParentRanks == NULL) {\n    NCCLCHECK(ncclCalloc(&comm->topParentRanks, comm->nRanks));\n    for (int i = 0; i < comm->nRanks; ++i)\n      comm->topParentRanks[i] = i;\n  }\n\n  ncclIntruQueueMpscConstruct(&comm->callbackQueue);\n\n  comm->regCache.pageSize = sysconf(_SC_PAGESIZE);\n  return ncclSuccess;\n}\n\nstatic ncclResult_t devCommSetup(ncclComm_t comm) {\n  ncclResult_t ret = ncclSuccess;\n  int nRanks = comm->nRanks;\n  struct ncclDevCommAndChannels tmpCommAndChans;\n  struct ncclDevCommAndChannels *devCommAndChans = NULL;\n\n  NCCLCHECKGOTO(ncclStrongStreamAcquireUncaptured(&comm->sharedRes->deviceStream), ret, fail);\n  NCCLCHECKGOTO(ncclCudaCallocAsync(&devCommAndChans, 1, comm->sharedRes->deviceStream.cudaStream), ret, fail);\n  ncclCommPushCudaFree(comm, devCommAndChans);\n  comm->devComm = &devCommAndChans->comm;\n  tmpCommAndChans.comm.rank = comm->rank;\n  tmpCommAndChans.comm.nRanks = nRanks;\n  tmpCommAndChans.comm.node = comm->node;\n  tmpCommAndChans.comm.nNodes = comm->nNodes;\n  tmpCommAndChans.comm.abortFlag = comm->abortFlag;\n  for (int p=0; p < NCCL_NUM_PROTOCOLS; p++) {\n    tmpCommAndChans.comm.buffSizes[p] = comm->buffSizes[p];\n  }\n  tmpCommAndChans.comm.p2pChunkSize = comm->p2pChunkSize;\n  tmpCommAndChans.comm.channels = &devCommAndChans->channels[0];\n\n  comm->workFifoDepth = ncclParamWorkFifoDepth();\n  if (0 != (comm->workFifoDepth & (comm->workFifoDepth-1))) {\n    WARN(\"NCCL_WORK_FIFO_DEPTH=%d is being ignored because it is not a power of 2.\", comm->workFifoDepth);\n    comm->workFifoDepth = 64<<10;\n  }\n  tmpCommAndChans.comm.workFifoDepth = comm->workFifoDepth;\n\n  if (ncclGdrCopy != NULL && ncclParamGdrCopyFifoEnable() == 1) {\n    // The workFifoHeap lives in GDR mapped CUDA memory.\n    NCCLCHECKGOTO(ncclGdrCudaCalloc(&comm->workFifoHeap, &comm->devWorkFifoHeap, comm->workFifoDepth, &comm->workFifoHeapGdrHandle), ret, fail);\n    ncclCommPushCudaGdrFree(comm, comm->workFifoHeapGdrHandle);\n  } else {\n    // The workFifoHeap lives in cudaHost memory.\n    comm->workFifoHeapGdrHandle = nullptr;\n    NCCLCHECKGOTO(ncclCudaHostCalloc(&comm->workFifoHeap, comm->workFifoDepth), ret, fail);\n    ncclCommPushCudaHostFree(comm, comm->workFifoHeap);\n    comm->devWorkFifoHeap = comm->workFifoHeap;\n  }\n  tmpCommAndChans.comm.workFifoHeap = comm->devWorkFifoHeap;\n\n  NCCLCHECKGOTO(ncclCudaHostCalloc(&comm->workFifoDone, MAXCHANNELS), ret, fail);\n  ncclCommPushCudaHostFree(comm, comm->workFifoDone);\n  comm->workFifoSent = 0;\n  comm->workFifoAckdMin = 0;\n\n  if (comm->collNetDenseToUserRank != nullptr) {\n    NCCLCHECKGOTO(ncclCudaCallocAsync(&tmpCommAndChans.comm.collNetDenseToUserRank, nRanks, comm->sharedRes->deviceStream.cudaStream), ret, fail);\n    ncclCommPushCudaFree(comm, tmpCommAndChans.comm.collNetDenseToUserRank);\n    NCCLCHECKGOTO(ncclCudaMemcpyAsync(tmpCommAndChans.comm.collNetDenseToUserRank, comm->collNetDenseToUserRank, nRanks, comm->sharedRes->deviceStream.cudaStream), ret, fail);\n  }\n\n  for (int c=0; c < MAXCHANNELS; c++) {\n    tmpCommAndChans.channels[c].peers = comm->channels[c].devPeers;\n    tmpCommAndChans.channels[c].ring = comm->channels[c].ring;\n    tmpCommAndChans.channels[c].ring.userRanks = comm->channels[c].devRingUserRanks;\n    tmpCommAndChans.channels[c].tree = comm->channels[c].tree;\n    tmpCommAndChans.channels[c].collnetChain = comm->channels[c].collnetChain;\n    tmpCommAndChans.channels[c].collnetDirect = comm->channels[c].collnetDirect;\n    tmpCommAndChans.channels[c].nvls = comm->channels[c].nvls;\n    tmpCommAndChans.channels[c].workFifoDone = &comm->workFifoDone[c];\n\n    if (comm->channels[c].ring.userRanks != nullptr) {\n      NCCLCHECKGOTO(ncclCudaMemcpyAsync(tmpCommAndChans.channels[c].ring.userRanks, comm->channels[c].ring.userRanks, nRanks, comm->sharedRes->deviceStream.cudaStream), ret, fail);\n    }\n  }\n\n  NCCLCHECKGOTO(ncclCudaMemcpyAsync(devCommAndChans, &tmpCommAndChans, 1, comm->sharedRes->deviceStream.cudaStream), ret, fail);\nexit:\n  NCCLCHECK(ncclStrongStreamSynchronize(&comm->sharedRes->deviceStream));\n  NCCLCHECK(ncclStrongStreamRelease(ncclCudaGraphNone(), &comm->sharedRes->deviceStream));\n  return ret;\nfail:\n  goto exit;\n}\n\n// Pre-process the string so that running \"strings\" on the lib can quickly reveal the version.\n#define VERSION_STRING \"NCCL version \" STR(NCCL_MAJOR) \".\" STR(NCCL_MINOR) \".\" STR(NCCL_PATCH) NCCL_SUFFIX \"+cuda\" STR(CUDA_MAJOR) \".\" STR(CUDA_MINOR)\nstatic void showVersion() {\n  static int shown = 0;\n  if (shown == 0 && ncclDebugLevel >= NCCL_LOG_VERSION) {\n    printf(\"%s\\n\", VERSION_STRING);\n    fflush(stdout);\n    if (ncclDebugFile != stdout)\n      INFO(NCCL_ALL,\"%s\", VERSION_STRING); // Also log NCCL version in one of the files\n    shown = 1;\n  }\n}\n\nstatic ncclResult_t fillInfo(struct ncclComm* comm, struct ncclPeerInfo* info, uint64_t commHash) {\n  info->rank = comm->rank;\n  info->cudaDev = comm->cudaDev;\n  info->nvmlDev = comm->nvmlDev;\n  info->hostHash=getHostHash()+commHash;\n  info->pidHash=getPidHash()+commHash;\n\n  // Get the device MAJOR:MINOR of /dev/shm so we can use that\n  // information to decide whether we can use SHM for inter-process\n  // communication in a container environment\n  struct stat statbuf;\n  SYSCHECK(stat(\"/dev/shm\", &statbuf), \"stat\");\n  info->shmDev = statbuf.st_dev;\n\n  info->busId = comm->busId;\n\n  NCCLCHECK(ncclGpuGdrSupport(comm, &info->gdrSupport));\n  info->comm = comm;\n  info->cudaCompCap = comm->minCompCap = comm->maxCompCap = comm->compCap;\n\n  // MNNVL support\n  {\n    // MNNVL: Request the fabric UUID and partition info\n    char busId[NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE];\n    nvmlDevice_t nvmlDev;\n    NCCLCHECK(int64ToBusId(info->busId, busId));\n    NCCLCHECK(ncclNvmlDeviceGetHandleByPciBusId(busId, &nvmlDev));\n    info->fabricInfo.state = NVML_GPU_FABRIC_STATE_NOT_SUPPORTED;\n    (void) ncclNvmlDeviceGetGpuFabricInfoV(nvmlDev, &info->fabricInfo);\n    if (info->fabricInfo.state != NVML_GPU_FABRIC_STATE_NOT_SUPPORTED) {\n      INFO(NCCL_INIT, \"MNNVL busId 0x%lx fabric UUID %lx.%lx cliqueId 0x%x state %d healthMask 0x%x\",\n           info->busId,\n           ((long *)&info->fabricInfo.clusterUuid)[0], ((long *)&info->fabricInfo.clusterUuid)[1],\n           info->fabricInfo.cliqueId, info->fabricInfo.state, info->fabricInfo.healthMask);\n    }\n  }\n\n  return ncclSuccess;\n}\n\nstatic ncclResult_t setupChannel(struct ncclComm* comm, int channelId, int rank, int nranks, int* ringRanks) {\n  TRACE(NCCL_INIT, \"rank %d nranks %d\", rank, nranks);\n  NCCLCHECK(initChannel(comm, channelId));\n\n  struct ncclRing* ring = &comm->channels[channelId].ring;\n  // Find our ring-distance from rank zero and reorganize ranks to start with rank.\n  int ixZero=0, ixRank=0;\n  for (int i=0; i < nranks; i++) {\n    if (ringRanks[i] == 0) ixZero = i;\n    if (ringRanks[i] == rank) ixRank = i;\n  }\n  ring->index = (ixRank-ixZero + nranks)%nranks;\n  for (int i=0; i<nranks; i++) {\n    ring->userRanks[i] = ringRanks[(i+ixRank)%nranks];\n  }\n  return ncclSuccess;\n}\n\n#define DEFAULT_LL_BUFFSIZE (NCCL_LL_LINES_PER_THREAD*NCCL_LL_MAX_NTHREADS*NCCL_STEPS*sizeof(union ncclLLFifoLine))\n#define DEFAULT_LL128_BUFFSIZE (NCCL_LL128_ELEMS_PER_THREAD*NCCL_LL128_MAX_NTHREADS*NCCL_STEPS*sizeof(uint64_t))\n#define DEFAULT_BUFFSIZE (1 << 22) /* 4MiB */\nNCCL_PARAM(BuffSize, \"BUFFSIZE\", -2);\nNCCL_PARAM(LlBuffSize, \"LL_BUFFSIZE\", -2);\nNCCL_PARAM(Ll128BuffSize, \"LL128_BUFFSIZE\", -2);\n\nNCCL_PARAM(P2pNetChunkSize, \"P2P_NET_CHUNKSIZE\", (1 << 17)); /* 128 kB */\nNCCL_PARAM(P2pPciChunkSize, \"P2P_PCI_CHUNKSIZE\", (1 << 17)); /* 128 kB */\nNCCL_PARAM(P2pNvlChunkSize, \"P2P_NVL_CHUNKSIZE\", (1 << 19)); /* 512 kB */\n\nstatic ncclResult_t computeBuffSizes(struct ncclComm* comm) {\n  int cpuArch, cpuVendor, cpuModel;\n  NCCLCHECK(ncclTopoCpuType(comm->topo, &cpuArch, &cpuVendor, &cpuModel));\n\n  int64_t envs[NCCL_NUM_PROTOCOLS] = { ncclParamLlBuffSize(), ncclParamLl128BuffSize(), ncclParamBuffSize() };\n  int defaults[NCCL_NUM_PROTOCOLS] = { DEFAULT_LL_BUFFSIZE, DEFAULT_LL128_BUFFSIZE, DEFAULT_BUFFSIZE };\n\n  for (int p=0; p<NCCL_NUM_PROTOCOLS; p++) {\n    comm->buffSizes[p] = envs[p] != -2 ? envs[p] : defaults[p];\n  }\n\n  if (comm->nNodes > 1) comm->p2pChunkSize = ncclParamP2pNetChunkSize();\n  else if (ncclTopoPathAllNVLink(comm->topo)) comm->p2pChunkSize = ncclParamP2pNvlChunkSize();\n  else comm->p2pChunkSize = ncclParamP2pPciChunkSize();\n\n  // Make sure P2P chunksize is not larger than coll chunksize.\n  if (comm->p2pChunkSize * NCCL_STEPS > comm->buffSizes[NCCL_PROTO_SIMPLE]) comm->p2pChunkSize = comm->buffSizes[NCCL_PROTO_SIMPLE]/NCCL_STEPS;\n\n  if (comm->sharedRes->owner != comm) {\n    /* make sure split comm p2pChunkSize won't exceed shared p2pChunkSize. */\n    comm->p2pChunkSize = std::min(comm->p2pChunkSize, comm->sharedRes->tpP2pChunkSize);\n  } else {\n    comm->sharedRes->tpP2pChunkSize = comm->p2pChunkSize;\n  }\n\n  INFO(NCCL_INIT, \"P2P Chunksize set to %d\", comm->p2pChunkSize);\n  return ncclSuccess;\n}\n\nNCCL_PARAM(GraphDumpFileRank, \"GRAPH_DUMP_FILE_RANK\", 0);\nNCCL_PARAM(CollNetNodeThreshold, \"COLLNET_NODE_THRESHOLD\", 2);\nNCCL_PARAM(NvbPreconnect, \"NVB_PRECONNECT\", 1);\nNCCL_PARAM(AllocP2pNetLLBuffers, \"ALLOC_P2P_NET_LL_BUFFERS\", 0);\n\nstatic ncclResult_t collNetInitRailRankMap(ncclComm_t comm) {\n  int rank = comm->rank;\n  uint64_t nonHeadMask = (1ull << comm->localRanks) - 1;\n\n  comm->collNetDenseToUserRank = ncclMemoryStackAlloc<int>(&comm->memPermanent, comm->nRanks);\n  comm->collNetUserToDenseRank = ncclMemoryStackAlloc<int>(&comm->memPermanent, comm->nRanks);\n  // initialize collNetUserToDenseRank[rank]  \n  comm->collNetUserToDenseRank[rank] = -1;\n  for (int h = 0; h < comm->collNetHeadsNum; h++) {\n    nonHeadMask ^= 1ull << comm->rankToLocalRank[comm->collNetHeads[h]];\n    if (comm->collNetHeads[h] == rank) { comm->collNetUserToDenseRank[rank] = h; break; }\n  }\n  if (comm->collNetUserToDenseRank[rank] == -1) {\n    comm->collNetUserToDenseRank[rank] = __builtin_popcountll(nonHeadMask & ((1ull << comm->localRank) - 1));\n  }\n  comm->collNetUserToDenseRank[rank] += comm->node * comm->localRanks;\n\n  NCCLCHECK(bootstrapAllGather(comm->bootstrap, comm->collNetUserToDenseRank, sizeof(int)));\n  for (int r = 0; r < comm->nRanks; r++) {\n    comm->collNetDenseToUserRank[comm->collNetUserToDenseRank[r]] = r;\n  }\n  return ncclSuccess;\n}\n\nstatic ncclResult_t collNetTrySetup(ncclComm_t comm, ncclComm_t parent, struct ncclTopoGraph* collNetGraph) {\n  ncclResult_t ret = ncclSuccess;\n  int rank = comm->rank;\n  int collNetSetupFail = 0;\n  int highestTypes[NCCL_MAX_LOCAL_RANKS] = { TRANSPORT_P2P };\n  // Find all head ranks\n  int nHeadsUnique = 0;\n  int* headsUnique = NULL;\n  int highestTransportType0, highestTransportType1;\n  char line[1024];\n  bool share;\n\n  struct collnetShareInfo {\n    int headPosition;\n    int isMaster;\n  };\n  struct collnetShareInfo* infos = NULL;\n\n  NCCLCHECKGOTO(ncclCalloc(&headsUnique, collNetGraph->nChannels), ret, fail);\n  { uint64_t mask = 0;\n    // Head GPU index is always 0\n    for (int c = 0; c < collNetGraph->nChannels; c++) {\n      int head = collNetGraph->intra[c * comm->localRanks + 0];\n      assert(comm->rankToNode[head] == comm->node);\n      uint64_t mask0 = mask;\n      mask |= 1ull<<comm->rankToLocalRank[head];\n      if (mask != mask0) headsUnique[nHeadsUnique++] = head;\n    }\n  }\n\n  comm->collNetHeads = headsUnique;\n  comm->collNetHeadsNum = nHeadsUnique;\n  if (parent && parent->collNetSupport && parent->config.splitShare && parent->nNodes == comm->nNodes) {\n    NCCLCHECKGOTO(ncclCalloc(&infos, comm->nRanks), ret, fail);\n    /* check whether child can share collnet resources of parent. Since parent builds each collnet communicator\n     * based on heads with the same head position in each node, as long as the collnet heads of child comm\n     * can match parent's heads, we can let child communicator share parent's collnet resources. */\n    for (int h = 0; h < nHeadsUnique; ++h) {\n      int prev = INT_MIN;\n      struct collnetShareInfo* myinfo;\n\n      share = true;\n      myinfo = infos + comm->rank;\n      memset(myinfo, 0, sizeof(struct collnetShareInfo));\n      /* find the child head position in parent collnet heads. */\n      if (headsUnique[h] == comm->rank) {\n        myinfo->headPosition = -1;\n        myinfo->isMaster = 1;\n        for (int th = 0; th < parent->collNetHeadsNum; ++th)\n          if (parent->topParentRanks[parent->collNetHeads[th]] == comm->topParentRanks[comm->rank]) {\n            myinfo->headPosition = th;\n            break;\n          }\n      }\n\n      NCCLCHECKGOTO(bootstrapAllGather(comm->bootstrap, infos, sizeof(struct collnetShareInfo)), ret, fail);\n      for (int i = 0; i < comm->nRanks; ++i) {\n        if (infos[i].isMaster) {\n          if (prev == INT_MIN)\n            prev = infos[i].headPosition;\n\n          if (infos[i].headPosition == -1 || prev != infos[i].headPosition) {\n            share = false;\n            break;\n          }\n        }\n      }\n\n      if (share) {\n        if (myinfo->isMaster) {\n          comm->collNetSharedRes = parent->collNetSharedRes;\n          for (int c = 0; c < comm->nChannels; ++c)\n            NCCLCHECKGOTO(initCollnetChannel(comm, c, parent, true), ret, fail);\n        }\n\n        NCCLCHECKGOTO(collNetInitRailRankMap(comm), ret, fail);\n      } else {\n        /* TODO: CX-6 and CX-7 both do not support multiple sharp resources per process, if child comm cannot\n         * share the sharp resource from parent, we cannot use sharp in this case. This restriction might be\n         * lifted by sharp plugin/IB hardware in the future. */\n        collNetSetupFail = 1;\n        if (comm->rank == 0) {\n          WARN(\"Child comms (nRanks %d) fails to share parent comms (nRanks %d) sharp resources\", comm->nRanks, parent->nRanks);\n        }\n        goto fail;\n      }\n    }\n    share = true;\n  } else {\n    /* this allocated buffer will be freed on proxy side */\n    NCCLCHECK(ncclCalloc(&comm->collNetSharedRes, 1));\n    comm->collNetSharedRes->nChannels = comm->nChannels;\n    comm->collNetSharedRes->buffSize = comm->buffSizes[NCCL_PROTO_SIMPLE];\n\n    NCCLCHECKGOTO(collNetInitRailRankMap(comm), ret, fail);\n\n    for (int c = 0; c < comm->nChannels; c++) {\n      struct ncclChannel* channel = comm->channels + c;\n      NCCLCHECKGOTO(initCollnetChannel(comm, c, parent, false), ret, fail);\n      for (int h = 0; h < nHeadsUnique; h++) {\n        const int head = headsUnique[h];\n        ncclConnect connect;\n        collNetSetupFail |= ncclTransportCollNetSetup(comm, collNetGraph, channel, head, head, h, collNetRecv, &connect);\n        if (!collNetSetupFail) collNetSetupFail |= ncclTransportCollNetSetup(comm, collNetGraph, channel, head, head, h, collNetSend, &connect);\n      }\n      // Verify CollNet setup across ranks after trying the first channel\n      if (c == 0) {\n        NCCLCHECKGOTO(ncclTransportCollNetCheck(comm, collNetSetupFail), ret, fail);\n      }\n    }\n    share = false;\n  }\n\n  if (share) {\n    memcpy(comm->collNetSupportMatrix, parent->collNetSupportMatrix, sizeof(comm->collNetSupportMatrix));\n  } else {\n    do {\n      /* Initialize all entries in collNetSupportMatrix[redop][type]. Since some\n      ranks don't connect to sharp we enable a (redop,type) if any rank claims\n      support. */\n      const ncclRedOp_t redops[] = {ncclSum, ncclProd, ncclMin, ncclMax};\n      uint8_t(*matrix)[4][ncclNumTypes];\n      bool isHead = false;\n      matrix = nullptr;\n      NCCLCHECKGOTO(ncclCalloc(&matrix, comm->nRanks), ret, matrix_end);\n      for (int h = 0; h < nHeadsUnique; h++) isHead |= (headsUnique[h] == comm->rank);\n      if (isHead) {\n        for (int ty=0; ty < ncclNumTypes; ty++) {\n          for (int i=0; i < 4; i++) {\n            int support = 0;\n            NCCLCHECKGOTO(collNetReduceSupport(comm, (ncclDataType_t)ty, redops[i], &support), ret, matrix_end);\n            // bit 0 = not supported, bit 1 = supported\n            matrix[rank][redops[i]][ty] = 1<<(support ? 1 : 0);\n          }\n        }\n      }\n      NCCLCHECKGOTO(bootstrapAllGather(comm->bootstrap, matrix, sizeof(*matrix)), ret, matrix_end);\n      for (int ty=0; ty < ncclNumTypes; ty++) {\n        for (int i=0; i < 4; i++) {\n          int op = redops[i];\n          uint8_t accum = 0;\n          for (int r=0; r < comm->nRanks; r++) accum |= matrix[r][op][ty];\n          // We support (redop, type) if some rank supports it and no rank doesn't support it\n          comm->collNetSupportMatrix[op][ty] = (accum == (1<<1));\n        }\n      }\n    matrix_end:\n      free(matrix);\n      if (ret != ncclSuccess) goto fail;\n    } while (0);\n  }\n\n  // Verify CollNet setup across ranks after trying all channels\n  NCCLCHECKGOTO(ncclTransportCollNetCheck(comm, collNetSetupFail), ret, fail);\n  TRACE(NCCL_INIT, \"rank %d Connected inter-node CollNet\", rank);\n\n  line[0] = '\\0';\n  for (int c = 0; c < comm->nChannels; c++) {\n    struct ncclTree* chain = &comm->channels[c].collnetChain;\n    snprintf(line + strlen(line), 1023 - strlen(line), \" [%d] %d->%d->%d\",\n      c, chain->down[0], rank, chain->up);\n  }\n  line[1023] = '\\0';\n\n  INFO(NCCL_INIT, \"Collnet Chains %s\", line);\n  // Connect Collnet + chain\n  for (int c = 0; c < comm->nChannels; c++) {\n    struct ncclChannel* channel = comm->channels + c;\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, &channel->collnetChain.up, 1, channel->collnetChain.down, 0), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, collNetGraph, 0), ret, fail);\n  for (int c = 0; c < comm->nChannels; c++) {\n    struct ncclChannel* channel = comm->channels + c;\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, channel->collnetChain.down, 1, &channel->collnetChain.up, 1), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, collNetGraph, 1), ret, fail);\n  INFO(NCCL_INIT, \"Connected collnet + chain\");\n\n  // Connect intra-node CollNet + Direct\n  for (int c = 0; c < comm->nChannels; c++) {\n    struct ncclChannel* channelRecv = comm->channels + c;\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, NCCL_MAX_DIRECT_ARITY, channelRecv->collnetDirect.up, NCCL_MAX_DIRECT_ARITY, channelRecv->collnetDirect.down, 0), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, collNetGraph, 0, &highestTransportType0), ret, fail);\n\n  for (int c = 0; c < comm->nChannels; c++) {\n    struct ncclChannel* channelSend = comm->channels + c;\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, NCCL_MAX_DIRECT_ARITY, channelSend->collnetDirect.down, NCCL_MAX_DIRECT_ARITY, channelSend->collnetDirect.up, 1), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, collNetGraph, 1, &highestTransportType1), ret, fail);\n\n  // Exchange highest intra-node transport type among ranks\n  // because we need to know whether all ranks can p2p each other to determine whether we can directly read/write registered user buffer\n  comm->intraHighestTransportType = highestTypes[comm->localRank] = highestTransportType0 > highestTransportType1 ? highestTransportType0 : highestTransportType1;\n  if (share) {\n    comm->intraHighestTransportType = std::max(comm->intraHighestTransportType, parent->intraHighestTransportType);\n  }\n  NCCLCHECKGOTO(bootstrapIntraNodeAllGather(comm->bootstrap, comm->localRankToRank, comm->localRank, comm->localRanks, highestTypes, sizeof(int)), ret, fail);\n  for (int i = 0; i < comm->localRanks; i++) {\n    if (highestTypes[i] > comm->intraHighestTransportType)\n      comm->intraHighestTransportType = highestTypes[i];\n  }\n\n  INFO(NCCL_INIT, \"rank %d Connected CollNet\", rank);\n\nexit:\n  free(infos);\n  return ret;\nfail:\n  ncclTransportCollNetFree(comm);\n  comm->collNetSupport = 0;\n  goto exit;\n}\n\n// MNNVL: Flag to indicate whether to enable Multi-Node NVLink\nNCCL_PARAM(MNNVLEnable, \"MNNVL_ENABLE\", 2);\n\n#if CUDART_VERSION >= 11030\n\n#include <cuda.h>\n#include \"cudawrap.h\"\n\n// Determine if MNNVL support is available\nstatic int checkMNNVL(struct ncclComm* comm) {\n  ncclResult_t ret = ncclSuccess;\n\n  // MNNVL requires cuMem to be enabled\n  if (!ncclCuMemEnable()) return 0;\n\n  // MNNVL also requires FABRIC handle support\n  int cudaDev;\n  int flag = 0;\n  CUdevice currentDev;\n  CUDACHECK(cudaGetDevice(&cudaDev));\n  CUCHECK(cuDeviceGet(&currentDev, cudaDev));\n  // Ignore error if CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_FABRIC_SUPPORTED is not supported\n  (void) CUPFN(cuDeviceGetAttribute(&flag, CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_FABRIC_SUPPORTED, currentDev));;\n  if (!flag) return 0;\n  // Check that all ranks have initialized the fabric fully\n  for (int i = 0; i < comm->nRanks; i++) {\n    if (comm->peerInfo[i].fabricInfo.state != NVML_GPU_FABRIC_STATE_COMPLETED) return 0;\n  }\n\n  // Determine our MNNVL domain/clique\n  NCCLCHECKGOTO(ncclCalloc(&comm->clique.ranks, comm->nRanks), ret, fail);\n  comm->clique.id = comm->peerInfo[comm->rank].fabricInfo.cliqueId;\n  for (int i = 0; i < comm->nRanks; i++) {\n    nvmlGpuFabricInfoV_t *fabricInfo1 = &comm->peerInfo[comm->rank].fabricInfo;\n    nvmlGpuFabricInfoV_t *fabricInfo2 = &comm->peerInfo[i].fabricInfo;\n    // Check if the cluster UUID and cliqueId match\n    // A zero UUID means we don't have MNNVL fabric info - disable MNNVL\n    if ((((long *)&fabricInfo2->clusterUuid)[0]|((long *)fabricInfo2->clusterUuid)[1]) == 0) goto fail;\n    if ((memcmp(fabricInfo1->clusterUuid, fabricInfo2->clusterUuid, NVML_GPU_FABRIC_UUID_LEN) == 0) &&\n        (fabricInfo1->cliqueId == fabricInfo2->cliqueId)) {\n      if (i == comm->rank) {\n        comm->cliqueRank = comm->clique.size;\n      }\n      comm->clique.ranks[comm->clique.size++] = i;\n    }\n  }\n  // Determine whether to enable MNNVL or not\n  comm->MNNVL = ncclParamMNNVLEnable() == 2 ? comm->clique.size > 1 : ncclParamMNNVLEnable();\n  INFO(NCCL_INIT, \"MNNVL %d cliqueId %x cliqueSize %d cliqueRank %d \", comm->MNNVL, comm->clique.id, comm->clique.size, comm->cliqueRank);\n\n  if (comm->MNNVL) {\n    // Force the CUMEM handle type to be FABRIC for MNNVL\n    ncclCuMemHandleType = CU_MEM_HANDLE_TYPE_FABRIC;\n  }\n\n  return comm->MNNVL;\n\nfail:\n  if (comm->clique.ranks) free(comm->clique.ranks);\n  return 0;\n}\n\n#else\nstatic int checkMNNVL(struct ncclComm* comm) {\n  return 0;\n}\n#endif\n\nstatic ncclResult_t initTransportsRank(struct ncclComm* comm, struct ncclComm* parent = NULL) {\n  // We use 2 AllGathers\n  // 1. { peerInfo, comm, compCap}\n  // 2. { nChannels, graphInfo, topoRanks }\n  ncclResult_t ret = ncclSuccess;\n  int rank = comm->rank;\n  int nranks = comm->nRanks;\n  int nNodes = 1;\n  cpu_set_t affinitySave;\n  struct ncclTopoGraph ringGraph;\n  struct ncclTopoGraph treeGraph;\n  struct ncclTopoGraph collNetGraph;\n  struct ncclTopoGraph nvlsGraph;\n  struct ncclTopoGraph* graphs[] = { &treeGraph, &ringGraph, &collNetGraph, &collNetGraph, &nvlsGraph, &nvlsGraph };\n\n  struct graphInfo {\n    int pattern;\n    int nChannels;\n    int sameChannels;\n    float bwIntra;\n    float bwInter;\n    int typeIntra;\n    int typeInter;\n    int crossNic;\n  };\n\n  struct allGatherInfo {\n    struct graphInfo graphInfo[NCCL_NUM_ALGORITHMS];\n    struct ncclTopoRanks topoRanks;\n  };\n\n  int nChannelsOrig;\n  struct allGatherInfo *allGather3Data = NULL;\n  struct ncclTopoRanks** allTopoRanks = NULL;\n  int *nodesFirstRank = NULL, *nodesTreePatterns = NULL;\n  int *rings = NULL;\n  int* nvbPeers = NULL;\n  struct ncclProxyConnector proxyConn;\n  int* pxnPeers = NULL;\n  int *topParentLocalRanks = NULL;\n  int tpProxyRank;\n\n  // AllGather1 - begin\n  NCCLCHECKGOTO(ncclCalloc(&comm->peerInfo, nranks+1), ret, fail); // Extra rank to represent CollNet root\n  NCCLCHECKGOTO(fillInfo(comm, comm->peerInfo+rank, comm->commHash), ret, fail);\n  NCCLCHECKGOTO(bootstrapAllGather(comm->bootstrap, comm->peerInfo, sizeof(struct ncclPeerInfo)), ret, fail);\n\n  for (int i = 0; i < nranks; i++) {\n    if (comm->peerInfo[i].hostHash != comm->peerInfo[rank].hostHash) nNodes++;\n    if ((i != rank) && (comm->peerInfo[i].hostHash == comm->peerInfo[rank].hostHash) && (comm->peerInfo[i].busId == comm->peerInfo[rank].busId)) {\n      WARN(\"Duplicate GPU detected : rank %d and rank %d both on CUDA device %lx\", rank, i, comm->peerInfo[rank].busId);\n      ret = ncclInvalidUsage;\n      goto fail;\n    }\n  }\n  // AllGather1 - end\n\n  // MNNVL support\n  if (nNodes > 1 && !checkMNNVL(comm) && ncclParamMNNVLEnable() == 1) {\n    // Return an error if the user specifically requested MNNVL support\n    WARN(\"MNNVL is not supported on this system\");\n    ret = ncclSystemError;\n    goto fail;\n  }\n\n  do {\n    // Compute intra-process ranks\n    int intraProcRank0 = -1, intraProcRank = -1, intraProcRanks = 0;\n    for (int i = 0; i < nranks; i++) comm->minCompCap = std::min(comm->minCompCap, comm->peerInfo[i].cudaCompCap);\n    for (int i = 0; i < nranks; i++) comm->maxCompCap = std::max(comm->maxCompCap, comm->peerInfo[i].cudaCompCap);\n\n    comm->nvlsRegSupport = 1;\n    for (int i = 0; i < nranks; i++) {\n      if ((comm->peerInfo[i].hostHash == comm->peerInfo[rank].hostHash)\n          && (comm->peerInfo[i].pidHash == comm->peerInfo[rank].pidHash)) {\n        // Rank is in same process\n        if (intraProcRanks == 0) intraProcRank0 = i;\n        if (i == rank) intraProcRank = intraProcRanks;\n        intraProcRanks++;\n        if (intraProcRank0 == rank && rank != i) {\n          comm->peerInfo[i].comm->intraNext = comm->intraNext;\n          comm->intraNext = comm->peerInfo[i].comm;\n        }\n      }\n\n      if (comm->nvlsRegSupport) {\n        for (int j = i + 1; j < nranks; j++) {\n          if (comm->peerInfo[i].hostHash == comm->peerInfo[j].hostHash &&\n            comm->peerInfo[i].pidHash == comm->peerInfo[j].pidHash) {\n            comm->nvlsRegSupport = 0;\n            break;\n          }\n        }\n      }\n    }\n\n    // Buffer Registration is not supported with MNNVL\n    if (comm->MNNVL) comm->nvlsRegSupport = 0;\n\n    TRACE(NCCL_INIT,\"pidHash[%d] %lx intraProcRank %d intraProcRanks %d intraProcRank0 %d\",\n        rank, comm->peerInfo[rank].pidHash, intraProcRank, intraProcRanks, intraProcRank0);\n    if (intraProcRank == -1 || intraProcRank0 == -1 || comm->peerInfo[intraProcRank0].comm == NULL) {\n      WARN(\"Failed to determine intra proc ranks rank %d hostHash %lx pidHash %lx intraProcRank %d intraProcRanks %d intraProcRank0 %d\",\n          rank, comm->peerInfo[rank].hostHash, comm->peerInfo[rank].pidHash,\n          intraProcRank, intraProcRanks, intraProcRank0);\n      ret = ncclInternalError;\n      goto fail;\n    }\n    struct ncclComm* comm0 = comm->peerInfo[intraProcRank0].comm;\n    assert(intraProcRank==0 ? comm==comm0 : true);\n    comm->intraComm0 = comm0;\n    comm->intraRank = intraProcRank;\n    comm->intraRanks = intraProcRanks;\n    comm->intraBarrierPhase = 0;\n    comm->intraBarrierCounter = 0;\n    comm->intraBarrierGate = 0;\n  } while(0);\n\n  // Topo detection / System graph creation\n  NCCLCHECKGOTO(ncclTopoGetSystem(comm, &comm->topo), ret, fail);\n  // Compute paths between GPUs and NICs\n  NCCLCHECKGOTO(ncclTopoComputePaths(comm->topo, comm), ret, fail);\n  // Remove inaccessible GPUs and unused NICs\n  NCCLCHECKGOTO(ncclTopoTrimSystem(comm->topo, comm), ret, fail);\n  // Recompute paths after trimming\n  NCCLCHECKGOTO(ncclTopoComputePaths(comm->topo, comm), ret, fail);\n  // Init search\n  NCCLCHECKGOTO(ncclTopoSearchInit(comm->topo), ret, fail);\n  // Print final topology\n  NCCLCHECKGOTO(ncclTopoPrint(comm->topo), ret, fail);\n\n  // Set Affinity to a CPU local the our GPU, so that all memory we allocate\n  // on the host is local.\n  NCCLCHECKGOTO(ncclTopoGetCpuAffinity(comm->topo, comm->rank, &comm->cpuAffinity), ret, fail);\n  if (CPU_COUNT(&comm->cpuAffinity)) {\n    sched_getaffinity(0, sizeof(cpu_set_t), &affinitySave);\n    sched_setaffinity(0, sizeof(cpu_set_t), &comm->cpuAffinity);\n  }\n\n  // Determine local CollNet support\n  if (collNetSupport(comm)) {\n    const char *collNetEnable = ncclGetEnv(\"NCCL_COLLNET_ENABLE\");\n    if (collNetEnable != NULL) {\n      INFO(NCCL_ALL, \"NCCL_COLLNET_ENABLE set by environment to %s.\", collNetEnable);\n      if (strcmp(collNetEnable, \"1\") == 0) {\n        comm->collNetSupport = 1;\n      }\n    }\n  }\n\n  // Determine local Nvls support\n  NCCLCHECK(ncclNvlsInit(comm));\n\n  // Get rings and trees\n  memset(&ringGraph, 0, sizeof(struct ncclTopoGraph));\n  ringGraph.id = 0;\n  ringGraph.pattern = NCCL_TOPO_PATTERN_RING;\n  ringGraph.minChannels = 1;\n  ringGraph.maxChannels = MAXCHANNELS/2;\n  NCCLCHECKGOTO(ncclTopoCompute(comm->topo, &ringGraph), ret, fail);\n  NCCLCHECKGOTO(ncclTopoPrintGraph(comm->topo, &ringGraph), ret, fail);\n\n  memset(&treeGraph, 0, sizeof(struct ncclTopoGraph));\n  treeGraph.id = 1;\n  treeGraph.pattern = NCCL_TOPO_PATTERN_BALANCED_TREE;\n  treeGraph.minChannels = ringGraph.nChannels;\n  treeGraph.maxChannels = ringGraph.nChannels;\n  NCCLCHECKGOTO(ncclTopoCompute(comm->topo, &treeGraph), ret, fail);\n  NCCLCHECKGOTO(ncclTopoPrintGraph(comm->topo, &treeGraph), ret, fail);\n\n  memset(&collNetGraph, 0, sizeof(struct ncclTopoGraph));\n  collNetGraph.id = 2;\n  collNetGraph.pattern = NCCL_TOPO_PATTERN_TREE;\n  collNetGraph.collNet = 1;\n  collNetGraph.minChannels = collNetGraph.maxChannels = ringGraph.nChannels;\n  if (comm->collNetSupport) {\n    NCCLCHECKGOTO(ncclTopoCompute(comm->topo, &collNetGraph), ret, fail);\n    NCCLCHECKGOTO(ncclTopoPrintGraph(comm->topo, &collNetGraph), ret, fail);\n  }\n\n  memset(&nvlsGraph, 0, sizeof(struct ncclTopoGraph));\n  nvlsGraph.id = 3;\n  nvlsGraph.pattern = NCCL_TOPO_PATTERN_NVLS;\n  nvlsGraph.minChannels = 1;\n  nvlsGraph.maxChannels = MAXCHANNELS;\n  if (comm->nvlsSupport) {\n    NCCLCHECKGOTO(ncclTopoCompute(comm->topo, &nvlsGraph), ret, fail);\n    NCCLCHECKGOTO(ncclTopoPrintGraph(comm->topo, &nvlsGraph), ret, fail);\n  }\n\n  // Initialize num P2P LL buffers for this communicator\n  comm->allocP2pNetLLBuffers = ncclParamAllocP2pNetLLBuffers() == 1;\n\n  if (comm->rank == ncclParamGraphDumpFileRank()) {\n    struct ncclTopoGraph* dumpGraphs[4] = { &ringGraph, &treeGraph, &collNetGraph, &nvlsGraph };\n    NCCLCHECKGOTO(ncclTopoDumpGraphs(comm->topo, 4, dumpGraphs), ret, fail);\n  }\n\n  // AllGather3 - begin\n  NCCLCHECKGOTO(ncclCalloc(&allGather3Data, nranks), ret, fail);\n\n  for (int a=0; a<NCCL_NUM_ALGORITHMS; a++) {\n    allGather3Data[rank].graphInfo[a].pattern = graphs[a]->pattern;\n    allGather3Data[rank].graphInfo[a].nChannels = graphs[a]->nChannels;\n    allGather3Data[rank].graphInfo[a].sameChannels = graphs[a]->sameChannels;\n    allGather3Data[rank].graphInfo[a].bwIntra = graphs[a]->bwIntra;\n    allGather3Data[rank].graphInfo[a].bwInter = graphs[a]->bwInter;\n    allGather3Data[rank].graphInfo[a].typeIntra = graphs[a]->typeIntra;\n    allGather3Data[rank].graphInfo[a].typeInter = graphs[a]->typeInter;\n    allGather3Data[rank].graphInfo[a].crossNic = graphs[a]->crossNic;\n  }\n\n  comm->nChannels = std::min(treeGraph.nChannels, ringGraph.nChannels);\n  NCCLCHECKGOTO(ncclTopoPreset(comm, graphs, &allGather3Data[rank].topoRanks), ret, fail);\n\n  NCCLCHECKGOTO(bootstrapAllGather(comm->bootstrap, allGather3Data, sizeof(*allGather3Data)), ret, fail);\n\n  // Determine nNodes, firstRanks, ...\n  NCCLCHECKGOTO(ncclCalloc(&nodesFirstRank, nranks), ret, fail);\n  NCCLCHECKGOTO(ncclCalloc(&nodesTreePatterns, nranks), ret, fail);\n  NCCLCHECKGOTO(ncclCalloc(&comm->rankToNode, comm->nRanks), ret, fail);\n  for (int r=0; r<nranks; r++) {\n    int node;\n    int firstRank = allGather3Data[r].topoRanks.ringRecv[0];\n    for (node=0; node<comm->nNodes && nodesFirstRank[node] != firstRank; node++);\n    if (node == comm->nNodes) {\n      comm->nNodes++;\n      nodesFirstRank[node] = firstRank;\n      // Record tree pattern of each node as they can be different depending on sm arch\n      nodesTreePatterns[node] = allGather3Data[r].graphInfo[NCCL_ALGO_TREE].pattern;\n    }\n    comm->rankToNode[r] = node;\n  }\n  // Now that we know nNodes, alloc nodeRanks and compute localRanks for each node\n  NCCLCHECKGOTO(ncclCalloc(&comm->nodeRanks, comm->nNodes), ret, fail);\n  NCCLCHECKGOTO(ncclCalloc(&comm->rankToLocalRank, comm->nRanks), ret, fail);\n  for (int r=0; r<comm->nRanks; r++) {\n    int node = comm->rankToNode[r];\n    comm->rankToLocalRank[r] = comm->nodeRanks[node].localRanks;\n    comm->nodeRanks[node].localRanks++;\n  }\n  // Allocate ranks arrays for each node\n  for (int n=0; n<comm->nNodes; n++) {\n    NCCLCHECKGOTO(ncclCalloc(&comm->nodeRanks[n].localRankToRank, comm->nodeRanks[n].localRanks), ret, fail);\n    comm->maxLocalRanks = std::max(comm->maxLocalRanks, comm->nodeRanks[n].localRanks);\n    comm->nodeRanks[n].localRanks = 0;\n  }\n  // And fill the ranks arrays\n  for (int r=0; r<comm->nRanks; r++) {\n    int node = comm->rankToNode[r];\n    comm->nodeRanks[node].localRankToRank[comm->nodeRanks[node].localRanks++] = r;\n  }\n  comm->node = comm->rankToNode[rank];\n  comm->localRankToRank = comm->nodeRanks[comm->node].localRankToRank;\n  comm->localRank = comm->rankToLocalRank[rank];\n  comm->localRanks = comm->nodeRanks[comm->node].localRanks;\n\n  TRACE(NCCL_INIT,\"hostHash[%d] %lx localRank %d localRanks %d localRank0 %d\",\n        rank, comm->peerInfo[rank].hostHash, comm->localRank, comm->localRanks, comm->localRankToRank[0]);\n  if (comm->localRank == -1 || comm->localRankToRank[0] == -1 || comm->localRanks == 0) {\n    WARN(\"Failed to determine local ranks rank %d hostHash %lx pidHash %lx localRank %d localRanks %d localRank0 %d\",\n         rank, comm->peerInfo[rank].hostHash, comm->peerInfo[rank].pidHash,\n         comm->localRank, comm->localRanks, comm->localRankToRank[0]);\n    ret = ncclInternalError;\n    goto fail;\n  }\n\n  INFO(NCCL_INIT, \"comm %p rank %d nRanks %d nNodes %d localRanks %d localRank %d MNNVL %d\",\n       comm, rank, comm->nRanks, comm->nNodes, comm->localRanks, comm->localRank, comm->MNNVL);\n\n  nChannelsOrig = comm->nChannels;\n  NCCLCHECKGOTO(ncclCalloc(&allTopoRanks, comm->nRanks), ret, fail);\n  for (int i=0; i<nranks; i++) {\n    allTopoRanks[i] = &allGather3Data[i].topoRanks;\n    // Make sure we align all ranks so that the tuning is consistent across ranks\n    for (int a=0; a<NCCL_NUM_ALGORITHMS; a++) {\n      graphs[a]->nChannels = std::min(allGather3Data[i].graphInfo[a].nChannels, graphs[a]->nChannels);\n      graphs[a]->sameChannels = std::min(allGather3Data[i].graphInfo[a].sameChannels, graphs[a]->sameChannels);\n      graphs[a]->bwIntra = std::min(allGather3Data[i].graphInfo[a].bwIntra, graphs[a]->bwIntra);\n      graphs[a]->bwInter = std::min(allGather3Data[i].graphInfo[a].bwInter, graphs[a]->bwInter);\n      graphs[a]->typeIntra = std::max(allGather3Data[i].graphInfo[a].typeIntra, graphs[a]->typeIntra);\n      graphs[a]->typeInter = std::max(allGather3Data[i].graphInfo[a].typeInter, graphs[a]->typeInter);\n      graphs[a]->crossNic = std::max(allGather3Data[i].graphInfo[a].crossNic, graphs[a]->crossNic);\n    }\n  }\n  if (graphs[NCCL_ALGO_COLLNET_CHAIN]->nChannels == 0) comm->collNetSupport = 0;\n  if (graphs[NCCL_ALGO_NVLS]->nChannels == 0) comm->nvlsSupport = comm->nvlsChannels = 0;\n\n  comm->nChannels = treeGraph.nChannels = ringGraph.nChannels = std::min(treeGraph.nChannels, ringGraph.nChannels);\n  if (comm->nChannels < nChannelsOrig) {\n    // We started duplicating channels during Preset(), so we need to move the\n    // duplicated channels since we have removed some.\n    for (int i=0; i<comm->nChannels; i++) memcpy(comm->channels+comm->nChannels+i, comm->channels+nChannelsOrig+i, sizeof(struct ncclChannel));\n  }\n\n  // Determine CollNet support after all-gather now that we know nNodes and each node localRanks\n  if (comm->collNetSupport == 1) {\n    int collNetNodeThreshold = ncclParamCollNetNodeThreshold();\n    if (comm->nNodes < collNetNodeThreshold) {\n      INFO(NCCL_INIT, \"Communicator has %d nodes which is less than CollNet node threshold %d, disabling CollNet\", comm->nNodes, collNetNodeThreshold);\n      comm->collNetSupport = 0;\n    }\n    comm->collNetRegSupport = true;\n    for (int n=0; n<comm->nNodes; n++) {\n      if (comm->nodeRanks[n].localRanks > NCCL_MAX_DIRECT_ARITY+1) {\n        WARN(\"CollNet currently only supports up to %d GPUs per node, disabling CollNet\", NCCL_MAX_DIRECT_ARITY+1);\n        comm->collNetSupport = 0;\n        break;\n      }\n      if (comm->nodeRanks[n].localRanks > 1) {\n        // As long as there is more than 1 rank on any node, we need to disable collnet reg\n        comm->collNetRegSupport = false;\n      }\n    }\n  }\n\n  NCCLCHECKGOTO(ncclCalloc(&rings, nranks*MAXCHANNELS), ret, fail);\n  NCCLCHECKGOTO(ncclTopoPostset(comm, nodesFirstRank, nodesTreePatterns, allTopoRanks, rings, graphs, parent), ret, fail);\n  // AllGather3 - end\n\n  TRACE(NCCL_INIT, \"rank %d nranks %d - BUILT %d TREES/RINGS\", rank, nranks, comm->nChannels);\n\n  char line[1024];\n  line[0]='\\0';\n  for (int c=0; c<comm->nChannels; c++) {\n    struct ncclTree* tree = &comm->channels[c].tree;\n    snprintf(line+strlen(line), 1023-strlen(line), \" [%d] %d/%d/%d->%d->%d\",\n        c, tree->down[0], tree->down[1], tree->down[2], rank, tree->up);\n    INFO(NCCL_GRAPH, \"Ring %02d : %d -> %d -> %d\", c, comm->channels[c].ring.prev, comm->rank, comm->channels[c].ring.next);\n  }\n  line[1023] = '\\0';\n  INFO(NCCL_INIT, \"Trees%s\", line);\n\n  NCCLCHECKGOTO(computeBuffSizes(comm), ret, fail);\n\n  // Compute nChannels per peer for p2p\n  NCCLCHECKGOTO(ncclTopoComputeP2pChannels(comm), ret, fail);\n\n  /* until now, all info of comm should be known. We can initialize shared resources and\n   * map localRanks to top parent local ranks. NOTE: this shareRes init must be put before\n   * all proxy operations. */\n  if (comm->sharedRes->owner == comm) {\n    comm->sharedRes->tpNLocalRanks = comm->localRanks;\n    comm->sharedRes->magic = comm->magic;\n    comm->sharedRes->tpNChannels = comm->nChannels;\n    comm->sharedRes->tpP2pNChannels = comm->p2pnChannels;\n    memcpy(comm->sharedRes->tpRankToLocalRank, comm->rankToLocalRank, sizeof(int) * comm->nRanks);\n  }\n  NCCLCHECKGOTO(ncclCalloc(&topParentLocalRanks, comm->localRanks), ret, fail);\n  for (int i = 0; i < comm->localRanks; ++i) {\n    int tpRank = comm->topParentRanks[comm->localRankToRank[i]];\n    topParentLocalRanks[i] = comm->sharedRes->tpRankToLocalRank[tpRank];\n  }\n  comm->topParentLocalRanks = topParentLocalRanks;\n\n  // Launch proxy service thread, after this, the proxy calls can be used.\n  if (parent && parent->config.splitShare) {\n    comm->proxyState = parent->sharedRes->proxyState;\n    ncclAtomicRefCountIncrement(&parent->sharedRes->proxyState->refCount);\n  } else {\n    NCCLCHECKGOTO(ncclProxyCreate(comm), ret, fail);\n  }\n\n  // Connect with prev/next for each ring\n  for (int c=0; c<comm->nChannels; c++) {\n    struct ncclChannel* channel = comm->channels+c;\n    NCCLCHECKGOTO(setupChannel(comm, c, rank, nranks, rings+c*nranks), ret, fail);\n    if (comm->nRanks == 1) continue;\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, &channel->ring.prev, 1, &channel->ring.next, 0), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, &ringGraph, 0), ret, fail);\n  INFO(NCCL_INIT, \"Connected all rings\");\n\n  // Connect Trees\n  for (int c=0; c<comm->nChannels; c++) {\n    struct ncclChannel* channel = comm->channels+c;\n    if (comm->nRanks == 1) continue;\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, NCCL_MAX_TREE_ARITY, channel->tree.down, 1, &channel->tree.up, 0), ret, fail);\n    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, &channel->tree.up, NCCL_MAX_TREE_ARITY, channel->tree.down, 0), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, &treeGraph, 0), ret, fail);\n  INFO(NCCL_INIT, \"Connected all trees\");\n\n  // Setup NVLS\n  NCCLCHECKGOTO(ncclNvlsSetup(comm, parent), ret, fail);\n  // And NVLS trees if needed\n  if (comm->nvlsSupport && comm->nNodes > 1) {\n    for (int c=0; c<comm->nChannels; c++) {\n      struct ncclChannel* channel = comm->channels+c;\n      NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, NCCL_MAX_NVLS_TREE_ARITY, channel->nvls.treeDown, 1, &channel->nvls.treeUp, 0), ret, fail);\n      NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, &channel->nvls.treeUp, NCCL_MAX_NVLS_TREE_ARITY, channel->nvls.treeDown, 0), ret, fail);\n    }\n    NCCLCHECKGOTO(ncclTransportP2pSetup(comm, &nvlsGraph, 0), ret, fail);\n    INFO(NCCL_INIT, \"Connected NVLS tree\");\n  }\n\n  // Check if we can setup CollNet\n  if (comm->collNetSupport > 0) collNetTrySetup(comm, parent, &collNetGraph);\n\n  TRACE(NCCL_INIT, \"rank %d nranks %d - CONNECTED %d RINGS AND TREES\", rank, nranks, comm->nChannels);\n\n  // Compute time models for algorithm and protocol combinations\n  NCCLCHECKGOTO(ncclTopoTuneModel(comm, comm->minCompCap, comm->maxCompCap, graphs), ret, fail);\n\n  INFO(NCCL_INIT, \"%d coll channels, %d collnet channels, %d nvls channels, %d p2p channels, %d p2p channels per peer\", comm->nChannels, comm->nChannels, comm->nvlsChannels, comm->p2pnChannels, comm->p2pnChannelsPerPeer);\n\n  do { // Setup p2p structures in comm->tasks\n    struct ncclTasks* tasks = &comm->tasks;\n    int node = comm->node;\n    int nNodes = comm->nNodes;\n    struct ncclNodeRanks *nodeRanks = comm->nodeRanks;\n    int localRank = comm->localRank;\n    // We want to fuse along node boundaries. Make sure nsteps is a multiple or divides 8.\n    int steps = ALIGN_POWER(comm->maxLocalRanks, NCCL_MAX_WORK_ELEMENTS_P2P/2);\n    tasks->p2pOrderSteps = comm->nNodes * steps;\n    tasks->peers = ncclMemoryStackAlloc<ncclTasks::Peer>(&comm->memPermanent, tasks->p2pOrderSteps);\n    tasks->p2pSendOrder = ncclMemoryStackAlloc<int>(&comm->memPermanent, tasks->p2pOrderSteps);\n    tasks->p2pRecvOrder = ncclMemoryStackAlloc<int>(&comm->memPermanent, tasks->p2pOrderSteps);\n    int i=0;\n    // schedule delta 0, +1, -1, +2, -2, ...\n    // also make sure we don't do 0 twice, nor +n/2 and -n/2 if n is even.\n    for (int d=0; d <= nNodes/4; d++) {\n      int deltas[4] = { d, (nNodes-d)%nNodes, nNodes/2-d, (nNodes-(nNodes/2-d))%nNodes };\n      int index = 0;\n      int delta = deltas[index];\n    sched_delta:\n      int recvNode = (node+nNodes-delta)%nNodes;\n      int sendNode = (node+delta)%nNodes;\n      for (int step=0; step < steps; step++) {\n        int recvIndex = (localRank-step+steps)%steps;\n        int recvRank = recvIndex < nodeRanks[recvNode].localRanks ? nodeRanks[recvNode].localRankToRank[recvIndex] : -1;\n        tasks->p2pRecvOrder[i] = recvRank;\n        int sendIndex = (localRank+step)%steps;\n        int sendRank = sendIndex < nodeRanks[sendNode].localRanks ? nodeRanks[sendNode].localRankToRank[sendIndex] : -1;\n        tasks->p2pSendOrder[i] = sendRank;\n        i++;\n      }\n      index++;\n      if (index == 1 && deltas[1] == deltas[0]) index++;\n      if (index == 2 && deltas[2] == deltas[0]) index++;\n      if (index == 3 && deltas[3] == deltas[2]) index++;\n      if (index == 3 && deltas[3] == deltas[1]) index++;\n      if (index < 4) {\n        delta = deltas[index];\n        goto sched_delta;\n      }\n    }\n    assert(i == tasks->p2pOrderSteps);\n  } while (0);\n\n  if (ncclParamNvbPreconnect()) {\n    // Connect p2p when using NVB path\n    int nvbNpeers;\n    NCCLCHECKGOTO(ncclTopoGetNvbGpus(comm->topo, comm->rank, &nvbNpeers, &nvbPeers), ret, fail);\n    for (int r=0; r<nvbNpeers; r++) {\n      int peer = nvbPeers[r];\n      int channelId;\n      for (int c=0; c<comm->p2pnChannelsPerPeer; c++) {\n        NCCLCHECKGOTO(ncclChannelCompute(comm, peer, c, ncclFuncSend, &channelId), ret, fail);\n        if (comm->channels[channelId].peers[peer]->send[1].connected == 0) {\n          comm->connectSend[peer] |= (1UL<<channelId);\n        }\n      }\n      for (int c=0; c<comm->p2pnChannelsPerPeer; c++) {\n        NCCLCHECKGOTO(ncclChannelCompute(comm, peer, c, ncclFuncRecv, &channelId), ret, fail);\n        if (comm->channels[channelId].peers[peer]->recv[1].connected == 0) {\n          comm->connectRecv[peer] |= (1UL<<channelId);\n        }\n      }\n    }\n\n    NCCLCHECKGOTO(ncclTransportP2pSetup(comm, NULL, 1), ret, fail);\n  }\n\n  // Connect to local net proxy\n  tpProxyRank = comm->topParentRanks[comm->rank];\n  NCCLCHECKGOTO(ncclProxyConnect(comm, TRANSPORT_NET, 1, tpProxyRank, &proxyConn), ret, fail);\n  NCCLCHECKGOTO(ncclProxyCallBlocking(comm, &proxyConn, ncclProxyMsgSharedInit, &comm->p2pnChannels, sizeof(int), NULL, 0), ret, fail);\n\n  // Then to remote ones when using PXN\n  if (ncclPxnDisable(comm) == 0) {\n    int nranks;\n    NCCLCHECKGOTO(ncclTopoGetPxnRanks(comm, &pxnPeers, &nranks), ret, fail);\n    for (int r=0; r<nranks; r++) {\n      tpProxyRank = comm->topParentRanks[pxnPeers[r]];\n      NCCLCHECKGOTO(ncclProxyConnect(comm, TRANSPORT_NET, 1, tpProxyRank, &proxyConn), ret, fail);\n      NCCLCHECKGOTO(ncclProxyCallBlocking(comm, &proxyConn, ncclProxyMsgSharedInit, &comm->p2pnChannels, sizeof(int), NULL, 0), ret, fail);\n    }\n  }\n\n  if (comm->intraRank == 0) { // Load ncclParamLaunchMode\n    const char* str = ncclGetEnv(\"NCCL_LAUNCH_MODE\");\n    enum ncclLaunchMode mode, modeOld;\n    if (str && strcasecmp(str, \"GROUP\") == 0) {\n      mode = ncclLaunchModeGroup;\n    } else {\n      mode = ncclLaunchModeParallel;\n    }\n    // In theory we could be racing with other communicators not associated with\n    // this one if the user is connecting to multiple ncclUniqueId's concurrently.\n    modeOld = __atomic_exchange_n(&ncclParamLaunchMode, mode, __ATOMIC_RELAXED);\n    if (modeOld == ncclLaunchModeInvalid && str && str[0]!='\\0') {\n      INFO(NCCL_ENV, \"NCCL_LAUNCH_MODE set by environment to %s\", mode == ncclLaunchModeParallel ? \"PARALLEL\" : \"GROUP\");\n    }\n  }\n\n  // Call devCommSetup before the last barrier, making sure we don't have a thread running in front and starting to\n  // launch NCCL kernels before all cuda mem allocation is complete. That could cause a deadlock.\n  NCCLCHECKGOTO(devCommSetup(comm), ret, fail);\n\n  /* Local intra-node barrier */\n  NCCLCHECKGOTO(bootstrapIntraNodeBarrier(comm->bootstrap, comm->localRankToRank, comm->localRank, comm->localRanks, comm->localRankToRank[0]), ret, fail);\n\n  // We should have allocated all buffers, collective fifos, ... we can\n  // restore the affinity.\n  TRACE(NCCL_INIT, \"rank %d nranks %d - DONE\", rank, nranks);\n\nexit:\n  if (CPU_COUNT(&comm->cpuAffinity)) sched_setaffinity(0, sizeof(cpu_set_t), &affinitySave);\n  /* If split resource is shared, we are not able to unlink the proxy ops pool here since the child comm can\n   * attach the proxy ops pool of parent at any time; otherwise, unlink it here to make sure the pool will be\n   * properly cleaned up. */\n  if (comm->sharedRes->owner == comm && !comm->config.splitShare && ret == ncclSuccess) ncclProxyShmUnlink(comm);\n  free(allTopoRanks);\n  free(nodesTreePatterns);\n  free(nodesFirstRank);\n  free(allGather3Data);\n  free(rings);\n  free(nvbPeers);\n  free(pxnPeers);\n  return ret;\nfail:\n  goto exit;\n}\n\nNCCL_PARAM(SetStackSize, \"SET_STACK_SIZE\", 0);\nNCCL_PARAM(CGAClusterSize, \"CGA_CLUSTER_SIZE\", NCCL_CONFIG_UNDEF_INT);\n// Match config max/minCTAs\nNCCL_PARAM(MaxCTAs, \"MAX_CTAS\", NCCL_CONFIG_UNDEF_INT);\nNCCL_PARAM(MinCTAs, \"MIN_CTAS\", NCCL_CONFIG_UNDEF_INT);\n#define NCCL_MAX_CGA_CLUSTER_SIZE 8\n\nstruct ncclCommInitRankAsyncJob {\n  struct ncclAsyncJob base;\n  struct ncclComm* comm;\n  struct ncclComm** newcomm;\n  int cudaDev;\n  // For ncclCommInitRank\n  int nranks, myrank;\n  ncclUniqueId commId;\n  // for ncclCommSplit\n  struct ncclComm* parent;\n  int color, key;\n};\n\nstruct ncclCommFinalizeAsyncJob {\n  struct ncclAsyncJob base;\n  ncclComm_t comm;\n};\n\nNCCL_PARAM(CommSplitShareResources, \"COMM_SPLIT_SHARE_RESOURCES\", NCCL_CONFIG_UNDEF_INT);\n\nstatic ncclResult_t commGetSplitInfo(struct ncclComm* comm, struct ncclComm* parent, int color, int key, int* nRanksRet, int* myRankRet, int* parentRanksRet) {\n  int* colors = NULL;\n  int* keys = NULL;\n  int nRanks = 0, myRank = 0;\n  ncclResult_t ret = ncclSuccess;\n\n  NCCLCHECKGOTO(ncclCalloc(&colors, parent->nRanks), ret, fail);\n  NCCLCHECKGOTO(ncclCalloc(&keys, parent->nRanks), ret, fail);\n\n  // Compute nRanks, my rank and the ranks (of the original comm) before and after me\n  colors[parent->rank] = color;\n  keys[parent->rank] = key;\n  NCCLCHECKGOTO(bootstrapAllGather(parent->bootstrap, colors, sizeof(int)), ret, fail);\n  NCCLCHECKGOTO(bootstrapAllGather(parent->bootstrap, keys, sizeof(int)), ret, fail);\n\n  // Negative color does not create a new comm. Return now.\n  if (color == NCCL_SPLIT_NOCOLOR) goto exit;\n\n  memset(parentRanksRet, 0xff, sizeof(int) * parent->nRanks);\n  for (int i = 0; i < parent->nRanks; i++) {\n    if (colors[i] != color) continue;\n    // Find where to insert this rank\n    int insert = 0;\n    while (insert < nRanks && keys[parentRanksRet[insert]] <= keys[i]) insert++;\n    // Shift ranks by one after insert\n    for (int r = nRanks; r > insert; r--) parentRanksRet[r] = parentRanksRet[r - 1];\n    // Insert our rank\n    parentRanksRet[insert] = i;\n    nRanks++;\n  }\n\n  for (int i = 0; i < nRanks; i++) {\n    if (parentRanksRet[i] == parent->rank) myRank = i;\n  }\n\n  *nRanksRet = nRanks;\n  *myRankRet = myRank;\n\nexit:\n  free(colors);\n  free(keys);\n  return ret;\nfail:\n  goto exit;\n}\n\nstatic ncclResult_t ncclCommInitRankFunc(struct ncclAsyncJob* job_) {\n  struct ncclCommInitRankAsyncJob* job = (struct ncclCommInitRankAsyncJob*)job_;\n  ncclComm_t comm = job->comm;\n  ncclResult_t res = ncclSuccess;\n  int archMajor, archMinor;\n  size_t maxLocalSizeBytes = 0;\n  int cudaDev = job->cudaDev;\n  int* parentRanks = NULL;\n  int cudaArch;\n\n  CUDACHECKGOTO(cudaSetDevice(cudaDev), res, fail);\n  CUDACHECKGOTO(cudaDeviceGetAttribute(&archMajor, cudaDevAttrComputeCapabilityMajor, cudaDev), res, fail);\n  CUDACHECKGOTO(cudaDeviceGetAttribute(&archMinor, cudaDevAttrComputeCapabilityMinor, cudaDev), res, fail);\n  cudaArch = 100*archMajor + 10*archMinor;\n\n  NCCLCHECK(ncclInitKernelsForDevice(cudaArch, &maxLocalSizeBytes));\n  // Set the maximum kernel stack size of all kernels to avoid\n  // a CUDA memory reconfig on load (c.f. NVSHMEM issue)\n  if (maxLocalSizeBytes > 0 && ncclParamSetStackSize() == 1) {\n    TRACE(NCCL_INIT, \"Setting cudaLimitStackSize to %zi\", maxLocalSizeBytes);\n    CUDACHECKIGNORE(cudaDeviceSetLimit(cudaLimitStackSize, maxLocalSizeBytes));\n  }\n\n  if (job->parent) {\n    NCCLCHECKGOTO(ncclCalloc(&parentRanks, job->parent->nRanks), res, fail);\n    NCCLCHECKGOTO(commGetSplitInfo(comm, job->parent, job->color, job->key, &job->nranks, &job->myrank, parentRanks), res, fail);\n    // Negative color does not create a new comm object. We needed to take part in the allgather, but we're done now.\n    if (job->color == NCCL_SPLIT_NOCOLOR) goto exit;\n    snprintf((char*)&job->commId, sizeof(job->commId), \"%016lx-%d\", job->parent->commHash, job->color);\n    NCCLCHECKGOTO(commAlloc(comm, job->parent, job->nranks, job->myrank), res, fail);\n    NCCLCHECKGOTO(bootstrapSplit((struct ncclBootstrapHandle*)&job->commId, comm, job->parent, job->color, job->key, parentRanks), res, fail);\n  } else {\n    NCCLCHECKGOTO(commAlloc(comm, NULL, job->nranks, job->myrank), res, fail);\n    NCCLCHECKGOTO(bootstrapInit((struct ncclBootstrapHandle*)&job->commId, comm), res, fail);\n  }\n\n  comm->cudaArch = cudaArch;\n  comm->commHash = getHash(job->commId.internal, NCCL_UNIQUE_ID_BYTES);\n\n  if (job->parent) {\n    INFO(NCCL_INIT,\"ncclCommSplit comm %p rank %d nranks %d cudaDev %d nvmlDev %d busId %lx parent %p color %d key %d commId 0x%llx - Init START\",\n    comm, comm->rank, comm->nRanks, comm->cudaDev, comm->nvmlDev, comm->busId, job->parent, job->color, job->key, (unsigned long long)hashUniqueId(job->commId));\n  } else {\n    INFO(NCCL_INIT,\"ncclCommInitRank comm %p rank %d nranks %d cudaDev %d nvmlDev %d busId %lx commId 0x%llx - Init START\",\n    comm, comm->rank, comm->nRanks, comm->cudaDev, comm->nvmlDev, comm->busId, (unsigned long long)hashUniqueId(job->commId));\n  }\n\n  NCCLCHECKGOTO(initTransportsRank(comm, job->parent), res, fail);\n\n  NCCLCHECKGOTO(ncclTunerPluginLoad(&comm->tuner), res, fail);\n  if (comm->tuner) {\n    NCCLCHECK(comm->tuner->init(comm->nRanks, comm->nNodes, ncclDebugLog, &comm->tunerContext));\n  }\n\n  // update communicator state\n  comm->initState = ncclSuccess;\n\n  // Trace this call for replay tool\n  if (job->parent) {\n    /* unlink child abort flag. */\n    __atomic_store_n(&job->parent->childAbortFlag, NULL, __ATOMIC_RELEASE);\n    TRACE_CALL(\"ncclCommSplit(%p, %d, %d, %p, %d, %d)\",\n                job->parent, job->color, job->key, comm, comm->rank, comm->nRanks);\n  } else {\n    TRACE_CALL(\"ncclCommInitRank(%p, %d, 0x%llx, %d, %d)\",\n                comm, comm->nRanks, (unsigned long long)hashUniqueId(job->commId), comm->rank, comm->cudaDev);\n  }\n\n  if (job->parent) {\n    INFO(NCCL_INIT,\"ncclCommSplit comm %p rank %d nranks %d cudaDev %d nvmlDev %d busId %lx parent %p color %d key %d commId 0x%llx - Init COMPLETE\",\n    comm, comm->rank, comm->nRanks, comm->cudaDev, comm->nvmlDev, comm->busId, job->parent, job->color, job->key, (unsigned long long)hashUniqueId(job->commId));\n  } else {\n    INFO(NCCL_INIT,\"ncclCommInitRank comm %p rank %d nranks %d cudaDev %d nvmlDev %d busId %lx commId 0x%llx - Init COMPLETE\",\n    comm, comm->rank, comm->nRanks, comm->cudaDev, comm->nvmlDev, comm->busId, (unsigned long long)hashUniqueId(job->commId));\n  }\n\n  tracepoint(nccl, commInit, comm->commHash, comm->localRanks, comm->nRanks, comm->nChannels, comm->p2pnChannels, comm->p2pnChannelsPerPeer);\n  int ringChannel[32];\n  int treeChannel[32*4];\n  for (int i=0; i<comm->nChannels; i++) {\n      ringChannel[i] = comm->channels[i].ring.next;\n      treeChannel[i*4] = comm->channels[i].tree.up;\n      treeChannel[i*4+1] = comm->channels[i].tree.down[0];\n      treeChannel[i*4+2] = comm->channels[i].tree.down[1];\n      treeChannel[i*4+3] = comm->channels[i].tree.down[2];\n  }\n  tracepoint(nccl, commChannel, comm->commHash, comm->rank, comm->nChannels, ringChannel, treeChannel);\n\nexit:\n  if (job->newcomm) {\n    /* assign it to user pointer. */\n    __atomic_store_n(job->newcomm, comm, __ATOMIC_RELEASE);\n  }\n  free(parentRanks);\n  return res;\nfail:\n  comm->initState = res;\n  goto exit;\n}\n\n#define NCCL_CONFIG_DEFAULT(config, field, undef, defvalue, fieldStr, format) \\\n  if (config->field == undef) { \\\n    config->field = defvalue; \\\n  } else { \\\n    INFO(NCCL_ENV, \"Comm config \" fieldStr \" set to \" format, config->field); \\\n  }\n\nstatic ncclResult_t envConfigOverride(ncclComm_t comm) {\n  ncclResult_t ret = ncclSuccess;\n  const char* tmpNetName = comm->config.netName;\n  const char* envNetName;\n  int blockingEnv;\n  int cgaClusterSizeEnv;\n  int minCTAsEnv;\n  int maxCTAsEnv;\n  int splitShareEnv;\n\n  /* override configuration from env variable. */\n  blockingEnv = ncclParamCommBlocking();\n  if (blockingEnv == 0 || blockingEnv == 1)\n    comm->config.blocking = blockingEnv;\n\n  cgaClusterSizeEnv = ncclParamCGAClusterSize();\n  if (0 <= cgaClusterSizeEnv && cgaClusterSizeEnv <= NCCL_MAX_CGA_CLUSTER_SIZE) {\n    comm->config.cgaClusterSize = cgaClusterSizeEnv;\n  } else if (cgaClusterSizeEnv > NCCL_MAX_CGA_CLUSTER_SIZE) {\n    WARN(\"NCCL_CGA_CLUSTER_SIZE value %d is too big. Limiting value to %d.\", cgaClusterSizeEnv, NCCL_MAX_CGA_CLUSTER_SIZE);\n    comm->config.cgaClusterSize = NCCL_MAX_CGA_CLUSTER_SIZE;\n  }\n\n  minCTAsEnv = ncclParamMinCTAs();\n  if (minCTAsEnv != NCCL_CONFIG_UNDEF_INT) {\n    comm->config.minCTAs = minCTAsEnv;\n  }\n\n  maxCTAsEnv = ncclParamMaxCTAs();\n  if (maxCTAsEnv != NCCL_CONFIG_UNDEF_INT) {\n    comm->config.maxCTAs = maxCTAsEnv;\n  }\n\n  envNetName = ncclGetEnv(\"NCCL_NET\");\n  if (envNetName)\n    tmpNetName = envNetName;\n  if (tmpNetName != NULL) {\n    int netNameLen = strlen(tmpNetName) + 1;\n    comm->config.netName = (char*)malloc(netNameLen);\n    memcpy((void*)comm->config.netName, tmpNetName, netNameLen);\n  } else {\n    comm->config.netName = NULL;\n  }\n\n  splitShareEnv = ncclParamCommSplitShareResources();\n  if (splitShareEnv != NCCL_CONFIG_UNDEF_INT) {\n    comm->config.splitShare = splitShareEnv;\n  }\n\n  /* cap channels if needed */\n  if (comm->config.minCTAs > MAXCHANNELS) {\n    WARN(\"minCTAs %d is larger than #channels upper limit %d, cap it to %d\", comm->config.minCTAs, MAXCHANNELS, MAXCHANNELS);\n    comm->config.minCTAs = MAXCHANNELS;\n  }\n\n  if (comm->config.maxCTAs > MAXCHANNELS) {\n    WARN(\"maxCTAs %d is larger than #channels upper limit %d, cap it to %d\", comm->config.maxCTAs, MAXCHANNELS, MAXCHANNELS);\n    comm->config.maxCTAs = MAXCHANNELS;\n  }\n\n  if (comm->config.minCTAs > comm->config.maxCTAs) {\n    WARN(\"minCTAs %d is larger than maxCTAs %d, set both to %d\", comm->config.minCTAs, comm->config.maxCTAs, comm->config.maxCTAs);\n    comm->config.minCTAs = comm->config.maxCTAs;\n  }\n\n  if (comm->config.splitShare != 1 && comm->config.splitShare != 0) {\n    WARN(\"splitShare %d is not a valid value 0/1, set it to 0\\n\", comm->config.splitShare);\n    comm->config.splitShare = 0;\n  }\n\n  return ret;\n}\n\nstatic ncclResult_t copyCommConfig(ncclComm_t childComm, ncclComm_t parnet) {\n  memcpy(&childComm->config, &parnet->config, sizeof(ncclConfig_t));\n  NCCLCHECK(envConfigOverride(childComm));\n  return ncclSuccess;\n}\n\nstatic ncclResult_t parseCommConfig(ncclComm_t comm, ncclConfig_t *config) {\n  ncclResult_t ret = ncclSuccess;\n  /* config must not be NULL in this function */\n  ncclConfig_t defaultConfig = NCCL_CONFIG_INITIALIZER;\n  ncclConfig_t internalConfig = NCCL_CONFIG_INITIALIZER;\n  ncclConfig_t *internalConfigPtr;\n  size_t realSize;\n\n  internalConfigPtr = &internalConfig;\n  if (config) {\n    memcpy((void*)&realSize, (void*)config, sizeof(size_t));\n    realSize = realSize > sizeof(ncclConfig_t) ? sizeof(ncclConfig_t) : realSize;\n    memcpy((void*)internalConfigPtr, (void*)config, realSize);\n    if (internalConfigPtr->magic != 0xcafebeef) {\n      WARN(\"ncclConfig_t argument not initialized via NCCL_CONFIG_INITIALIZER\");\n      ret = ncclInvalidArgument;\n      goto fail;\n    }\n\n    /* check version. */\n    if (internalConfigPtr->version < NCCL_VERSION(2, 14, 0)) {\n      internalConfigPtr->blocking = defaultConfig.blocking;\n    }\n\n    if (internalConfigPtr->version < NCCL_VERSION(2, 17, 0)) {\n      internalConfigPtr->cgaClusterSize = defaultConfig.cgaClusterSize;\n      internalConfigPtr->minCTAs = defaultConfig.minCTAs;\n      internalConfigPtr->maxCTAs = defaultConfig.maxCTAs;\n      internalConfigPtr->netName = defaultConfig.netName;\n    }\n  }\n\n  /* check input config attributes, -1 means user-undefined and we should use default value from NCCL. */\n  if (internalConfigPtr->blocking != NCCL_CONFIG_UNDEF_INT && internalConfigPtr->blocking != 0 && internalConfigPtr->blocking != 1) {\n    WARN(\"Invalid config blocking attribute value %d\", internalConfigPtr->blocking);\n    ret = ncclInvalidArgument;\n    goto fail;\n  }\n\n  if (internalConfigPtr->cgaClusterSize != NCCL_CONFIG_UNDEF_INT && internalConfigPtr->cgaClusterSize < 0) {\n    WARN(\"Invalid config cgaClusterSize attribute value %d\", internalConfigPtr->cgaClusterSize);\n    ret = ncclInvalidArgument;\n    goto fail;\n  }\n\n  if ((internalConfigPtr->minCTAs != NCCL_CONFIG_UNDEF_INT &&\n    internalConfigPtr->minCTAs <= 0) ||\n    (internalConfigPtr->maxCTAs != NCCL_CONFIG_UNDEF_INT &&\n      internalConfigPtr->maxCTAs <= 0) ||\n    (internalConfigPtr->minCTAs > internalConfigPtr->maxCTAs)) {\n    WARN(\"Invalid config min/max channels attribute value %d/%d\", internalConfigPtr->minCTAs, internalConfigPtr->maxCTAs);\n    ret = ncclInvalidArgument;\n    goto fail;\n  }\n\n  if (internalConfigPtr->splitShare != NCCL_CONFIG_UNDEF_INT && internalConfigPtr->splitShare != 0 && internalConfigPtr->splitShare != 1) {\n    WARN(\"Invalid config splitShare attribute value %d\", internalConfigPtr->splitShare);\n    ret = ncclInvalidArgument;\n    goto fail;\n  }\n\n  /* default config value can be tuned on different platform. */\n  NCCL_CONFIG_DEFAULT(internalConfigPtr, blocking, NCCL_CONFIG_UNDEF_INT, 1, \"Blocking\", \"%d\");\n  NCCL_CONFIG_DEFAULT(internalConfigPtr, cgaClusterSize, NCCL_CONFIG_UNDEF_INT, 4, \"CGA cluster size\", \"%d\");\n  NCCL_CONFIG_DEFAULT(internalConfigPtr, minCTAs, NCCL_CONFIG_UNDEF_INT, 1, \"Min CTAs\", \"%d\");\n  NCCL_CONFIG_DEFAULT(internalConfigPtr, maxCTAs, NCCL_CONFIG_UNDEF_INT, MAXCHANNELS, \"Max CTAs\", \"%d\");\n  NCCL_CONFIG_DEFAULT(internalConfigPtr, netName, NCCL_CONFIG_UNDEF_PTR, NULL, \"Net name\", \"%s\");\n  NCCL_CONFIG_DEFAULT(internalConfigPtr, splitShare, NCCL_CONFIG_UNDEF_INT, 0, \"Split share\", \"%d\");\n\n  /* assign config to communicator */\n  comm->config.blocking = internalConfigPtr->blocking;\n  comm->config.cgaClusterSize = internalConfigPtr->cgaClusterSize;\n  comm->config.minCTAs = internalConfigPtr->minCTAs;\n  comm->config.maxCTAs = internalConfigPtr->maxCTAs;\n  comm->config.netName = internalConfigPtr->netName;\n  comm->config.splitShare = internalConfigPtr->splitShare;\n\n  NCCLCHECKGOTO(envConfigOverride(comm), ret, fail);\n\nexit:\n  return ret;\nfail:\n  goto exit;\n}\n\nstatic ncclResult_t ncclCommInitRankDev(ncclComm_t* newcomm, int nranks, ncclUniqueId commId, int myrank, int cudaDev, ncclConfig_t *config) {\n  ncclResult_t res = ncclSuccess;\n  ncclComm_t comm = NULL;\n  struct ncclCommInitRankAsyncJob *job = NULL;\n  const char* env = ncclGetEnv(\"NCCL_COMM_ID\");\n  if (env && myrank == 0) {\n    INFO(NCCL_ENV, \"NCCL_COMM_ID set by environment to %s\", env);\n    NCCLCHECKGOTO(bootstrapCreateRoot((struct ncclBootstrapHandle*)&commId, true), res, fail);\n  }\n\n  NCCLCHECKGOTO(ncclInit(), res, fail);\n  if (myrank == 0) showVersion();\n\n  // Make sure the CUDA runtime is initialized.\n  CUDACHECKGOTO(cudaFree(NULL), res, fail);\n\n  NCCLCHECKGOTO(PtrCheck(newcomm, \"CommInitRank\", \"newcomm\"), res, fail);\n  NCCLCHECKGOTO(PtrCheck(config, \"CommInitRank\", \"config\"), res, fail);\n  if (nranks < 1 || myrank < 0 || myrank >= nranks) {\n    WARN(\"Invalid rank requested : %d/%d\", myrank, nranks);\n    res = ncclInvalidArgument;\n    goto fail;\n  }\n\n  NCCLCHECKGOTO(ncclCalloc(&comm, 1), res, fail);\n  comm->startMagic = comm->endMagic = NCCL_MAGIC; // Used to detect comm corruption.\n  NCCLCHECKGOTO(ncclCudaHostCalloc((uint32_t**)&comm->abortFlag, 1), res, fail);\n  NCCLCHECKGOTO(ncclCalloc((uint32_t**)&comm->abortFlagRefCount, 1), res, fail);\n  *comm->abortFlagRefCount = 1;\n  NCCLCHECKGOTO(parseCommConfig(comm, config), res, fail);\n  /* start with ncclInternalError and will be changed to ncclSuccess if init succeeds. */\n  comm->initState = ncclInternalError;\n  *newcomm = comm;\n\n  NCCLCHECKGOTO(ncclCalloc(&job, 1), res, fail);\n  job->comm = comm;\n  job->nranks = nranks;\n  job->commId = commId; // C++ struct assignment\n  job->myrank = myrank;\n  job->cudaDev = cudaDev;\n  NCCLCHECKGOTO(ncclAsyncLaunch(&job->base, ncclCommInitRankFunc, NULL, free, comm), res, fail);\n\nexit:\n  return ncclGroupErrCheck(res);\nfail:\n  if (comm) {\n    if (comm->abortFlag) ncclCudaHostFree((void *)comm->abortFlag);\n    if (comm->abortFlagRefCount) free(comm->abortFlagRefCount);\n    free(comm);\n  }\n  if (newcomm) *newcomm = NULL;\n  goto exit;\n}\n\nstruct NvtxParamsCommInitRank\n{\n  int rank;\n  int nranks;\n  int cudaDev;\n};\nconstexpr nvtxPayloadSchemaEntry_t CommInitRankSchema[] = {\n  {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"Rank\"},\n  {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"No. of ranks\", nullptr, 0, offsetof(NvtxParamsCommInitRank, nranks)},\n  {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"CUDA device\", nullptr, 0, offsetof(NvtxParamsCommInitRank, cudaDev)},\n};\n\nNCCL_API(ncclResult_t, ncclCommInitRank, ncclComm_t* newcomm, int nranks, ncclUniqueId commId, int myrank);\nncclResult_t ncclCommInitRank(ncclComm_t* newcomm, int nranks, ncclUniqueId commId, int myrank) {\n  // Load the CUDA driver and dlsym hooks (can fail on old drivers)\n  (void)ncclCudaLibraryInit();\n\n  int cudaDev;\n  ncclConfig_t config = NCCL_CONFIG_INITIALIZER;\n  CUDACHECK(cudaGetDevice(&cudaDev));\n\n  NvtxParamsCommInitRank payload{myrank, nranks, cudaDev};\n  NVTX3_FUNC_WITH_PARAMS(CommInitRank, CommInitRankSchema, payload)\n\n  NCCLCHECK(ncclCommInitRankDev(newcomm, nranks, commId, myrank, cudaDev, &config));\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommInitAll, ncclComm_t* comms, int ndev, const int* devlist);\nncclResult_t ncclCommInitAll(ncclComm_t* comms, int ndev, const int* devlist) {\n  ncclResult_t ret = ncclSuccess;\n  int totalnDev;\n  int *gpuFlags = NULL;\n  ncclConfig_t config = NCCL_CONFIG_INITIALIZER;\n\n  constexpr nvtxPayloadSchemaEntry_t CommInitAllSchema[] = {\n    {0, NVTX_PAYLOAD_ENTRY_TYPE_INT, \"No. of devices\"}\n  };\n  NVTX3_FUNC_WITH_PARAMS(CommInitAll, CommInitAllSchema, ndev)\n\n  // Load the CUDA driver and dlsym hooks (can fail on old drivers)\n  (void)ncclCudaLibraryInit();\n\n  NCCLCHECKGOTO(PtrCheck(comms, \"CommInitAll\", \"comms\"), ret, fail);\n  if (ndev < 0) {\n    WARN(\"Invalid device count requested : %d\", ndev);\n    ret = ncclInvalidArgument;\n    goto fail;\n  }\n\n  CUDACHECKGOTO(cudaGetDeviceCount(&totalnDev), ret, fail);\n  if (devlist) {\n    NCCLCHECKGOTO(ncclCalloc(&gpuFlags, totalnDev), ret, fail);\n    for (int i = 0; i < ndev; ++i) {\n      /* invalid device check. */\n      if (devlist[i] < 0 || devlist[i] >= totalnDev) {\n        ret = ncclUnhandledCudaError;\n        goto fail;\n      }\n\n      /* duplicate device check. */\n      if (gpuFlags[devlist[i]] != 0) {\n        ret = ncclInvalidUsage;\n        goto fail;\n      }\n\n      gpuFlags[devlist[i]] = 1;\n    }\n    free(gpuFlags);\n    gpuFlags = nullptr;\n  }\n\n  ncclUniqueId uniqueId;\n  NCCLCHECKGOTO(ncclGetUniqueId(&uniqueId), ret, fail);\n  NCCLCHECKGOTO(ncclGroupStart(), ret, fail);\n  for (int i=0; i<ndev; i++) {\n    // Ignore return codes .. we need to call ncclGroupEnd to clean up anyway\n    ncclCommInitRankDev(comms+i, ndev, uniqueId, i, devlist ? devlist[i] : i, &config);\n  }\n  NCCLCHECKGOTO(ncclGroupEnd(), ret, fail);\n\nfail:\n  free(gpuFlags);\n  return ret;\n}\n\nncclResult_t ncclCommSetAsyncError(ncclComm_t comm, ncclResult_t nextState) {\n  if (nextState < 0 || nextState >= ncclNumResults || comm == NULL) {\n    WARN(\"ncclCommSetAsyncError: error comm %p sets state %d\", comm, nextState);\n    return ncclInvalidArgument;\n  }\n\n  __atomic_store_n(&comm->asyncResult, nextState, __ATOMIC_RELEASE);\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommInitRankConfig, ncclComm_t* comm, int nranks, ncclUniqueId commId, int myrank, ncclConfig_t *config);\nncclResult_t ncclCommInitRankConfig(ncclComm_t *newcomm, int nranks, ncclUniqueId commId, int myrank, ncclConfig_t *config) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n  int cudaDev;\n  ncclResult_t ret = ncclSuccess;\n  ncclConfig_t internalConfig = NCCL_CONFIG_INITIALIZER;\n  ncclConfig_t *internalConfigPtr = NULL;\n  NCCLCHECK(ncclGroupStartInternal());\n\n  (void)ncclCudaLibraryInit();\n  CUDACHECKGOTO(cudaGetDevice(&cudaDev), ret, fail);\n\n  if (config == NULL)\n    internalConfigPtr = &internalConfig;\n  else\n    internalConfigPtr = config;\n  NCCLCHECKGOTO(ncclCommInitRankDev(newcomm, nranks, commId, myrank, cudaDev, internalConfigPtr), ret, fail);\n\nexit:\n  ncclGroupErrCheck(ret);\n  NCCLCHECK(ncclGroupEndInternal());\n  if (newcomm && *newcomm && !(*newcomm)->config.blocking) (void) ncclCommGetAsyncError(*newcomm, &ret);\n  return ret;\nfail:\n  if (newcomm && *newcomm && !(*newcomm)->config.blocking) (void) ncclCommSetAsyncError(*newcomm, ret);\n  goto exit;\n}\n\nstatic ncclResult_t commDestroySync(struct ncclAsyncJob* job_) {\n  struct ncclCommFinalizeAsyncJob* job = (struct ncclCommFinalizeAsyncJob*) job_;\n  ncclComm_t comm = job->comm;\n  int savedDevice;\n  int commDevice = comm->cudaDev;\n  ncclResult_t ret = ncclSuccess;\n\n  CUDACHECKGOTO(cudaGetDevice(&savedDevice), ret, fail);\n  if (savedDevice != commDevice) {\n    CUDACHECKGOTO(cudaSetDevice(commDevice), ret, fail);\n  }\n\n  TRACE(NCCL_INIT, \"Destroying comm %p rank %d abortFlag %d asyncResult %d\", comm, comm->rank, *comm->abortFlag, comm->asyncResult);\n\n  if (comm->initState == ncclSuccess) {\n    NCCLCHECKGOTO(ncclStrongStreamSynchronize(&comm->sharedRes->hostStream), ret, fail);\n    NCCLCHECKGOTO(ncclStrongStreamSynchronize(&comm->sharedRes->deviceStream), ret, fail);\n  }\n  NCCLCHECKGOTO(ncclCommPollCallbacks(comm, false), ret, fail);\n  // And keep polling until all graphs referencing us die.\n  while (comm->persistentRefs != 0) {\n    NCCLCHECKGOTO(ncclCommPollCallbacks(comm, /*waitSome=*/true), ret, fail);\n  }\n\n  if (savedDevice != commDevice) {\n    CUDACHECKGOTO(cudaSetDevice(savedDevice), ret, fail);\n  }\n\n  comm->finalizeCalled = true;\nexit:\n  return ret;\nfail:\n  goto exit;\n}\n\nstatic ncclResult_t commCleanup(ncclComm_t comm) {\n  int savedDevice;\n  int commDevice = comm->cudaDev;\n\n  CUDACHECK(cudaGetDevice(&savedDevice));\n  if (savedDevice != commDevice) {\n    CUDACHECK(cudaSetDevice(commDevice));\n  }\n\n  if (comm->tuner != NULL) {\n    NCCLCHECK(comm->tuner->destroy(comm->tunerContext));\n    NCCLCHECK(ncclTunerPluginUnload(&comm->tuner));\n  }\n\n  NCCLCHECK(commFree(comm));\n\n  if (savedDevice != commDevice) {\n    CUDACHECK(cudaSetDevice(savedDevice));\n  }\n\n  return ncclSuccess;\n}\n\nstatic ncclResult_t commFinalize(ncclComm_t comm, bool userCalled) {\n  ncclResult_t ret = ncclSuccess;\n  struct ncclCommFinalizeAsyncJob *job = NULL;\n\n  /* launch async thread to finalize comm. */\n  NCCLCHECKGOTO(ncclCalloc(&job, 1), ret, fail);\n  job->comm = comm;\n\n  if (userCalled) {\n    NCCLCHECKGOTO(ncclAsyncLaunch(&job->base, commDestroySync, NULL, free, comm), ret, fail);\n  } else {\n    NCCLCHECKGOTO(commDestroySync(&job->base), ret, fail);\n    free(job);\n  }\n\nexit:\n  return ncclGroupErrCheck(ret);\nfail:\n  goto exit;\n}\n\nNCCL_API(ncclResult_t, ncclCommFinalize, ncclComm_t comm);\nncclResult_t ncclCommFinalize(ncclComm_t comm) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n  ncclResult_t ret = ncclSuccess;\n\n  NCCLCHECK(ncclGroupStartInternal());\n  if (comm == NULL) goto exit;\n\n  /* wait comm ready before finalize. */\n  NCCLCHECKGOTO(ncclCommEnsureReady(comm), ret, fail);\n\n  /* prevent double finalize. */\n  if (comm->finalizeCalled) {\n    ret = ncclInvalidArgument;\n    goto fail;\n  }\n\n  /* finalize comm. */\n  ret = commFinalize(comm, true);\n\nexit:\n  ncclGroupErrCheck(ret);\n  NCCLCHECK(ncclGroupEndInternal());\n  if (comm && !comm->config.blocking) { NCCLCHECK(ncclCommGetAsyncError(comm, &ret)) };\n  return ret;\nfail:\n  if (comm && !comm->config.blocking) (void) ncclCommSetAsyncError(comm, ret);\n  goto exit;\n}\n\nstatic ncclResult_t commReclaim(ncclComm_t comm) {\n  ncclResult_t ret = ncclSuccess;\n  ncclResult_t state;\n  int curRank; /* Debug info */\n\n  NCCLCHECKGOTO(ncclCommGetAsyncError(comm, &state), ret, fail);\n  TRACE(NCCL_INIT, \"commReclaim: reclaim comm %p rank %d state %d\", comm, comm->rank, state);\n  if (state == ncclSuccess && __atomic_load_n(comm->abortFlag, __ATOMIC_RELAXED) == 0 && comm->finalizeCalled == false) {\n    /* user does not call ncclCommFinalize and this is a normal comm destroy. ncclCommDestroy\n     * should be nonblocking until last call of ncclCommDestroy. */\n    NCCLCHECKGOTO(commFinalize(comm, false), ret, fail);\n  }\n\n  if (comm->intraComm0 != NULL) {\n    int curRankCnt;\n    int intraRanks = comm->intraRanks;\n    ncclComm_t intracomm0 = comm->intraComm0;\n    int *finalizeRankCnt = &intracomm0->finalizeRankCnt;\n\n    assert(intracomm0 != NULL && finalizeRankCnt != NULL);\n    curRankCnt = __atomic_add_fetch(finalizeRankCnt, 1, __ATOMIC_ACQ_REL);\n    if (curRankCnt == intraRanks) {\n      ncclComm_t curIntraComm;\n      ncclComm_t nextIntraComm = intracomm0;\n\n      /* this is  the last call to ncclCommDestroy/Abort, we need to make sure all comms\n       * in the process have been finalized before we free local resources. */\n      while (nextIntraComm) {\n        curIntraComm = nextIntraComm;\n        curRank = curIntraComm->rank;\n        nextIntraComm = nextIntraComm->intraNext;\n\n        if (curIntraComm->finalizeCalled == false) {\n          struct ncclCommFinalizeAsyncJob job;\n          job.comm = curIntraComm;\n          /* every comm aborts, commDestroySync should not be blocked. */\n          if ((ret = commDestroySync((struct ncclAsyncJob*) &job)) != ncclSuccess)\n            WARN(\"commReclaim: comm %p (rank = %d) in abort, error %d\", curIntraComm, curRank, ret);\n        }\n      }\n\n      /* ncclProxyStop() loop must be put after commDestroySync() loop. Namely, you cannot do:\n       *  while(...) {\n       *     commDestroySync(...);\n       *     ncclProxyStop(...);\n       *  }\n       * Considering one process multi-gpu case, we must guarantee all kernels are complete before\n       * we free proxy resources; otherwise, we will face invalid memory issues where proxy connection\n       * and related intermediate memory from one rank are freed but other ranks are still using it.\n       * This is not a problem for multi-process case, since intermediate memory is opened by CUDA IPC\n       * or mmap where memory free is guarded by CUDA driver and operating system, so we will not have\n       * invalid memory access issue. */\n      nextIntraComm = intracomm0;\n      while (nextIntraComm) {\n        curIntraComm = nextIntraComm;\n        curRank = curIntraComm->rank;\n        nextIntraComm = nextIntraComm->intraNext;\n\n        /* free intraprocess proxy resources. */\n        if ((ret = ncclProxyStop(curIntraComm)) != ncclSuccess) {\n          WARN(\"commReclaim: comm %p (rank = %d) destroys proxy resource error %d\", curIntraComm, curRank, ret);\n        }\n      }\n\n      /* free local resources. */\n      nextIntraComm = intracomm0;\n      while (nextIntraComm) {\n        curIntraComm = nextIntraComm;\n        curRank = curIntraComm->rank;\n        nextIntraComm = nextIntraComm->intraNext;\n\n        if ((ret = commCleanup(curIntraComm)) != ncclSuccess) {\n          WARN(\"commReclaim: cleanup comm %p rank %d failed in destroy/abort, error %d\", curIntraComm, curRank, ret);\n        }\n      }\n    }\n  }\n\nexit:\n  return ret;\nfail:\n  goto exit;\n}\n\nNCCL_API(ncclResult_t, ncclCommDestroy, ncclComm_t comm);\nncclResult_t ncclCommDestroy(ncclComm_t comm) {\n  if (comm == NULL) {\n    NVTX3_FUNC_RANGE_IN(nccl_domain);\n    return ncclSuccess;\n  }\n\n  int rank = comm->rank, nranks = comm->nRanks, cudaDev = comm->cudaDev;\n\n  NvtxParamsCommInitRank payload{rank, nranks, cudaDev};\n  NVTX3_FUNC_WITH_PARAMS(CommDestroy, CommInitRankSchema, payload)\n\n  int64_t busId = comm->busId;\n  TRACE(NCCL_INIT, \"comm %p rank %d nRanks %d cudaDev %d busId %lx\", comm, rank, nranks, cudaDev, busId);\n  // Try and prevent a double free of the comm struct (user error)\n  if (comm->rank == -1 || comm->nRanks == -1 || comm->cudaDev == -1 || comm->busId == -1) {\n    WARN(\"comm %p has already been destroyed\", comm);\n    return ncclInvalidArgument;\n  }\n\n  /* init thread must be joined before we destroy the comm. */\n  NCCLCHECK(ncclCommEnsureReady(comm));\n\n  NCCLCHECK(commReclaim(comm));\n  INFO(NCCL_INIT,\"comm %p rank %d nranks %d cudaDev %d busId %lx - Destroy COMPLETE\", comm, rank, nranks, cudaDev, busId);\n\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommAbort, ncclComm_t comm);\nncclResult_t ncclCommAbort(ncclComm_t comm) {\n  if (comm == NULL) {\n    NVTX3_FUNC_RANGE_IN(nccl_domain);\n    return ncclSuccess;\n  }\n\n  volatile uint32_t* childAbortFlag;\n  int rank = comm->rank, nranks = comm->nRanks, cudaDev = comm->cudaDev;\n\n  NvtxParamsCommInitRank payload{rank, nranks, cudaDev};\n  NVTX3_FUNC_WITH_PARAMS(CommAbort, CommInitRankSchema, payload)\n\n  int64_t busId = comm->busId;\n  TRACE(NCCL_INIT, \"comm %p rank %d nRanks %d cudaDev %d busId %lx\", comm, rank, nranks, cudaDev, busId);\n\n  // Ask anything that might still be running on the device to quit\n  childAbortFlag = __atomic_load_n(&comm->childAbortFlag, __ATOMIC_ACQUIRE);\n  if (childAbortFlag != NULL) {\n    __atomic_store_n(childAbortFlag, 1, __ATOMIC_RELAXED);\n  }\n  __atomic_store_n(comm->abortFlag, 1, __ATOMIC_RELAXED);\n  /* init thread must be joined before we destroy the comm,\n   * and we should ignore the init error here. */\n  ncclCommEnsureReady(comm);\n\n  (void) commReclaim(comm);\n  INFO(NCCL_INIT,\"comm %p rank %d nranks %d cudaDev %d busId %lx - Abort COMPLETE\", comm, rank, nranks, cudaDev, busId);\n\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommSplit, ncclComm_t comm, int color, int key, ncclComm_t *newcomm, ncclConfig_t *config);\nncclResult_t ncclCommSplit(ncclComm_t comm, int color, int key, ncclComm_t *newcomm, ncclConfig_t *config) {\n  struct ncclCommInitRankAsyncJob *job = NULL;\n  struct ncclComm* childComm = NCCL_COMM_NULL;\n  ncclResult_t res = ncclSuccess;\n\n  NCCLCHECK(ncclGroupStartInternal());\n  NCCLCHECKGOTO(CommCheck(comm, \"CommSplit\", \"comm\"), res, fail);\n  NCCLCHECKGOTO(PtrCheck(newcomm, \"CommSplit\", \"newcomm\"), res, fail);\n  NCCLCHECKGOTO(ncclCommEnsureReady(comm), res, fail);\n\n  /* *newcomm should be NCCL_COMM_NULL until comm split fully complete. */\n  *newcomm = NCCL_COMM_NULL;\n  if (color == NCCL_SPLIT_NOCOLOR) {\n    INFO(NCCL_INIT, \"Rank %d has color with NCCL_SPLIT_NOCOLOR, not creating a new communicator\", comm->rank);\n  } else {\n    NCCLCHECKGOTO(ncclCalloc(&childComm, 1), res, fail);\n    childComm->startMagic = childComm->endMagic = NCCL_MAGIC;\n    if (comm->config.splitShare) {\n      childComm->abortFlag = comm->abortFlag;\n      childComm->abortFlagRefCount = comm->abortFlagRefCount;\n      comm->childAbortFlag = NULL;\n      ncclAtomicRefCountIncrement(comm->abortFlagRefCount);\n    } else {\n      NCCLCHECKGOTO(ncclCudaHostCalloc((uint32_t**)&childComm->abortFlag, 1), res, fail);\n      NCCLCHECKGOTO(ncclCalloc((uint32_t**)&childComm->abortFlagRefCount, 1), res, fail);\n      /* temporarily used to abort everything during child comm init. */\n      comm->childAbortFlag = childComm->abortFlag;\n      *childComm->abortFlagRefCount = 1;\n    }\n    if (config == NULL) {\n      NCCLCHECKGOTO(copyCommConfig(childComm, comm), res, fail);\n    } else {\n      NCCLCHECKGOTO(parseCommConfig(childComm, config), res, fail);\n    }\n\n    /* start with ncclInternalError and will be changed to ncclSuccess if init succeeds. */\n    childComm->initState = ncclInternalError;\n  }\n\n  NCCLCHECKGOTO(ncclCalloc(&job, 1), res, fail);\n  job->comm = childComm;\n  job->newcomm = newcomm;\n  job->parent = comm;\n  job->color = color;\n  job->key = key;\n  job->cudaDev = comm->cudaDev;\n  NCCLCHECKGOTO(ncclAsyncLaunch(&job->base, ncclCommInitRankFunc, NULL, free, comm), res, fail);\n\nexit:\n  ncclGroupErrCheck(res);\n  NCCLCHECK(ncclGroupEndInternal());\n  return res;\nfail:\n  if (childComm) {\n    if (comm && !comm->config.splitShare) {\n      if (childComm->abortFlag) ncclCudaHostFree((void*)childComm->abortFlag);\n      if (childComm->abortFlagRefCount) free(childComm->abortFlagRefCount);\n    }\n    free(childComm);\n  }\n  if (newcomm) *newcomm = NULL;\n  goto exit;\n}\n\nNCCL_API(const char*, ncclGetErrorString, ncclResult_t code);\nconst char* ncclGetErrorString(ncclResult_t code) {\n  switch (code) {\n    case ncclSuccess                : return \"no error\";\n    case ncclUnhandledCudaError     : return \"unhandled cuda error (run with NCCL_DEBUG=INFO for details)\";\n    case ncclSystemError            : return \"unhandled system error (run with NCCL_DEBUG=INFO for details)\";\n    case ncclInternalError          : return \"internal error - please report this issue to the NCCL developers\";\n    case ncclInvalidArgument        : return \"invalid argument (run with NCCL_DEBUG=WARN for details)\";\n    case ncclInvalidUsage           : return \"invalid usage (run with NCCL_DEBUG=WARN for details)\";\n    case ncclRemoteError            : return \"remote process exited or there was a network error\";\n    case ncclInProgress             : return \"NCCL operation in progress\";\n    default                         : return \"unknown result code\";\n  }\n}\n\n/* Returns a human-readable message of the last error that occurred.\n * comm is currently unused and can be set to NULL\n */\nNCCL_API(const char*, ncclGetLastError, const ncclComm_t comm);\nconst char* ncclGetLastError(ncclComm_t comm) {\n  return ncclLastError;\n}\n\nNCCL_API(ncclResult_t, ncclCommGetAsyncError, ncclComm_t comm, ncclResult_t *asyncError);\nncclResult_t ncclCommGetAsyncError(ncclComm_t comm, ncclResult_t *asyncError) {\n  NCCLCHECK(CommCheck(comm, \"ncclGetAsyncError\", \"comm\"));\n  NCCLCHECK(PtrCheck(asyncError, \"ncclGetAsyncError\", \"asyncError\"));\n\n  *asyncError = __atomic_load_n(&comm->asyncResult, __ATOMIC_ACQUIRE);\n  if (*asyncError == ncclSuccess && comm->proxyState) *asyncError = __atomic_load_n(&comm->proxyState->asyncResult, __ATOMIC_ACQUIRE);\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommCount, const ncclComm_t comm, int* count);\nncclResult_t ncclCommCount(const ncclComm_t comm, int* count) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n\n  NCCLCHECK(CommCheck(comm, \"CommCount\", \"comm\"));\n  NCCLCHECK(PtrCheck(count, \"CommCount\", \"count\"));\n\n  /* init thread must be joined before we access the attributes of comm. */\n  NCCLCHECK(ncclCommEnsureReady(comm));\n\n  *count = comm->nRanks;\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommCuDevice, const ncclComm_t comm, int* devid);\nncclResult_t ncclCommCuDevice(const ncclComm_t comm, int* devid) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n\n  NCCLCHECK(CommCheck(comm, \"CommCuDevice\", \"comm\"));\n  NCCLCHECK(PtrCheck(devid, \"CommCuDevice\", \"devid\"));\n\n  NCCLCHECK(ncclCommEnsureReady(comm));\n\n  *devid = comm->cudaDev;\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclCommUserRank, const ncclComm_t comm, int* rank);\nncclResult_t ncclCommUserRank(const ncclComm_t comm, int* rank) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n\n  NCCLCHECK(CommCheck(comm, \"CommUserRank\", \"comm\"));\n  NCCLCHECK(PtrCheck(rank, \"CommUserRank\", \"rank\"));\n\n  NCCLCHECK(ncclCommEnsureReady(comm));\n\n  *rank = comm->rank;\n  return ncclSuccess;\n}\n\nNCCL_API(ncclResult_t, ncclMemAlloc, void **ptr, size_t size);\nncclResult_t  ncclMemAlloc(void **ptr, size_t size) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n  ncclResult_t ret = ncclSuccess;\n\n#if CUDART_VERSION >= 12010\n  size_t memGran = 0;\n  size_t mcGran = 0;\n  CUdevice currentDev;\n  CUmemAllocationProp memprop = {};\n  CUmulticastObjectProp mcprop = {};\n  CUmemAccessDesc accessDesc = {};\n  CUmemGenericAllocationHandle handle;\n  int cudaDev;\n  int flag = 0;\n  int dcnt;\n  int mcSupport = 0;\n\n  if (ptr == NULL || size == 0) goto fallback;\n\n  if (ncclCudaLibraryInit() != ncclSuccess) goto fallback;\n\n  CUDACHECK(cudaGetDevice(&cudaDev));\n  CUCHECK(cuDeviceGet(&currentDev, cudaDev));\n  if (CUPFN(cuMulticastCreate) != NULL)\n    CUCHECK(cuDeviceGetAttribute(&mcSupport, CU_DEVICE_ATTRIBUTE_MULTICAST_SUPPORTED, currentDev));\n\n  if (mcSupport) {\n    memprop.type = CU_MEM_ALLOCATION_TYPE_PINNED;\n    memprop.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n    memprop.requestedHandleTypes = ncclCuMemHandleType;\n    memprop.location.id = currentDev;\n    // Query device to see if RDMA support is available\n    CUCHECK(cuDeviceGetAttribute(&flag, CU_DEVICE_ATTRIBUTE_GPU_DIRECT_RDMA_SUPPORTED, currentDev));\n    if (flag) memprop.allocFlags.gpuDirectRDMACapable = 1;\n    CUCHECK(cuMemGetAllocationGranularity(&memGran, &memprop, CU_MEM_ALLOC_GRANULARITY_RECOMMENDED));\n\n    /* mc property */\n    CUDACHECK(cudaGetDeviceCount(&dcnt));\n    mcprop.size = size;\n    /* device cnt is a dummy value right now, it might affect mc granularity in the future. */\n    mcprop.numDevices = dcnt;\n    mcprop.handleTypes = ncclCuMemHandleType;\n    mcprop.flags = 0;\n    CUCHECK(cuMulticastGetGranularity(&mcGran, &mcprop, CU_MULTICAST_GRANULARITY_RECOMMENDED));\n\n    /* only size needs to be aligned to mcGran */\n    ALIGN_SIZE(size, mcGran);\n    /* Allocate the physical memory on the device */\n    CUCHECK(cuMemCreate(&handle, size, &memprop, 0));\n    /* Reserve a virtual address range */\n    CUCHECK(cuMemAddressReserve((CUdeviceptr*)ptr, size, memGran, 0, 0));\n    /* Map the virtual address range to the physical allocation */\n    CUCHECK(cuMemMap((CUdeviceptr)*ptr, size, 0, handle, 0));\n    /* Now allow RW access to the newly mapped memory */\n    for (int i = 0; i < dcnt; ++i) {\n      int p2p = 0;\n      if (i == cudaDev || ((cudaDeviceCanAccessPeer(&p2p, cudaDev, i) == cudaSuccess) && p2p)) {\n        accessDesc.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n        accessDesc.location.id = i;\n        accessDesc.flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE;\n        CUCHECK(cuMemSetAccess((CUdeviceptr)*ptr, size, &accessDesc, 1));\n      }\n    }\n    goto exit;\n  }\n\nfallback:\n#endif\n  CUDACHECKGOTO(cudaMalloc(ptr, size), ret, fail);\n\nexit:\n  return ret;\nfail:\n  goto exit;\n}\n\nNCCL_API(ncclResult_t, ncclMemFree, void *ptr);\nncclResult_t  ncclMemFree(void *ptr) {\n  NVTX3_FUNC_RANGE_IN(nccl_domain);\n  ncclResult_t ret = ncclSuccess;\n  int saveDevice;\n\n  CUDACHECK(cudaGetDevice(&saveDevice));\n#if CUDART_VERSION >= 12010\n  CUdevice ptrDev = 0;\n  int mcSupport = 0;\n\n  if (ptr == NULL) goto fallback;\n\n  if (ncclCudaLibraryInit() != ncclSuccess) goto fallback;\n\n  CUCHECKGOTO(cuPointerGetAttribute((void*)&ptrDev, CU_POINTER_ATTRIBUTE_DEVICE_ORDINAL, (CUdeviceptr)ptr), ret, fail);\n  if (CUPFN(cuMulticastCreate) != NULL)\n    CUCHECKGOTO(cuDeviceGetAttribute(&mcSupport, CU_DEVICE_ATTRIBUTE_MULTICAST_SUPPORTED, ptrDev), ret, fail);\n\n  CUDACHECKGOTO(cudaSetDevice((int)ptrDev), ret, fail);\n  if (mcSupport) {\n    NCCLCHECKGOTO(ncclCuMemFree(ptr), ret, fail);\n    goto exit;\n  }\n\nfallback:\n#endif\n  CUDACHECKGOTO(cudaFree(ptr), ret, fail);\n\nexit:\n  cudaSetDevice(saveDevice);\n  return ret;\nfail:\n  goto exit;\n}\n","uri":"file:///root/code/multi/nccl/src/init.cc","version":1}}}

I[13:46:31.713] <-- textDocument/didOpen
I[13:46:31.712] Failed to find compilation database for /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h
I[13:46:31.713] ASTWorker building file /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h version 1 with command clangd fallback
[/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include]
/usr/bin/clang -xobjective-c++-header -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h
I[13:46:31.712] Loaded compilation database from /root/code/multi/nccl/compile_commands.json
V[13:46:31.713] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name x86intrin.h -mrelocation-model pic -pic-level 2 -pic-is-pie -mframe-pointer=all -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debugger-tuning=gdb -fdebug-compilation-dir=/usr/lib/gcc/x86_64-linux-gnu/9/include -fcoverage-compilation-dir=/usr/lib/gcc/x86_64-linux-gnu/9/include -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -fdeprecated-macro -ferror-limit 19 -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fobjc-runtime=gcc -fobjc-encode-cxx-class-template-spec -fobjc-exceptions -fcxx-exceptions -fexceptions -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x objective-c++-header /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h
V[13:46:31.713] Broadcasting compilation database from /root/code/multi/nccl
I[13:46:31.714] --> textDocument/clangd.fileStatus
V[13:46:31.714] System include extraction: driver g++ expanded to /usr/bin/g++
V[13:46:31.714] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h"}}

V[13:46:31.714] Building first preamble for /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h version 1
V[13:46:31.714] System include extraction: driver g++ expanded to /usr/bin/g++
V[13:46:31.714] System include extraction: driver g++ expanded to /usr/bin/g++
I[13:46:31.714] --> window/workDoneProgress/create(0)
V[13:46:31.714] >>> {"id":0,"jsonrpc":"2.0","method":"window/workDoneProgress/create","params":{"token":"backgroundIndexProgress"}}

I[13:46:31.714] Enqueueing 44 commands for indexing
V[13:46:31.714] System include extraction: driver g++ expanded to /usr/bin/g++
V[13:46:31.714] System include extraction: driver g++ expanded to /usr/bin/g++
V[13:46:31.716] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name ia32intrin.h -mrelocation-model pic -pic-level 2 -pic-is-pie -mframe-pointer=all -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debugger-tuning=gdb -fdebug-compilation-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -fcoverage-compilation-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -fdeprecated-macro -ferror-limit 19 -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fobjc-runtime=gcc -fobjc-encode-cxx-class-template-spec -fobjc-exceptions -fcxx-exceptions -fexceptions -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x objective-c++-header /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h
I[13:46:31.716] --> textDocument/clangd.fileStatus
V[13:46:31.716] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h"}}

V[13:46:31.716] Building first preamble for /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h version 1
V[13:46:31.716] <<< {"id":0,"jsonrpc":"2.0","result":null}

I[13:46:31.716] <-- reply(0)
I[13:46:31.716] --> $/progress
V[13:46:31.716] >>> {"jsonrpc":"2.0","method":"$/progress","params":{"token":"backgroundIndexProgress","value":{"kind":"begin","percentage":0,"title":"indexing"}}}

I[13:46:31.716] --> $/progress
V[13:46:31.716] >>> {"jsonrpc":"2.0","method":"$/progress","params":{"token":"backgroundIndexProgress","value":{"kind":"report","message":"0/1","percentage":0}}}

V[13:46:31.724] <<< {"id":1,"jsonrpc":"2.0","method":"textDocument/documentSymbol","params":{"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:31.724] <-- textDocument/documentSymbol(1)
V[13:46:31.724] <<< {"id":2,"jsonrpc":"2.0","method":"textDocument/codeAction","params":{"context":{"diagnostics":[],"triggerKind":2},"range":{"end":{"character":17,"line":4},"start":{"character":17,"line":4}},"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:31.724] <-- textDocument/codeAction(2)
V[13:46:31.725] System include extraction: target extracted: "x86_64-linux-gnu"
V[13:46:31.725] System include extraction: adding  /usr/include/c++/9
V[13:46:31.725] System include extraction: adding  /usr/include/x86_64-linux-gnu/c++/9
V[13:46:31.725] System include extraction: adding  /usr/include/c++/9/backward
V[13:46:31.725] System include extraction: adding  /usr/lib/gcc/x86_64-linux-gnu/9/include
V[13:46:31.725] System include extraction: adding  /usr/local/include
V[13:46:31.725] System include extraction: adding  /usr/include/x86_64-linux-gnu
V[13:46:31.725] System include extraction: adding  /usr/include
V[13:46:31.726] System include extraction: target extracted: "x86_64-linux-gnu"
V[13:46:31.726] System include extraction: adding  /usr/include/c++/9
V[13:46:31.726] System include extraction: adding  /usr/include/x86_64-linux-gnu/c++/9
V[13:46:31.726] System include extraction: adding  /usr/include/c++/9/backward
V[13:46:31.726] System include extraction: adding  /usr/lib/gcc/x86_64-linux-gnu/9/include
V[13:46:31.726] System include extraction: adding  /usr/local/include
V[13:46:31.726] System include extraction: adding  /usr/include/x86_64-linux-gnu
V[13:46:31.726] System include extraction: adding  /usr/include
V[13:46:31.727] System include extraction: target extracted: "x86_64-linux-gnu"
V[13:46:31.727] System include extraction: adding  /usr/include/c++/9
V[13:46:31.727] System include extraction: adding  /usr/include/x86_64-linux-gnu/c++/9
V[13:46:31.727] System include extraction: adding  /usr/include/c++/9/backward
V[13:46:31.727] System include extraction: adding  /usr/lib/gcc/x86_64-linux-gnu/9/include
V[13:46:31.727] System include extraction: adding  /usr/local/include
V[13:46:31.727] System include extraction: adding  /usr/include/x86_64-linux-gnu
V[13:46:31.727] System include extraction: adding  /usr/include
V[13:46:31.728] System include extraction: target extracted: "x86_64-linux-gnu"
V[13:46:31.728] System include extraction: adding  /usr/include/c++/9
V[13:46:31.728] System include extraction: adding  /usr/include/x86_64-linux-gnu/c++/9
V[13:46:31.728] System include extraction: adding  /usr/include/c++/9/backward
V[13:46:31.728] System include extraction: adding  /usr/lib/gcc/x86_64-linux-gnu/9/include
V[13:46:31.728] System include extraction: adding  /usr/local/include
V[13:46:31.728] System include extraction: adding  /usr/include/x86_64-linux-gnu
V[13:46:31.728] System include extraction: adding  /usr/include
V[13:46:31.729] System includes extractor: builtin headers /usr/lib/gcc/x86_64-linux-gnu/9/include excluded
I[13:46:31.729] System includes extractor: successfully executed /usr/bin/g++
	got includes: "/usr/include/c++/9, /usr/include/x86_64-linux-gnu/c++/9, /usr/include/c++/9/backward, /usr/local/include, /usr/include/x86_64-linux-gnu, /usr/include"
	got target: "x86_64-linux-gnu"
I[13:46:31.729] ASTWorker building file /root/code/multi/nccl/src/graph/paths.cc version 3 with command 
[/root/code/multi/nccl/src]
/usr/bin/g++ --driver-mode=g++ -c -I. -I/root/code/multi/nccl/include -DCUDA_MAJOR=12 -DCUDA_MINOR=2 -fPIC -fvisibility=hidden -Wall -Wno-unused-function -Wno-sign-compare -Wvla -I /usr/local/cuda/include -I/opt/x-ray/third-party/include -O3 -g -DENABLE_SLOW -DPROFAPI -Iinclude -o /root/code/multi/nccl/obj/graph/paths.o -I/opt/x-ray/third-party/include -I/opt/x-ray/third-party/rdma-core/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include --target=x86_64-linux-gnu -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /root/code/multi/nccl/src/graph/paths.cc
V[13:46:31.729] System includes extractor: builtin headers /usr/lib/gcc/x86_64-linux-gnu/9/include excluded
I[13:46:31.729] System includes extractor: successfully executed /usr/bin/g++
	got includes: "/usr/include/c++/9, /usr/include/x86_64-linux-gnu/c++/9, /usr/include/c++/9/backward, /usr/local/include, /usr/include/x86_64-linux-gnu, /usr/include"
	got target: "x86_64-linux-gnu"
V[13:46:31.729] System includes extractor: builtin headers /usr/lib/gcc/x86_64-linux-gnu/9/include excluded
I[13:46:31.729] System includes extractor: successfully executed /usr/bin/g++
	got includes: "/usr/include/c++/9, /usr/include/x86_64-linux-gnu/c++/9, /usr/include/c++/9/backward, /usr/local/include, /usr/include/x86_64-linux-gnu, /usr/include"
	got target: "x86_64-linux-gnu"
I[13:46:31.729] ASTWorker building file /root/code/multi/nccl/src/collectives.cc version 1 with command 
[/root/code/multi/nccl/src]
/usr/bin/g++ --driver-mode=g++ -c -I. -I/root/code/multi/nccl/include -DCUDA_MAJOR=12 -DCUDA_MINOR=2 -fPIC -fvisibility=hidden -Wall -Wno-unused-function -Wno-sign-compare -Wvla -I /usr/local/cuda/include -I/opt/x-ray/third-party/include -O3 -g -DENABLE_SLOW -DPROFAPI -Iinclude -o /root/code/multi/nccl/obj/collectives.o -I/opt/x-ray/third-party/include -I/opt/x-ray/third-party/rdma-core/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include --target=x86_64-linux-gnu -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /root/code/multi/nccl/src/collectives.cc
I[13:46:31.729] ASTWorker building file /root/code/multi/nccl/src/graph/topo.h version 1 with command inferred from graph/topo.cc
[/root/code/multi/nccl/src]
/usr/bin/g++ --driver-mode=g++ -c -I. -I/root/code/multi/nccl/include -DCUDA_MAJOR=12 -DCUDA_MINOR=2 -fPIC -fvisibility=hidden -Wall -Wno-unused-function -Wno-sign-compare -Wvla -I /usr/local/cuda/include -I/opt/x-ray/third-party/include -O3 -g -DENABLE_SLOW -DPROFAPI -Iinclude -x c++-header -I/opt/x-ray/third-party/include -I/opt/x-ray/third-party/rdma-core/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include --target=x86_64-linux-gnu -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /root/code/multi/nccl/src/graph/topo.h
V[13:46:31.731] <<< {"id":3,"jsonrpc":"2.0","method":"textDocument/documentLink","params":{"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:31.731] <-- textDocument/documentLink(3)
V[13:46:31.731] <<< {"id":4,"jsonrpc":"2.0","method":"textDocument/inlayHint","params":{"range":{"end":{"character":22,"line":74},"start":{"character":0,"line":0}},"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:31.731] <-- textDocument/inlayHint(4)
V[13:46:31.732] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name paths.cc -mrelocation-model pic -pic-level 2 -fhalf-no-semantic-interposition -mframe-pointer=none -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debug-info-kind=constructor -dwarf-version=5 -debugger-tuning=gdb -fdebug-compilation-dir=/root/code/multi/nccl/src -fcoverage-compilation-dir=/root/code/multi/nccl/src -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -I . -I /root/code/multi/nccl/include -D CUDA_MAJOR=12 -D CUDA_MINOR=2 -I /usr/local/cuda/include -I /opt/x-ray/third-party/include -D ENABLE_SLOW -D PROFAPI -I include -I /opt/x-ray/third-party/include -I /opt/x-ray/third-party/rdma-core/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -O3 -Wall -Wno-unused-function -Wno-sign-compare -Wvla -fdeprecated-macro -ferror-limit 19 -fvisibility=hidden -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fcxx-exceptions -fexceptions -vectorize-loops -vectorize-slp -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x c++ /root/code/multi/nccl/src/graph/paths.cc
V[13:46:31.732] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name collectives.cc -mrelocation-model pic -pic-level 2 -fhalf-no-semantic-interposition -mframe-pointer=none -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debug-info-kind=constructor -dwarf-version=5 -debugger-tuning=gdb -fdebug-compilation-dir=/root/code/multi/nccl/src -fcoverage-compilation-dir=/root/code/multi/nccl/src -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -I . -I /root/code/multi/nccl/include -D CUDA_MAJOR=12 -D CUDA_MINOR=2 -I /usr/local/cuda/include -I /opt/x-ray/third-party/include -D ENABLE_SLOW -D PROFAPI -I include -I /opt/x-ray/third-party/include -I /opt/x-ray/third-party/rdma-core/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -O3 -Wall -Wno-unused-function -Wno-sign-compare -Wvla -fdeprecated-macro -ferror-limit 19 -fvisibility=hidden -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fcxx-exceptions -fexceptions -vectorize-loops -vectorize-slp -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x c++ /root/code/multi/nccl/src/collectives.cc
I[13:46:31.732] --> textDocument/clangd.fileStatus
V[13:46:31.732] System includes extractor: builtin headers /usr/lib/gcc/x86_64-linux-gnu/9/include excluded
V[13:46:31.732] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///root/code/multi/nccl/src/collectives.cc"}}

V[13:46:31.732] Building first preamble for /root/code/multi/nccl/src/collectives.cc version 1
I[13:46:31.732] --> textDocument/clangd.fileStatus
V[13:46:31.732] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///root/code/multi/nccl/src/graph/paths.cc"}}

V[13:46:31.732] Building first preamble for /root/code/multi/nccl/src/graph/paths.cc version 3
I[13:46:31.732] System includes extractor: successfully executed /usr/bin/g++
	got includes: "/usr/include/c++/9, /usr/include/x86_64-linux-gnu/c++/9, /usr/include/c++/9/backward, /usr/local/include, /usr/include/x86_64-linux-gnu, /usr/include"
	got target: "x86_64-linux-gnu"
I[13:46:31.732] ASTWorker building file /root/code/multi/nccl/src/init.cc version 1 with command 
[/root/code/multi/nccl/src]
/usr/bin/g++ --driver-mode=g++ -c -I. -I/root/code/multi/nccl/include -DCUDA_MAJOR=12 -DCUDA_MINOR=2 -fPIC -fvisibility=hidden -Wall -Wno-unused-function -Wno-sign-compare -Wvla -I /usr/local/cuda/include -I/opt/x-ray/third-party/include -O3 -g -DENABLE_SLOW -DPROFAPI -Iinclude -o /root/code/multi/nccl/obj/init.o -I/opt/x-ray/third-party/include -I/opt/x-ray/third-party/rdma-core/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include --target=x86_64-linux-gnu -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /root/code/multi/nccl/src/init.cc
V[13:46:31.733] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name topo.h -mrelocation-model pic -pic-level 2 -fhalf-no-semantic-interposition -mframe-pointer=none -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debug-info-kind=constructor -dwarf-version=5 -debugger-tuning=gdb -fdebug-compilation-dir=/root/code/multi/nccl/src -fcoverage-compilation-dir=/root/code/multi/nccl/src -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -I . -I /root/code/multi/nccl/include -D CUDA_MAJOR=12 -D CUDA_MINOR=2 -I /usr/local/cuda/include -I /opt/x-ray/third-party/include -D ENABLE_SLOW -D PROFAPI -I include -I /opt/x-ray/third-party/include -I /opt/x-ray/third-party/rdma-core/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -O3 -Wall -Wno-unused-function -Wno-sign-compare -Wvla -fdeprecated-macro -ferror-limit 19 -fvisibility=hidden -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fcxx-exceptions -fexceptions -vectorize-loops -vectorize-slp -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x c++-header /root/code/multi/nccl/src/graph/topo.h
I[13:46:31.733] --> textDocument/clangd.fileStatus
V[13:46:31.733] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///root/code/multi/nccl/src/graph/topo.h"}}

V[13:46:31.733] Building first preamble for /root/code/multi/nccl/src/graph/topo.h version 1
V[13:46:31.734] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name init.cc -mrelocation-model pic -pic-level 2 -fhalf-no-semantic-interposition -mframe-pointer=none -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debug-info-kind=constructor -dwarf-version=5 -debugger-tuning=gdb -fdebug-compilation-dir=/root/code/multi/nccl/src -fcoverage-compilation-dir=/root/code/multi/nccl/src -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -I . -I /root/code/multi/nccl/include -D CUDA_MAJOR=12 -D CUDA_MINOR=2 -I /usr/local/cuda/include -I /opt/x-ray/third-party/include -D ENABLE_SLOW -D PROFAPI -I include -I /opt/x-ray/third-party/include -I /opt/x-ray/third-party/rdma-core/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -O3 -Wall -Wno-unused-function -Wno-sign-compare -Wvla -fdeprecated-macro -ferror-limit 19 -fvisibility=hidden -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fcxx-exceptions -fexceptions -vectorize-loops -vectorize-slp -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x c++ /root/code/multi/nccl/src/init.cc
V[13:46:31.735] System include extraction: target extracted: "x86_64-linux-gnu"
V[13:46:31.735] System include extraction: adding  /usr/include/c++/9
V[13:46:31.735] System include extraction: adding  /usr/include/x86_64-linux-gnu/c++/9
V[13:46:31.735] System include extraction: adding  /usr/include/c++/9/backward
V[13:46:31.735] System include extraction: adding  /usr/lib/gcc/x86_64-linux-gnu/9/include
V[13:46:31.735] System include extraction: adding  /usr/local/include
V[13:46:31.735] System include extraction: adding  /usr/include/x86_64-linux-gnu
V[13:46:31.735] System include extraction: adding  /usr/include
I[13:46:31.735] Built preamble of size 227472 for file /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h version 1 in 0.02 seconds
I[13:46:31.735] --> workspace/semanticTokens/refresh(1)
V[13:46:31.735] >>> {"id":1,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

I[13:46:31.736] --> textDocument/clangd.fileStatus
V[13:46:31.736] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///root/code/multi/nccl/src/init.cc"}}

V[13:46:31.736] Building first preamble for /root/code/multi/nccl/src/init.cc version 1
V[13:46:31.738] <<< {"id":1,"jsonrpc":"2.0","result":null}

I[13:46:31.738] <-- reply(1)
V[13:46:31.739] System includes extractor: builtin headers /usr/lib/gcc/x86_64-linux-gnu/9/include excluded
I[13:46:31.739] System includes extractor: successfully executed /usr/bin/g++
	got includes: "/usr/include/c++/9, /usr/include/x86_64-linux-gnu/c++/9, /usr/include/c++/9/backward, /usr/local/include, /usr/include/x86_64-linux-gnu, /usr/include"
	got target: "x86_64-linux-gnu"
I[13:46:31.739] ASTWorker building file /root/code/multi/nccl/src/profile.cc version 1 with command 
[/root/code/multi/nccl/src]
/usr/bin/g++ --driver-mode=g++ -c -I. -I/root/code/multi/nccl/include -DCUDA_MAJOR=12 -DCUDA_MINOR=2 -fPIC -fvisibility=hidden -Wall -Wno-unused-function -Wno-sign-compare -Wvla -I /usr/local/cuda/include -I/opt/x-ray/third-party/include -O3 -g -DENABLE_SLOW -DPROFAPI -Iinclude -o /root/code/multi/nccl/obj/profile.o -I/opt/x-ray/third-party/include -I/opt/x-ray/third-party/rdma-core/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include --target=x86_64-linux-gnu -resource-dir=/root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -- /root/code/multi/nccl/src/profile.cc
V[13:46:31.741] Driver produced command: cc1 -cc1 -triple x86_64-unknown-linux-gnu -fsyntax-only -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name profile.cc -mrelocation-model pic -pic-level 2 -fhalf-no-semantic-interposition -mframe-pointer=none -fmath-errno -ffp-contract=on -fno-rounding-math -mconstructor-aliases -funwind-tables=2 -target-cpu x86-64 -tune-cpu generic -debug-info-kind=constructor -dwarf-version=5 -debugger-tuning=gdb -fdebug-compilation-dir=/root/code/multi/nccl/src -fcoverage-compilation-dir=/root/code/multi/nccl/src -resource-dir /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18 -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/lib/gcc/x86_64-linux-gnu/9/include -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -isystem /usr/include/c++/9 -isystem /usr/include/x86_64-linux-gnu/c++/9 -isystem /usr/include/c++/9/backward -isystem /usr/local/include -isystem /usr/include/x86_64-linux-gnu -isystem /usr/include -I . -I /root/code/multi/nccl/include -D CUDA_MAJOR=12 -D CUDA_MINOR=2 -I /usr/local/cuda/include -I /opt/x-ray/third-party/include -D ENABLE_SLOW -D PROFAPI -I include -I /opt/x-ray/third-party/include -I /opt/x-ray/third-party/rdma-core/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++ -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/x86_64-linux-gnu -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../include/c++/backward -internal-isystem /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include -internal-isystem /usr/local/include -internal-isystem /usr/bin/../lib/gcc/x86_64-linux-gnu/10/../../../../x86_64-linux-gnu/include -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include -internal-externc-isystem /usr/include -O3 -Wall -Wno-unused-function -Wno-sign-compare -Wvla -fdeprecated-macro -ferror-limit 19 -fvisibility=hidden -fgnuc-version=4.2.1 -fskip-odr-check-in-gmf -fcxx-exceptions -fexceptions -vectorize-loops -vectorize-slp -no-round-trip-args -faddrsig -D__GCC_HAVE_DWARF2_CFI_ASM=1 -x c++ /root/code/multi/nccl/src/profile.cc
I[13:46:31.741] --> textDocument/clangd.fileStatus
V[13:46:31.741] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Update","uri":"file:///root/code/multi/nccl/src/profile.cc"}}

V[13:46:31.741] Building first preamble for /root/code/multi/nccl/src/profile.cc version 1
V[13:46:31.754] indexed preamble AST for /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h version 1:
  symbol slab: 5 symbols, 5376 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:31.755] Build dynamic index for header symbols with estimated memory usage of 26300 bytes
V[13:46:31.757] <<< {"id":5,"jsonrpc":"2.0","method":"textDocument/semanticTokens/full","params":{"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:31.757] <-- textDocument/semanticTokens/full(5)
V[13:46:31.856] indexed file AST for /root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h version 1:
  symbol slab: 48 symbols, 23544 bytes
  ref slab: 51 symbols, 91 refs, 5760 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:31.856] Build dynamic index for main-file symbols with estimated memory usage of 48472 bytes
I[13:46:31.856] --> textDocument/publishDiagnostics
V[13:46:31.856] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"pp_hash_error","message":"\"Never use <ia32intrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"relatedInformation":[],"severity":1,"source":"clang"}],"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h","version":1}}

I[13:46:31.856] --> textDocument/inactiveRegions
V[13:46:31.856] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[{"end":{"character":55,"line":25},"start":{"character":0,"line":24}},{"end":{"character":1,"line":327},"start":{"character":0,"line":300}},{"end":{"character":36,"line":772},"start":{"character":0,"line":734}}],"textDocument":{"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h"}}}

I[13:46:31.857] --> textDocument/clangd.fileStatus
V[13:46:31.857] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h"}}

V[13:46:31.918] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_getcsr'
V[13:46:31.920] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_setcsr'
V[13:46:31.930] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_sfence'
V[13:46:31.931] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_clflush'
V[13:46:31.931] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_lfence'
V[13:46:31.931] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_mfence'
V[13:46:31.932] <<< {"id":6,"jsonrpc":"2.0","method":"textDocument/foldingRange","params":{"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:31.932] <-- textDocument/foldingRange(6)
I[13:46:31.934] --> reply:textDocument/foldingRange(6) 1 ms
V[13:46:31.934] >>> {"id":6,"jsonrpc":"2.0","result":[{"endLine":18,"kind":"region","startCharacter":25,"startLine":12},{"endCharacter":2,"endLine":17,"kind":"region","startCharacter":45,"startLine":14},{"endCharacter":4,"endLine":16,"kind":"region","startCharacter":33,"startLine":15},{"endLine":40,"kind":"region","startCharacter":25,"startLine":30},{"endLine":57,"kind":"region","startCharacter":32,"startLine":43},{"endCharacter":2,"endLine":46,"kind":"region","startCharacter":53,"startLine":45},{"endLine":87,"kind":"region","startCharacter":137,"startLine":60},{"endCharacter":2,"endLine":70,"kind":"region","startCharacter":38,"startLine":66},{"endLine":147,"kind":"region","startCharacter":37,"startLine":90},{"endCharacter":2,"endLine":146,"kind":"region","startCharacter":15,"startLine":91},{"endCharacter":4,"endLine":136,"kind":"region","startCharacter":33,"startLine":101},{"endCharacter":6,"endLine":123,"kind":"region","startCharacter":44,"startLine":106},{"endCharacter":8,"endLine":108,"kind":"region","startCharacter":46,"startLine":107},{"endCharacter":8,"endLine":111,"kind":"region","startCharacter":46,"startLine":110},{"endCharacter":8,"endLine":114,"kind":"region","startCharacter":44,"startLine":113},{"endCharacter":8,"endLine":118,"kind":"region","startCharacter":45,"startLine":116},{"endCharacter":8,"endLine":122,"kind":"region","startCharacter":43,"startLine":120},{"endCharacter":6,"endLine":128,"kind":"region","startCharacter":61,"startLine":125},{"endCharacter":6,"endLine":135,"kind":"region","startCharacter":50,"startLine":130},{"endCharacter":4,"endLine":143,"kind":"region","startCharacter":25,"startLine":139},{"endLine":158,"kind":"region","startCharacter":24,"startLine":150},{"endCharacter":2,"endLine":156,"kind":"region","startCharacter":21,"startLine":153},{"endLine":271,"kind":"region","startCharacter":12,"startLine":176},{"endLine":183,"kind":"comment","startCharacter":2,"startLine":178},{"endLine":212,"kind":"comment","startCharacter":2,"startLine":205},{"endCharacter":36,"endLine":261,"kind":"comment","startCharacter":2,"startLine":260}]}

V[13:46:32.016] BackgroundIndex: building version 1 after loading index from disk
V[13:46:32.026] <<< {"id":7,"jsonrpc":"2.0","method":"textDocument/documentSymbol","params":{"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:32.026] <-- textDocument/documentSymbol(7)
V[13:46:32.252] Dropped diagnostic: /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h: in included file: "Never use <fma4intrin.h> directly; include <x86intrin.h> instead."
V[13:46:32.265] BackgroundIndex: serving version 1 (37266342 bytes)
I[13:46:32.283] --> $/progress
V[13:46:32.283] >>> {"jsonrpc":"2.0","method":"$/progress","params":{"token":"backgroundIndexProgress","value":{"kind":"report","message":"0/1","percentage":0}}}

I[13:46:32.283] --> $/progress
V[13:46:32.283] >>> {"jsonrpc":"2.0","method":"$/progress","params":{"token":"backgroundIndexProgress","value":{"kind":"end"}}}

I[13:46:32.380] Built preamble of size 3370628 for file /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h version 1 in 0.67 seconds
I[13:46:32.380] --> workspace/semanticTokens/refresh(2)
V[13:46:32.380] >>> {"id":2,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

I[13:46:32.380] --> textDocument/clangd.fileStatus
V[13:46:32.380] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Build AST","uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h"}}

V[13:46:32.381] <<< {"id":2,"jsonrpc":"2.0","result":null}

I[13:46:32.381] <-- reply(2)
V[13:46:32.390] indexed file AST for /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h version 1:
  symbol slab: 1 symbols, 4448 bytes
  ref slab: 1 symbols, 1 refs, 4248 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:32.390] Build dynamic index for main-file symbols with estimated memory usage of 57432 bytes
I[13:46:32.390] --> textDocument/publishDiagnostics
V[13:46:32.390] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"pp_hash_error","message":"In included file: \"Never use <ia32intrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":26},"start":{"character":9,"line":26}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/ia32intrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"pp_hash_error","message":"In included file: \"Never use <fma4intrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":35},"start":{"character":9,"line":35}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/fma4intrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"pp_hash_error","message":"In included file: \"Never use <xopintrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":37},"start":{"character":9,"line":37}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/xopintrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"pp_hash_error","message":"In included file: \"Never use <lwpintrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":39},"start":{"character":9,"line":39}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/lwpintrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"pp_hash_error","message":"In included file: \"Never use <tbmintrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":41},"start":{"character":9,"line":41}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/tbmintrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"pp_hash_error","message":"In included file: \"Never use <mwaitxintrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":45},"start":{"character":9,"line":45}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":10},"start":{"character":1,"line":10}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/mwaitxintrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"pp_hash_error","message":"In included file: \"Never use <clzerointrin.h> directly; include <x86intrin.h> instead.\"","range":{"end":{"character":10,"line":47},"start":{"character":9,"line":47}},"relatedInformation":[{"location":{"range":{"end":{"character":6,"line":9},"start":{"character":1,"line":9}},"uri":"file:///root/.vscode-server/data/User/globalStorage/llvm-vs-code-extensions.vscode-clangd/install/18.1.3/clangd_18.1.3/lib/clang/18/include/clzerointrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"}],"uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h","version":1}}

I[13:46:32.390] --> textDocument/inactiveRegions
V[13:46:32.390] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[],"textDocument":{"uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h"}}}

I[13:46:32.390] --> textDocument/clangd.fileStatus
V[13:46:32.390] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h"}}

V[13:46:32.599] indexed preamble AST for /usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h version 1:
  symbol slab: 7644 symbols, 2731992 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:32.651] Build dynamic index for header symbols with estimated memory usage of 6276520 bytes
V[13:46:32.883] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
V[13:46:32.898] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
V[13:46:32.900] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
V[13:46:32.912] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
V[13:46:32.986] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
V[13:46:32.989] Dropped diagnostic: /root/code/multi/nccl/src/init.cc: in included file: definition of builtin function '_mm_setcsr'
V[13:46:33.000] Dropped diagnostic: /root/code/multi/nccl/src/init.cc: in included file: definition of builtin function '_mm_sfence'
V[13:46:33.000] Dropped diagnostic: /root/code/multi/nccl/src/init.cc: in included file: definition of builtin function '_mm_clflush'
V[13:46:33.000] Dropped diagnostic: /root/code/multi/nccl/src/init.cc: in included file: definition of builtin function '_mm_lfence'
V[13:46:33.001] Dropped diagnostic: /root/code/multi/nccl/src/init.cc: in included file: definition of builtin function '_mm_mfence'
V[13:46:33.179] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
I[13:46:33.182] Built preamble of size 8201284 for file /root/code/multi/nccl/src/graph/topo.h version 1 in 1.45 seconds
I[13:46:33.182] --> workspace/semanticTokens/refresh(3)
V[13:46:33.182] >>> {"id":3,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

I[13:46:33.182] Indexing c++17 standard library in the context of /root/code/multi/nccl/src/graph/topo.h
I[13:46:33.182] --> textDocument/clangd.fileStatus
V[13:46:33.182] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Build AST","uri":"file:///root/code/multi/nccl/src/graph/topo.h"}}

I[13:46:33.183] --> textDocument/clangd.fileStatus
V[13:46:33.183] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, parsing main file","uri":"file:///root/code/multi/nccl/src/graph/topo.h"}}

V[13:46:33.184] <<< {"id":3,"jsonrpc":"2.0","result":null}

I[13:46:33.184] <-- reply(3)
V[13:46:33.210] indexed file AST for /root/code/multi/nccl/src/graph/topo.h version 1:
  symbol slab: 117 symbols, 31360 bytes
  ref slab: 131 symbols, 244 refs, 14464 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:33.210] Build dynamic index for main-file symbols with estimated memory usage of 143328 bytes
I[13:46:33.210] --> textDocument/publishDiagnostics
V[13:46:33.210] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"unused-includes","codeDescription":{"href":"https://clangd.llvm.org/guides/include-cleaner"},"message":"Included header core.h is not used directly (fix available)","range":{"end":{"character":17,"line":10},"start":{"character":0,"line":10}},"relatedInformation":[],"severity":2,"source":"clangd","tags":[1]}],"uri":"file:///root/code/multi/nccl/src/graph/topo.h","version":1}}

I[13:46:33.210] --> textDocument/inactiveRegions
V[13:46:33.210] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[],"textDocument":{"uri":"file:///root/code/multi/nccl/src/graph/topo.h"}}}

I[13:46:33.211] --> textDocument/clangd.fileStatus
V[13:46:33.211] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/code/multi/nccl/src/graph/topo.h"}}

V[13:46:33.310] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
I[13:46:33.314] Built preamble of size 8660576 for file /root/code/multi/nccl/src/graph/paths.cc version 3 in 1.58 seconds
I[13:46:33.314] --> workspace/semanticTokens/refresh(4)
V[13:46:33.314] >>> {"id":4,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

I[13:46:33.314] --> textDocument/clangd.fileStatus
V[13:46:33.315] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Build AST","uri":"file:///root/code/multi/nccl/src/graph/paths.cc"}}

V[13:46:33.318] <<< {"id":4,"jsonrpc":"2.0","result":null}

I[13:46:33.318] <-- reply(4)
V[13:46:33.336] Dropped diagnostic: include/nvtx3/nvtx3.hpp: suggest braces around initialization of subobject
I[13:46:33.340] Built preamble of size 8651116 for file /root/code/multi/nccl/src/collectives.cc version 1 in 1.61 seconds
I[13:46:33.341] --> workspace/semanticTokens/refresh(5)
I[13:46:33.341] --> textDocument/clangd.fileStatus
V[13:46:33.341] >>> {"id":5,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

V[13:46:33.341] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Build AST","uri":"file:///root/code/multi/nccl/src/collectives.cc"}}

I[13:46:33.341] --> textDocument/clangd.fileStatus
V[13:46:33.341] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, parsing main file","uri":"file:///root/code/multi/nccl/src/collectives.cc"}}

V[13:46:33.342] <<< {"id":5,"jsonrpc":"2.0","result":null}

I[13:46:33.342] <-- reply(5)
V[13:46:33.427] indexed file AST for /root/code/multi/nccl/src/collectives.cc version 1:
  symbol slab: 24 symbols, 9784 bytes
  ref slab: 83 symbols, 423 refs, 19584 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:33.428] Build dynamic index for main-file symbols with estimated memory usage of 197944 bytes
I[13:46:33.428] --> textDocument/publishDiagnostics
V[13:46:33.428] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"unused-includes","codeDescription":{"href":"https://clangd.llvm.org/guides/include-cleaner"},"message":"Included header argcheck.h is not used directly (fix available)","range":{"end":{"character":67,"line":6},"start":{"character":0,"line":6}},"relatedInformation":[],"severity":2,"source":"clangd","tags":[1]}],"uri":"file:///root/code/multi/nccl/src/collectives.cc","version":1}}

I[13:46:33.428] --> textDocument/inactiveRegions
V[13:46:33.428] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[],"textDocument":{"uri":"file:///root/code/multi/nccl/src/collectives.cc"}}}

I[13:46:33.430] --> textDocument/clangd.fileStatus
V[13:46:33.430] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/code/multi/nccl/src/collectives.cc"}}

V[13:46:33.469] indexed file AST for /root/code/multi/nccl/src/graph/paths.cc version 3:
  symbol slab: 39 symbols, 13264 bytes
  ref slab: 170 symbols, 1363 refs, 55424 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:33.470] Build dynamic index for main-file symbols with estimated memory usage of 322928 bytes
I[13:46:33.470] --> textDocument/publishDiagnostics
V[13:46:33.470] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"unused-includes","codeDescription":{"href":"https://clangd.llvm.org/guides/include-cleaner"},"message":"Included header core.h is not used directly (fix available)","range":{"end":{"character":17,"line":6},"start":{"character":0,"line":6}},"relatedInformation":[],"severity":2,"source":"clangd","tags":[1]}],"uri":"file:///root/code/multi/nccl/src/graph/paths.cc","version":3}}

I[13:46:33.470] --> textDocument/inactiveRegions
V[13:46:33.470] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[{"end":{"character":81,"line":116},"start":{"character":0,"line":116}},{"end":{"character":62,"line":133},"start":{"character":0,"line":125}}],"textDocument":{"uri":"file:///root/code/multi/nccl/src/graph/paths.cc"}}}

I[13:46:33.478] --> textDocument/clangd.fileStatus
V[13:46:33.478] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/code/multi/nccl/src/graph/paths.cc"}}

V[13:46:33.518] Dropped diagnostic: /root/code/multi/nccl/src/profile.cc: in included file: definition of builtin function '_mm_pause'
I[13:46:33.521] Built preamble of size 9931332 for file /root/code/multi/nccl/src/profile.cc version 1 in 1.78 seconds
I[13:46:33.522] --> workspace/semanticTokens/refresh(6)
V[13:46:33.522] >>> {"id":6,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

I[13:46:33.522] --> textDocument/clangd.fileStatus
V[13:46:33.522] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"parsing includes, running Build AST","uri":"file:///root/code/multi/nccl/src/profile.cc"}}

V[13:46:33.526] <<< {"id":6,"jsonrpc":"2.0","result":null}

I[13:46:33.526] <-- reply(6)
V[13:46:33.587] indexed preamble AST for /root/code/multi/nccl/src/graph/topo.h version 1:
  symbol slab: 15046 symbols, 5916295 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 365 relations, 8728 bytes
V[13:46:33.598] indexed file AST for /root/code/multi/nccl/src/profile.cc version 1:
  symbol slab: 38 symbols, 17128 bytes
  ref slab: 144 symbols, 555 refs, 26752 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:33.599] Build dynamic index for main-file symbols with estimated memory usage of 404512 bytes
I[13:46:33.600] --> textDocument/publishDiagnostics
V[13:46:33.600] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"builtin_definition","message":"In included file: definition of builtin function '__rdtsc'","range":{"end":{"character":10,"line":2},"start":{"character":9,"line":2}},"relatedInformation":[{"location":{"range":{"end":{"character":7,"line":111},"start":{"character":0,"line":111}},"uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/ia32intrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"unused-includes","codeDescription":{"href":"https://clangd.llvm.org/guides/include-cleaner"},"message":"Included header checks.h is not used directly (fix available)","range":{"end":{"character":19,"line":6},"start":{"character":0,"line":6}},"relatedInformation":[],"severity":2,"source":"clangd","tags":[1]}],"uri":"file:///root/code/multi/nccl/src/profile.cc","version":1}}

I[13:46:33.600] --> textDocument/inactiveRegions
V[13:46:33.600] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[],"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

V[13:46:33.604] ASTWorker running DocumentSymbols on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.611] --> reply:textDocument/documentSymbol(1) 1887 ms
V[13:46:33.613] >>> {"id":1,"jsonrpc":"2.0","result":[{"detail":"const char *[]","kind":13,"name":"ncclDevFuncTableStr","range":{"end":{"character":40,"line":9},"start":{"character":0,"line":9}},"selectionRange":{"end":{"character":38,"line":9},"start":{"character":19,"line":9}}},{"detail":"size_t","kind":13,"name":"ncclDevFuncTableStrCount","range":{"end":{"character":38,"line":10},"start":{"character":0,"line":10}},"selectionRange":{"end":{"character":38,"line":10},"start":{"character":14,"line":10}}},{"detail":"void ()","kind":12,"name":"getAllDevFuncStr","range":{"end":{"character":1,"line":19},"start":{"character":0,"line":12}},"selectionRange":{"end":{"character":21,"line":12},"start":{"character":5,"line":12}}},{"detail":"ncclKrRing_t *","kind":13,"name":"ncclKrRing","range":{"end":{"character":38,"line":21},"start":{"character":0,"line":21}},"selectionRange":{"end":{"character":31,"line":21},"start":{"character":21,"line":21}}},{"detail":"pthread_t","kind":13,"name":"ncclScanKernelThread","range":{"end":{"character":37,"line":22},"start":{"character":0,"line":22}},"selectionRange":{"end":{"character":37,"line":22},"start":{"character":17,"line":22}}},{"detail":"void *(void *)","kind":12,"name":"scanKrRing","range":{"end":{"character":35,"line":23},"start":{"character":0,"line":23}},"selectionRange":{"end":{"character":23,"line":23},"start":{"character":13,"line":23}}},{"detail":"void ()","kind":12,"name":"getAllDevFuncStr","range":{"end":{"character":23,"line":24},"start":{"character":0,"line":24}},"selectionRange":{"end":{"character":21,"line":24},"start":{"character":5,"line":24}}},{"detail":"pthread_mutex_t","kind":13,"name":"initLock","range":{"end":{"character":59,"line":26},"start":{"character":0,"line":26}},"selectionRange":{"end":{"character":31,"line":26},"start":{"character":23,"line":26}}},{"detail":"bool","kind":13,"name":"initialized","range":{"end":{"character":31,"line":27},"start":{"character":0,"line":27}},"selectionRange":{"end":{"character":23,"line":27},"start":{"character":12,"line":27}}},{"detail":"int64_t","kind":13,"name":"freq","range":{"end":{"character":24,"line":29},"start":{"character":0,"line":29}},"selectionRange":{"end":{"character":19,"line":29},"start":{"character":15,"line":29}}},{"detail":"void ()","kind":12,"name":"calibrate","range":{"end":{"character":1,"line":41},"start":{"character":0,"line":30}},"selectionRange":{"end":{"character":21,"line":30},"start":{"character":12,"line":30}}},{"detail":"void ()","kind":12,"name":"initKernelRecord","range":{"end":{"character":1,"line":58},"start":{"character":0,"line":43}},"selectionRange":{"end":{"character":28,"line":43},"start":{"character":12,"line":43}}},{"detail":"ncclKernelRecord_t *(uint64_t, int, int, int, int, uint64_t)","kind":12,"name":"allocKrRingSlot","range":{"end":{"character":1,"line":88},"start":{"character":0,"line":60}},"selectionRange":{"end":{"character":36,"line":60},"start":{"character":21,"line":60}}},{"detail":"void *(void *)","kind":12,"name":"scanKrRing","range":{"end":{"character":1,"line":148},"start":{"character":0,"line":90}},"selectionRange":{"end":{"character":23,"line":90},"start":{"character":13,"line":90}}},{"detail":"void ()","kind":12,"name":"initProfileOnce","range":{"end":{"character":1,"line":159},"start":{"character":0,"line":150}},"selectionRange":{"end":{"character":20,"line":150},"start":{"character":5,"line":150}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduce","range":{"end":{"character":13,"line":186},"start":{"character":0,"line":186}},"selectionRange":{"end":{"character":13,"line":186},"start":{"character":0,"line":186}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduce","range":{"end":{"character":14,"line":188},"start":{"character":0,"line":186}},"selectionRange":{"end":{"character":38,"line":186},"start":{"character":28,"line":186}}}],"detail":"(ncclResult_t, ncclReduce, const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":188},"start":{"character":0,"line":186}},"selectionRange":{"end":{"character":13,"line":186},"start":{"character":0,"line":186}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclBroadcast","range":{"end":{"character":13,"line":191},"start":{"character":0,"line":191}},"selectionRange":{"end":{"character":13,"line":191},"start":{"character":0,"line":191}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclBroadcast","range":{"end":{"character":14,"line":193},"start":{"character":0,"line":191}},"selectionRange":{"end":{"character":41,"line":191},"start":{"character":28,"line":191}}}],"detail":"(ncclResult_t, ncclBroadcast, const void* sendbuff, void* recvbuff, size_t count, ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":193},"start":{"character":0,"line":191}},"selectionRange":{"end":{"character":13,"line":191},"start":{"character":0,"line":191}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm *, cudaStream_t)","kind":12,"name":"ncclAllReduce","range":{"end":{"character":13,"line":195},"start":{"character":0,"line":195}},"selectionRange":{"end":{"character":13,"line":195},"start":{"character":0,"line":195}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm *, cudaStream_t)","kind":12,"name":"ncclAllReduce","range":{"end":{"character":14,"line":196},"start":{"character":0,"line":195}},"selectionRange":{"end":{"character":41,"line":195},"start":{"character":28,"line":195}}}],"detail":"(ncclResult_t, ncclAllReduce, const void* sendbuff, void* recvbuff, size_t count, ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":196},"start":{"character":0,"line":195}},"selectionRange":{"end":{"character":13,"line":195},"start":{"character":0,"line":195}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduceScatter","range":{"end":{"character":13,"line":198},"start":{"character":0,"line":198}},"selectionRange":{"end":{"character":13,"line":198},"start":{"character":0,"line":198}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduceScatter","range":{"end":{"character":14,"line":199},"start":{"character":0,"line":198}},"selectionRange":{"end":{"character":45,"line":198},"start":{"character":28,"line":198}}}],"detail":"(ncclResult_t, ncclReduceScatter, const void* sendbuff, void* recvbuff, size_t recvcount ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":199},"start":{"character":0,"line":198}},"selectionRange":{"end":{"character":13,"line":198},"start":{"character":0,"line":198}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclAllGather","range":{"end":{"character":13,"line":201},"start":{"character":0,"line":201}},"selectionRange":{"end":{"character":13,"line":201},"start":{"character":0,"line":201}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclAllGather","range":{"end":{"character":14,"line":203},"start":{"character":0,"line":201}},"selectionRange":{"end":{"character":41,"line":201},"start":{"character":28,"line":201}}}],"detail":"(ncclResult_t, ncclAllGather, const void* sendbuff, void* recvbuff, size_t sendcount ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":203},"start":{"character":0,"line":201}},"selectionRange":{"end":{"character":13,"line":201},"start":{"character":0,"line":201}}},{"children":[{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupStart","range":{"end":{"character":13,"line":215},"start":{"character":0,"line":215}},"selectionRange":{"end":{"character":13,"line":215},"start":{"character":0,"line":215}}},{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupStart","range":{"end":{"character":14,"line":216},"start":{"character":0,"line":215}},"selectionRange":{"end":{"character":42,"line":215},"start":{"character":28,"line":215}}}],"detail":"(ncclResult_t, ncclGroupStart)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":216},"start":{"character":0,"line":215}},"selectionRange":{"end":{"character":13,"line":215},"start":{"character":0,"line":215}}},{"children":[{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupEnd","range":{"end":{"character":13,"line":218},"start":{"character":0,"line":218}},"selectionRange":{"end":{"character":13,"line":218},"start":{"character":0,"line":218}}},{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupEnd","range":{"end":{"character":14,"line":219},"start":{"character":0,"line":218}},"selectionRange":{"end":{"character":40,"line":218},"start":{"character":28,"line":218}}}],"detail":"(ncclResult_t, ncclGroupEnd)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":219},"start":{"character":0,"line":218}},"selectionRange":{"end":{"character":13,"line":218},"start":{"character":0,"line":218}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, void *, size_t, void **)","kind":12,"name":"ncclCommRegister","range":{"end":{"character":13,"line":221},"start":{"character":0,"line":221}},"selectionRange":{"end":{"character":13,"line":221},"start":{"character":0,"line":221}}},{"detail":"ncclResult_t (const ncclComm_t, void *, size_t, void **)","kind":12,"name":"ncclCommRegister","range":{"end":{"character":14,"line":222},"start":{"character":0,"line":221}},"selectionRange":{"end":{"character":44,"line":221},"start":{"character":28,"line":221}}}],"detail":"(ncclResult_t, ncclCommRegister, const ncclComm_t comm, void* buff, size_t size, void ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":222},"start":{"character":0,"line":221}},"selectionRange":{"end":{"character":13,"line":221},"start":{"character":0,"line":221}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, void *)","kind":12,"name":"ncclCommDeregister","range":{"end":{"character":13,"line":224},"start":{"character":0,"line":224}},"selectionRange":{"end":{"character":13,"line":224},"start":{"character":0,"line":224}}},{"detail":"ncclResult_t (const ncclComm_t, void *)","kind":12,"name":"ncclCommDeregister","range":{"end":{"character":14,"line":225},"start":{"character":0,"line":224}},"selectionRange":{"end":{"character":46,"line":224},"start":{"character":28,"line":224}}}],"detail":"(ncclResult_t, ncclCommDeregister, const ncclComm_t comm, void* handle)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":225},"start":{"character":0,"line":224}},"selectionRange":{"end":{"character":13,"line":224},"start":{"character":0,"line":224}}},{"children":[{"detail":"ncclResult_t (int *)","kind":12,"name":"ncclGetVersion","range":{"end":{"character":13,"line":227},"start":{"character":0,"line":227}},"selectionRange":{"end":{"character":13,"line":227},"start":{"character":0,"line":227}}},{"detail":"ncclResult_t (int *)","kind":12,"name":"ncclGetVersion","range":{"end":{"character":14,"line":228},"start":{"character":0,"line":227}},"selectionRange":{"end":{"character":42,"line":227},"start":{"character":28,"line":227}}}],"detail":"(ncclResult_t, ncclGetVersion, int* version)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":228},"start":{"character":0,"line":227}},"selectionRange":{"end":{"character":13,"line":227},"start":{"character":0,"line":227}}},{"children":[{"detail":"ncclResult_t (ncclUniqueId *)","kind":12,"name":"ncclGetUniqueId","range":{"end":{"character":13,"line":230},"start":{"character":0,"line":230}},"selectionRange":{"end":{"character":13,"line":230},"start":{"character":0,"line":230}}},{"detail":"ncclResult_t (ncclUniqueId *)","kind":12,"name":"ncclGetUniqueId","range":{"end":{"character":14,"line":231},"start":{"character":0,"line":230}},"selectionRange":{"end":{"character":43,"line":230},"start":{"character":28,"line":230}}}],"detail":"(ncclResult_t, ncclGetUniqueId, ncclUniqueId* out)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":231},"start":{"character":0,"line":230}},"selectionRange":{"end":{"character":13,"line":230},"start":{"character":0,"line":230}}},{"children":[{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int)","kind":12,"name":"ncclCommInitRank","range":{"end":{"character":13,"line":233},"start":{"character":0,"line":233}},"selectionRange":{"end":{"character":13,"line":233},"start":{"character":0,"line":233}}},{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int)","kind":12,"name":"ncclCommInitRank","range":{"end":{"character":14,"line":234},"start":{"character":0,"line":233}},"selectionRange":{"end":{"character":44,"line":233},"start":{"character":28,"line":233}}}],"detail":"(ncclResult_t, ncclCommInitRank, ncclComm_t* newcomm, int nranks, ncclUniqueId commId ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":234},"start":{"character":0,"line":233}},"selectionRange":{"end":{"character":13,"line":233},"start":{"character":0,"line":233}}},{"children":[{"detail":"ncclResult_t (ncclComm_t *, int, const int *)","kind":12,"name":"ncclCommInitAll","range":{"end":{"character":13,"line":236},"start":{"character":0,"line":236}},"selectionRange":{"end":{"character":13,"line":236},"start":{"character":0,"line":236}}},{"detail":"ncclResult_t (ncclComm_t *, int, const int *)","kind":12,"name":"ncclCommInitAll","range":{"end":{"character":14,"line":237},"start":{"character":0,"line":236}},"selectionRange":{"end":{"character":43,"line":236},"start":{"character":28,"line":236}}}],"detail":"(ncclResult_t, ncclCommInitAll, ncclComm_t* comms, int ndev, const int* devlist)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":237},"start":{"character":0,"line":236}},"selectionRange":{"end":{"character":13,"line":236},"start":{"character":0,"line":236}}},{"children":[{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int, ncclConfig_t *)","kind":12,"name":"ncclCommInitRankConfig","range":{"end":{"character":13,"line":239},"start":{"character":0,"line":239}},"selectionRange":{"end":{"character":13,"line":239},"start":{"character":0,"line":239}}},{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int, ncclConfig_t *)","kind":12,"name":"ncclCommInitRankConfig","range":{"end":{"character":14,"line":240},"start":{"character":0,"line":239}},"selectionRange":{"end":{"character":50,"line":239},"start":{"character":28,"line":239}}}],"detail":"(ncclResult_t, ncclCommInitRankConfig, ncclComm_t* comm, int nranks, ncclUniqueId ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":240},"start":{"character":0,"line":239}},"selectionRange":{"end":{"character":13,"line":239},"start":{"character":0,"line":239}}},{"children":[{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommFinalize","range":{"end":{"character":13,"line":242},"start":{"character":0,"line":242}},"selectionRange":{"end":{"character":13,"line":242},"start":{"character":0,"line":242}}},{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommFinalize","range":{"end":{"character":14,"line":243},"start":{"character":0,"line":242}},"selectionRange":{"end":{"character":44,"line":242},"start":{"character":28,"line":242}}}],"detail":"(ncclResult_t, ncclCommFinalize, ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":243},"start":{"character":0,"line":242}},"selectionRange":{"end":{"character":13,"line":242},"start":{"character":0,"line":242}}},{"children":[{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommDestroy","range":{"end":{"character":13,"line":245},"start":{"character":0,"line":245}},"selectionRange":{"end":{"character":13,"line":245},"start":{"character":0,"line":245}}},{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommDestroy","range":{"end":{"character":14,"line":246},"start":{"character":0,"line":245}},"selectionRange":{"end":{"character":43,"line":245},"start":{"character":28,"line":245}}}],"detail":"(ncclResult_t, ncclCommDestroy, ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":246},"start":{"character":0,"line":245}},"selectionRange":{"end":{"character":13,"line":245},"start":{"character":0,"line":245}}},{"children":[{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommAbort","range":{"end":{"character":13,"line":248},"start":{"character":0,"line":248}},"selectionRange":{"end":{"character":13,"line":248},"start":{"character":0,"line":248}}},{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommAbort","range":{"end":{"character":14,"line":249},"start":{"character":0,"line":248}},"selectionRange":{"end":{"character":41,"line":248},"start":{"character":28,"line":248}}}],"detail":"(ncclResult_t, ncclCommAbort, ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":249},"start":{"character":0,"line":248}},"selectionRange":{"end":{"character":13,"line":248},"start":{"character":0,"line":248}}},{"children":[{"detail":"ncclResult_t (ncclComm_t, int, int, ncclComm_t *, ncclConfig_t *)","kind":12,"name":"ncclCommSplit","range":{"end":{"character":13,"line":251},"start":{"character":0,"line":251}},"selectionRange":{"end":{"character":13,"line":251},"start":{"character":0,"line":251}}},{"detail":"ncclResult_t (ncclComm_t, int, int, ncclComm_t *, ncclConfig_t *)","kind":12,"name":"ncclCommSplit","range":{"end":{"character":14,"line":252},"start":{"character":0,"line":251}},"selectionRange":{"end":{"character":41,"line":251},"start":{"character":28,"line":251}}}],"detail":"(ncclResult_t, ncclCommSplit, ncclComm_t comm, int color, int key, ncclComm_t *newcomm ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":252},"start":{"character":0,"line":251}},"selectionRange":{"end":{"character":13,"line":251},"start":{"character":0,"line":251}}},{"children":[{"detail":"const char *(ncclResult_t)","kind":12,"name":"ncclGetErrorString","range":{"end":{"character":13,"line":254},"start":{"character":0,"line":254}},"selectionRange":{"end":{"character":13,"line":254},"start":{"character":0,"line":254}}},{"detail":"const char *(ncclResult_t)","kind":12,"name":"ncclGetErrorString","range":{"end":{"character":14,"line":255},"start":{"character":0,"line":254}},"selectionRange":{"end":{"character":45,"line":254},"start":{"character":27,"line":254}}}],"detail":"(const char*, ncclGetErrorString, ncclResult_t code)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":255},"start":{"character":0,"line":254}},"selectionRange":{"end":{"character":13,"line":254},"start":{"character":0,"line":254}}},{"children":[{"detail":"const char *(const ncclComm_t)","kind":12,"name":"ncclGetLastError","range":{"end":{"character":13,"line":257},"start":{"character":0,"line":257}},"selectionRange":{"end":{"character":13,"line":257},"start":{"character":0,"line":257}}},{"detail":"const char *(const ncclComm_t)","kind":12,"name":"ncclGetLastError","range":{"end":{"character":14,"line":258},"start":{"character":0,"line":257}},"selectionRange":{"end":{"character":43,"line":257},"start":{"character":27,"line":257}}}],"detail":"(const char*, ncclGetLastError, const ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":258},"start":{"character":0,"line":257}},"selectionRange":{"end":{"character":13,"line":257},"start":{"character":0,"line":257}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCount","range":{"end":{"character":13,"line":263},"start":{"character":0,"line":263}},"selectionRange":{"end":{"character":13,"line":263},"start":{"character":0,"line":263}}},{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCount","range":{"end":{"character":14,"line":264},"start":{"character":0,"line":263}},"selectionRange":{"end":{"character":41,"line":263},"start":{"character":28,"line":263}}}],"detail":"(ncclResult_t, ncclCommCount, const ncclComm_t comm, int* count)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":264},"start":{"character":0,"line":263}},"selectionRange":{"end":{"character":13,"line":263},"start":{"character":0,"line":263}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCuDevice","range":{"end":{"character":13,"line":266},"start":{"character":0,"line":266}},"selectionRange":{"end":{"character":13,"line":266},"start":{"character":0,"line":266}}},{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCuDevice","range":{"end":{"character":14,"line":267},"start":{"character":0,"line":266}},"selectionRange":{"end":{"character":44,"line":266},"start":{"character":28,"line":266}}}],"detail":"(ncclResult_t, ncclCommCuDevice, const ncclComm_t comm, int* devid)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":267},"start":{"character":0,"line":266}},"selectionRange":{"end":{"character":13,"line":266},"start":{"character":0,"line":266}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommUserRank","range":{"end":{"character":13,"line":269},"start":{"character":0,"line":269}},"selectionRange":{"end":{"character":13,"line":269},"start":{"character":0,"line":269}}},{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommUserRank","range":{"end":{"character":14,"line":270},"start":{"character":0,"line":269}},"selectionRange":{"end":{"character":44,"line":269},"start":{"character":28,"line":269}}}],"detail":"(ncclResult_t, ncclCommUserRank, const ncclComm_t comm, int* rank)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":270},"start":{"character":0,"line":269}},"selectionRange":{"end":{"character":13,"line":269},"start":{"character":0,"line":269}}}]}

V[13:46:33.613] ASTWorker running codeAction on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.613] --> reply:textDocument/codeAction(2) 1888 ms
V[13:46:33.613] >>> {"id":2,"jsonrpc":"2.0","result":[]}

V[13:46:33.613] ASTWorker running DocumentLinks on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.613] --> reply:textDocument/documentLink(3) 1882 ms
V[13:46:33.613] >>> {"id":3,"jsonrpc":"2.0","result":[{"range":{"end":{"character":27,"line":0},"start":{"character":9,"line":0}},"target":"file:///opt/x-ray/third-party/include/lttng/tracelog.h"},{"range":{"end":{"character":21,"line":1},"start":{"character":9,"line":1}},"target":"file:///usr/include/x86_64-linux-gnu/sys/time.h"},{"range":{"end":{"character":22,"line":2},"start":{"character":9,"line":2}},"target":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/x86intrin.h"},{"range":{"end":{"character":17,"line":4},"start":{"character":9,"line":4}},"target":"file:///root/code/multi/nccl/include/nccl.h"},{"range":{"end":{"character":18,"line":5},"start":{"character":9,"line":5}},"target":"file:///root/code/multi/nccl/src/include/alloc.h"},{"range":{"end":{"character":19,"line":6},"start":{"character":9,"line":6}},"target":"file:///root/code/multi/nccl/src/include/checks.h"},{"range":{"end":{"character":20,"line":7},"start":{"character":9,"line":7}},"target":"file:///root/code/multi/nccl/include/nccl_tp.h"}]}

V[13:46:33.613] ASTWorker running InlayHints on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.614] --> reply:textDocument/inlayHint(4) 1883 ms
V[13:46:33.615] >>> {"id":4,"jsonrpc":"2.0","result":[{"kind":2,"label":"funcIndex:","paddingLeft":false,"paddingRight":true,"position":{"character":32,"line":16}},{"kind":2,"label":"funcName:","paddingLeft":false,"paddingRight":true,"position":{"character":35,"line":16}},{"kind":2,"label":"tv:","paddingLeft":false,"paddingRight":true,"position":{"character":17,"line":32}},{"kind":2,"label":"tz:","paddingLeft":false,"paddingRight":true,"position":{"character":22,"line":32}},{"kind":2,"label":"tv:","paddingLeft":false,"paddingRight":true,"position":{"character":17,"line":37}},{"kind":2,"label":"tz:","paddingLeft":false,"paddingRight":true,"position":{"character":22,"line":37}},{"kind":2,"label":"name:","paddingLeft":false,"paddingRight":true,"position":{"character":18,"line":45}},{"kind":2,"label":"len:","paddingLeft":false,"paddingRight":true,"position":{"character":28,"line":45}},{"kind":2,"label":"dest:","paddingLeft":false,"paddingRight":true,"position":{"character":12,"line":46}},{"kind":2,"label":"src:","paddingLeft":false,"paddingRight":true,"position":{"character":22,"line":46}},{"kind":2,"label":"n:","paddingLeft":false,"paddingRight":true,"position":{"character":33,"line":46}},{"kind":2,"label":"device:","paddingLeft":false,"paddingRight":true,"position":{"character":16,"line":49}},{"kind":2,"label":"cpuFreq:","paddingLeft":false,"paddingRight":true,"position":{"character":41,"line":50}},{"kind":2,"label":"ptr:","paddingLeft":false,"paddingRight":true,"position":{"character":40,"line":53}},{"kind":2,"label":"nelem:","paddingLeft":false,"paddingRight":true,"position":{"character":53,"line":53}},{"kind":2,"label":"mutex:","paddingLeft":false,"paddingRight":true,"position":{"character":30,"line":55}},{"kind":2,"label":"mutexattr:","paddingLeft":false,"paddingRight":true,"position":{"character":50,"line":55}},{"kind":2,"label":"newthread:","paddingLeft":false,"paddingRight":true,"position":{"character":17,"line":57}},{"kind":2,"label":"attr:","paddingLeft":false,"paddingRight":true,"position":{"character":40,"line":57}},{"kind":2,"label":"start_routine:","paddingLeft":false,"paddingRight":true,"position":{"character":46,"line":57}},{"kind":2,"label":"arg:","paddingLeft":false,"paddingRight":true,"position":{"character":58,"line":57}},{"kind":2,"label":"mutex:","paddingLeft":false,"paddingRight":true,"position":{"character":21,"line":63}},{"kind":2,"label":"mutex:","paddingLeft":false,"paddingRight":true,"position":{"character":25,"line":67}},{"kind":2,"label":"fmt:","paddingLeft":false,"paddingRight":true,"position":{"character":6,"line":69}},{"kind":2,"label":"mutex:","paddingLeft":false,"paddingRight":true,"position":{"character":23,"line":72}}]}

V[13:46:33.615] ASTWorker running SemanticHighlights on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.618] --> reply:textDocument/semanticTokens/full(5) 1860 ms
V[13:46:33.618] >>> {"id":5,"jsonrpc":"2.0","result":{"data":[9,19,19,0,131089,1,7,6,18,66048,0,7,24,0,131073,2,5,16,3,131075,1,6,1,1,16387,1,6,1,1,16384,0,1,1,21,0,0,4,1,1,16384,0,1,1,21,0,0,1,24,0,131072,0,26,1,1,16384,0,1,2,21,0,1,8,19,0,131088,0,20,1,1,16384,1,6,10,19,131072,0,26,1,1,16384,0,3,19,0,131088,0,20,1,1,16384,5,7,12,8,65536,0,14,10,0,65539,0,13,4,19,131072,1,7,9,18,66048,0,10,20,0,65539,1,13,10,3,65537,0,17,4,2,16387,1,5,16,3,131073,2,7,15,8,131584,0,16,8,0,65539,0,11,25,19,131072,1,12,11,0,65539,2,7,7,18,66048,0,8,4,0,65539,0,7,1,21,0,1,12,9,3,65539,1,11,7,8,131584,0,8,2,1,16387,1,4,12,3,131584,0,13,1,21,0,0,1,2,1,18432,0,4,4,19,131072,1,4,8,18,66048,0,9,10,1,16387,1,11,4,1,16387,0,7,1,21,0,0,2,2,1,16384,0,3,6,6,33280,0,6,1,21,0,0,5,1,21,0,0,2,2,1,16384,0,3,7,6,33280,1,4,8,18,66048,0,9,5,1,16387,2,4,12,3,131584,0,13,1,21,0,0,1,2,1,18432,0,4,4,19,131072,2,4,4,1,16384,0,5,2,21,0,0,3,2,1,16384,0,3,6,6,33280,0,6,1,21,0,0,5,1,21,0,0,2,2,1,16384,0,3,7,6,33280,1,4,4,0,65536,0,5,1,21,0,0,2,7,18,66048,0,8,10,1,16384,0,10,1,21,0,0,4,1,21,0,0,1,4,1,16384,3,12,16,3,65539,1,7,8,1,16387,1,6,11,3,131584,0,12,8,1,18432,0,17,8,1,16384,0,11,2,21,0,1,4,7,3,131584,0,8,8,1,18432,0,28,8,1,16384,2,6,7,1,16387,0,10,1,21,0,1,2,13,3,131072,0,14,1,21,0,0,1,7,1,18432,1,2,10,19,131072,0,29,8,1,16384,0,10,4,0,65536,2,2,16,3,131072,1,2,12,10,131072,0,13,3,1,16387,0,6,18,19,131072,0,19,1,21,0,0,1,10,0,67584,1,2,6,19,131072,0,7,3,1,16384,0,3,2,21,0,0,2,11,11,131088,1,6,2,1,16387,0,5,18,3,131584,0,19,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,2,6,19,131072,0,7,2,1,16384,0,2,2,21,0,1,2,14,3,131584,0,15,1,21,0,0,1,20,0,67584,0,22,4,19,131072,0,6,10,3,67584,0,12,4,19,131072,3,0,18,8,65536,0,21,15,3,131075,0,16,8,18,66048,0,9,8,2,16387,0,14,4,2,16387,0,10,9,2,16387,0,15,8,2,16387,0,14,13,2,16387,0,15,8,18,66048,0,9,11,2,16387,1,12,5,1,16387,1,12,3,1,16387,1,2,18,3,131584,0,19,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,2,5,1,16384,0,6,1,21,0,0,2,10,0,65536,0,12,5,6,32768,1,2,3,1,16384,0,4,1,21,0,0,2,10,0,65536,0,12,3,6,32768,1,6,3,1,16384,0,4,1,21,0,0,2,5,1,16384,0,6,2,21,0,0,3,14,0,65552,1,4,20,3,131584,0,21,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,4,18,19,131072,1,105,9,2,16384,0,11,8,2,16384,0,10,5,1,16384,0,7,3,1,16384,1,11,4,19,131072,2,2,20,3,131584,0,21,1,21,0,0,1,10,0,65536,0,12,5,6,34816,2,2,18,8,65536,0,20,4,1,16387,0,7,1,21,0,0,1,10,0,65536,0,12,7,6,32768,0,8,3,1,16384,0,3,1,21,0,0,1,14,0,65552,1,2,6,3,131584,0,7,4,1,18432,0,16,18,8,65536,1,2,4,1,16384,0,6,4,6,32768,0,5,1,21,0,0,2,4,2,16384,1,2,4,1,16384,0,6,9,6,32768,0,10,1,21,0,0,2,9,2,16384,1,2,4,1,16384,0,6,9,6,32768,0,10,1,21,0,0,2,8,2,16384,1,2,4,1,16384,0,6,13,6,32768,0,14,1,21,0,0,2,13,2,16384,1,2,4,1,16384,0,6,11,6,32768,0,12,1,21,0,0,2,11,2,16384,1,2,4,1,16384,0,6,2,6,32768,0,3,1,21,0,0,2,3,1,16384,1,2,10,19,131072,0,26,4,1,16384,0,6,2,6,32768,0,4,8,2,16384,0,10,4,2,16384,0,6,9,2,16384,0,11,8,2,16384,0,10,13,2,16384,0,15,11,2,16384,2,2,18,3,131584,0,19,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,2,10,0,65536,0,12,3,6,32768,0,3,2,21,0,1,2,20,3,131584,0,21,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,9,4,1,16384,3,13,10,3,65539,0,17,4,2,16387,2,14,5,1,16387,1,14,3,1,16387,1,14,2,1,16387,1,14,6,1,16387,1,4,18,3,131584,0,19,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,4,5,1,16384,0,6,1,21,0,0,2,10,0,65536,0,12,5,6,32768,1,4,3,1,16384,0,4,1,21,0,0,2,10,0,65536,0,12,3,6,32768,1,4,20,3,131584,0,21,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,4,6,1,16384,0,6,1,21,0,0,1,5,1,16384,0,5,1,21,0,1,8,2,1,16384,0,2,1,21,0,0,1,5,1,16384,0,7,2,1,16384,0,2,1,21,0,0,1,3,1,16384,0,5,2,1,16384,0,2,2,21,0,1,6,18,8,65536,0,20,4,1,16387,0,7,1,21,0,0,1,10,0,65536,0,12,7,6,32768,0,8,2,1,16384,0,2,1,21,0,0,1,14,0,65552,1,10,7,1,16387,1,10,5,1,16387,1,10,1,1,16387,1,10,1,1,16384,0,1,1,21,0,0,4,1,1,16384,0,1,1,21,0,0,1,4,1,16384,0,6,13,6,32768,0,15,1,1,16384,0,1,2,21,0,1,11,1,21,0,0,2,4,1,16384,0,6,11,6,32768,0,12,1,21,0,0,7,2,21,0,0,2,1,1,16384,3,11,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,11,6,32768,0,11,2,21,0,1,10,7,1,16384,0,7,2,21,0,2,11,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,9,6,32768,0,9,2,21,0,1,10,5,1,16384,0,5,2,21,0,2,11,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,11,6,32768,0,11,1,21,0,1,10,10,19,131072,0,31,4,1,16384,0,6,2,6,32768,0,4,1,1,16384,0,3,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,11,6,32768,0,13,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,9,6,32768,1,10,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,11,6,32768,0,12,1,21,0,0,3,1,21,0,0,1,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,11,6,32768,2,11,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,9,6,32768,0,9,1,21,0,1,10,10,19,131072,0,29,4,1,16384,0,6,2,6,32768,0,4,1,1,16384,0,3,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,9,6,32768,0,9,1,21,0,0,3,1,21,0,0,1,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,11,6,32768,1,10,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,9,6,32768,0,10,1,21,0,0,3,1,21,0,0,1,4,1,16384,0,6,8,6,32768,0,9,1,1,16384,0,3,9,6,32768,3,10,4,1,16384,0,6,7,6,32768,0,8,2,21,0,0,3,7,1,16384,0,8,2,21,0,0,3,4,1,16384,0,6,5,6,32768,0,6,2,21,0,0,3,5,1,16384,1,8,10,19,131072,0,25,4,1,16384,0,6,2,6,32768,0,4,7,1,16384,0,9,5,1,16384,1,8,4,1,16384,0,6,7,6,32768,0,8,1,21,0,0,2,7,1,16384,1,8,4,1,16384,0,6,5,6,32768,0,6,1,21,0,0,2,5,1,16384,2,9,6,1,16384,0,6,2,21,0,0,2,2,1,16384,0,2,1,21,0,0,3,2,21,0,0,3,5,1,16384,0,5,2,21,0,0,2,4,1,16384,0,6,9,6,32768,1,7,11,19,131072,1,8,10,19,131072,0,29,4,1,16384,0,6,2,6,32768,0,4,4,1,16384,0,6,2,6,32768,0,3,12,6,32768,0,14,4,1,16384,0,6,13,6,32768,2,8,6,1,16384,0,7,1,21,0,0,2,2,1,16384,1,8,6,3,131584,0,7,4,1,18432,0,16,1,21,0,0,1,4,1,16384,4,7,6,1,16384,0,6,2,21,0,0,2,5,1,16384,0,5,1,21,0,1,6,18,3,131584,0,19,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,6,10,0,65536,0,12,5,6,32768,0,6,1,21,0,0,2,6,1,16384,0,6,1,21,0,1,6,20,3,131584,0,21,1,21,0,0,1,10,0,65536,0,12,5,6,34816,1,6,10,19,131072,0,25,6,1,16384,0,6,1,21,0,3,4,6,3,131584,0,9,1,21,0,4,5,15,3,131075,1,22,1,21,0,0,1,11,0,65536,0,13,16,19,131072,1,2,18,3,131584,0,19,1,21,0,0,1,8,0,67584,1,6,1,21,0,0,1,11,0,65536,1,4,9,3,65536,1,4,16,3,65536,1,21,1,21,0,0,1,11,0,65536,0,19,16,19,131072,2,2,20,3,131584,0,21,1,21,0,0,1,8,0,67584,3,8,13,19,131073,6,12,10,19,131072,3,8,14,19,131073,2,12,10,19,131072,14,0,13,19,131072,0,14,12,10,131072,0,14,10,3,131075,0,24,8,2,16403,0,16,8,2,16387,0,10,6,18,66048,0,7,5,2,16387,0,7,14,10,131072,0,15,8,2,16387,1,4,11,10,131072,0,12,2,2,16387,0,8,4,2,16387,0,6,10,12,65536,0,11,4,2,16387,0,6,12,12,65536,0,13,6,2,16387,1,0,14,19,131072,0,27,8,2,16400,0,10,8,2,18432,0,10,5,2,16384,0,7,8,2,16384,0,10,2,2,16384,0,4,4,2,16384,0,6,4,2,18432,0,6,6,2,18432,3,0,13,19,131072,0,14,12,10,131072,0,14,13,3,131075,0,27,8,2,16403,0,16,8,2,16387,0,10,6,18,66048,0,7,5,2,16387,0,7,14,10,131072,0,15,8,2,16387,0,14,4,2,16387,1,4,10,12,65536,0,11,4,2,16387,0,6,12,12,65536,0,13,6,2,16387,1,0,14,19,131072,0,30,8,2,16400,0,10,8,2,18432,0,10,5,2,16384,0,7,8,2,16384,0,10,4,2,16384,0,6,4,2,18432,0,6,6,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,13,3,131075,0,27,8,2,16403,0,16,8,2,16387,0,10,6,18,66048,0,7,5,2,16387,0,7,14,10,131072,0,15,8,2,16387,0,10,11,10,131072,0,12,2,2,16387,0,4,8,8,131072,0,10,4,2,16387,0,6,12,12,65536,0,13,6,2,16387,1,0,14,19,131072,0,30,8,2,16400,0,11,8,2,18432,0,11,5,2,16384,0,8,8,2,16384,0,11,2,2,16384,0,5,4,2,18432,0,7,6,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,17,3,131075,0,31,8,2,16403,0,16,8,2,16387,0,10,6,18,66048,0,7,9,2,16387,0,11,14,10,131072,0,15,8,2,16387,0,10,11,10,131072,0,12,2,2,16387,0,4,10,12,65536,0,11,4,2,16387,0,6,12,12,65536,0,13,6,2,16387,1,0,14,19,131072,0,34,8,2,16400,0,10,8,2,18432,0,10,9,2,16384,0,11,8,2,16384,0,10,2,2,16384,0,4,4,2,18432,0,6,6,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,13,3,131075,0,27,8,2,16403,0,16,8,2,16387,0,10,6,18,66048,0,7,9,2,16387,1,4,14,10,131072,0,15,8,2,16387,0,10,10,12,65536,0,11,4,2,16387,0,6,12,12,65536,0,13,6,2,16387,1,0,14,19,131072,0,30,8,2,16400,0,10,8,2,18432,0,10,9,2,16384,0,11,8,2,16384,0,10,4,2,18432,0,6,6,2,18432,12,0,13,19,131072,0,14,12,10,131072,0,14,14,3,131075,1,0,14,19,131072,2,0,13,19,131072,0,14,12,10,131072,0,14,12,3,131075,1,0,14,19,131072,2,0,13,19,131072,0,14,12,10,131072,0,14,16,3,131075,0,24,10,12,65536,0,11,4,2,16403,0,12,4,2,16387,0,6,6,18,66048,0,7,4,2,16387,0,13,6,2,16387,1,0,14,19,131072,0,33,4,2,18448,0,6,4,2,18432,0,6,4,2,16384,0,6,6,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,18,3,131075,0,26,10,12,65536,0,11,4,2,16403,0,12,6,2,16387,1,0,14,19,131072,0,35,4,2,18448,0,6,6,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,14,3,131075,0,21,7,2,16387,1,0,14,19,131072,0,31,7,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,15,3,131075,0,17,12,8,131072,0,14,3,2,16387,1,0,14,19,131072,0,32,3,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,16,3,131075,0,18,10,12,65536,0,12,7,2,16387,0,13,6,2,16387,0,8,12,8,131072,0,13,6,2,16387,0,12,6,2,16387,1,0,14,19,131072,0,33,7,2,18432,0,10,6,2,16384,0,9,6,2,16384,0,9,6,2,16384,2,0,13,19,131072,0,14,12,10,131072,0,14,15,3,131075,0,17,10,12,65536,0,12,5,2,16387,0,11,4,2,16387,0,17,7,2,16403,1,0,14,19,131072,0,32,5,2,18432,0,8,4,2,16384,0,7,7,2,16400,2,0,13,19,131072,0,14,12,10,131072,0,14,22,3,131075,0,24,10,12,65536,0,12,4,2,16387,0,10,6,2,16387,0,8,12,8,131072,0,13,6,2,16387,0,12,6,2,16387,0,8,12,8,65536,0,14,6,2,16387,1,0,14,19,131072,0,39,4,2,18432,0,6,6,2,16384,0,9,6,2,16384,0,9,6,2,16384,0,9,6,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,16,3,131075,0,18,10,12,65536,0,11,4,2,16387,1,0,14,19,131072,0,33,4,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,15,3,131075,0,17,10,12,65536,0,11,4,2,16387,1,0,14,19,131072,0,32,4,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,13,3,131075,0,15,10,12,65536,0,11,4,2,16387,1,0,14,19,131072,0,30,4,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,13,3,131075,0,15,10,12,65536,0,11,4,2,16387,0,10,5,2,16387,0,11,3,2,16387,0,5,10,12,65536,0,12,7,2,16387,0,9,12,8,65536,0,14,6,2,16387,1,0,14,19,131072,0,30,4,2,18432,0,7,5,2,16384,0,8,3,2,16384,0,5,7,2,18432,0,9,6,2,18432,2,0,13,19,131072,0,27,18,3,131075,0,20,12,10,131072,0,13,4,2,16387,1,0,14,19,131072,0,35,4,2,16384,2,0,13,19,131072,0,27,16,3,131075,0,24,10,12,65536,0,11,4,2,16403,1,0,14,19,131072,0,33,4,2,18448,5,0,13,19,131072,0,14,12,10,131072,0,14,13,3,131075,0,21,10,12,65536,0,11,4,2,16403,0,11,5,2,16387,1,0,14,19,131072,0,30,4,2,18448,0,7,5,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,16,3,131075,0,24,10,12,65536,0,11,4,2,16403,0,11,5,2,16387,1,0,14,19,131072,0,33,4,2,18448,0,7,5,2,18432,2,0,13,19,131072,0,14,12,10,131072,0,14,16,3,131075,0,24,10,12,65536,0,11,4,2,16403,0,11,4,2,16387,1,0,14,19,131072,0,33,4,2,18448,0,7,4,2,18432],"resultId":"1"}}

V[13:46:33.618] ASTWorker running DocumentSymbols on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.622] --> reply:textDocument/documentSymbol(7) 1595 ms
V[13:46:33.623] >>> {"id":7,"jsonrpc":"2.0","result":[{"detail":"const char *[]","kind":13,"name":"ncclDevFuncTableStr","range":{"end":{"character":40,"line":9},"start":{"character":0,"line":9}},"selectionRange":{"end":{"character":38,"line":9},"start":{"character":19,"line":9}}},{"detail":"size_t","kind":13,"name":"ncclDevFuncTableStrCount","range":{"end":{"character":38,"line":10},"start":{"character":0,"line":10}},"selectionRange":{"end":{"character":38,"line":10},"start":{"character":14,"line":10}}},{"detail":"void ()","kind":12,"name":"getAllDevFuncStr","range":{"end":{"character":1,"line":19},"start":{"character":0,"line":12}},"selectionRange":{"end":{"character":21,"line":12},"start":{"character":5,"line":12}}},{"detail":"ncclKrRing_t *","kind":13,"name":"ncclKrRing","range":{"end":{"character":38,"line":21},"start":{"character":0,"line":21}},"selectionRange":{"end":{"character":31,"line":21},"start":{"character":21,"line":21}}},{"detail":"pthread_t","kind":13,"name":"ncclScanKernelThread","range":{"end":{"character":37,"line":22},"start":{"character":0,"line":22}},"selectionRange":{"end":{"character":37,"line":22},"start":{"character":17,"line":22}}},{"detail":"void *(void *)","kind":12,"name":"scanKrRing","range":{"end":{"character":35,"line":23},"start":{"character":0,"line":23}},"selectionRange":{"end":{"character":23,"line":23},"start":{"character":13,"line":23}}},{"detail":"void ()","kind":12,"name":"getAllDevFuncStr","range":{"end":{"character":23,"line":24},"start":{"character":0,"line":24}},"selectionRange":{"end":{"character":21,"line":24},"start":{"character":5,"line":24}}},{"detail":"pthread_mutex_t","kind":13,"name":"initLock","range":{"end":{"character":59,"line":26},"start":{"character":0,"line":26}},"selectionRange":{"end":{"character":31,"line":26},"start":{"character":23,"line":26}}},{"detail":"bool","kind":13,"name":"initialized","range":{"end":{"character":31,"line":27},"start":{"character":0,"line":27}},"selectionRange":{"end":{"character":23,"line":27},"start":{"character":12,"line":27}}},{"detail":"int64_t","kind":13,"name":"freq","range":{"end":{"character":24,"line":29},"start":{"character":0,"line":29}},"selectionRange":{"end":{"character":19,"line":29},"start":{"character":15,"line":29}}},{"detail":"void ()","kind":12,"name":"calibrate","range":{"end":{"character":1,"line":41},"start":{"character":0,"line":30}},"selectionRange":{"end":{"character":21,"line":30},"start":{"character":12,"line":30}}},{"detail":"void ()","kind":12,"name":"initKernelRecord","range":{"end":{"character":1,"line":58},"start":{"character":0,"line":43}},"selectionRange":{"end":{"character":28,"line":43},"start":{"character":12,"line":43}}},{"detail":"ncclKernelRecord_t *(uint64_t, int, int, int, int, uint64_t)","kind":12,"name":"allocKrRingSlot","range":{"end":{"character":1,"line":88},"start":{"character":0,"line":60}},"selectionRange":{"end":{"character":36,"line":60},"start":{"character":21,"line":60}}},{"detail":"void *(void *)","kind":12,"name":"scanKrRing","range":{"end":{"character":1,"line":148},"start":{"character":0,"line":90}},"selectionRange":{"end":{"character":23,"line":90},"start":{"character":13,"line":90}}},{"detail":"void ()","kind":12,"name":"initProfileOnce","range":{"end":{"character":1,"line":159},"start":{"character":0,"line":150}},"selectionRange":{"end":{"character":20,"line":150},"start":{"character":5,"line":150}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduce","range":{"end":{"character":13,"line":186},"start":{"character":0,"line":186}},"selectionRange":{"end":{"character":13,"line":186},"start":{"character":0,"line":186}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduce","range":{"end":{"character":14,"line":188},"start":{"character":0,"line":186}},"selectionRange":{"end":{"character":38,"line":186},"start":{"character":28,"line":186}}}],"detail":"(ncclResult_t, ncclReduce, const void* sendbuff, void* recvbuff, size_t count, ncclDataType_t ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":188},"start":{"character":0,"line":186}},"selectionRange":{"end":{"character":13,"line":186},"start":{"character":0,"line":186}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclBroadcast","range":{"end":{"character":13,"line":191},"start":{"character":0,"line":191}},"selectionRange":{"end":{"character":13,"line":191},"start":{"character":0,"line":191}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, int, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclBroadcast","range":{"end":{"character":14,"line":193},"start":{"character":0,"line":191}},"selectionRange":{"end":{"character":41,"line":191},"start":{"character":28,"line":191}}}],"detail":"(ncclResult_t, ncclBroadcast, const void* sendbuff, void* recvbuff, size_t count, ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":193},"start":{"character":0,"line":191}},"selectionRange":{"end":{"character":13,"line":191},"start":{"character":0,"line":191}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm *, cudaStream_t)","kind":12,"name":"ncclAllReduce","range":{"end":{"character":13,"line":195},"start":{"character":0,"line":195}},"selectionRange":{"end":{"character":13,"line":195},"start":{"character":0,"line":195}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm *, cudaStream_t)","kind":12,"name":"ncclAllReduce","range":{"end":{"character":14,"line":196},"start":{"character":0,"line":195}},"selectionRange":{"end":{"character":41,"line":195},"start":{"character":28,"line":195}}}],"detail":"(ncclResult_t, ncclAllReduce, const void* sendbuff, void* recvbuff, size_t count, ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":196},"start":{"character":0,"line":195}},"selectionRange":{"end":{"character":13,"line":195},"start":{"character":0,"line":195}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduceScatter","range":{"end":{"character":13,"line":198},"start":{"character":0,"line":198}},"selectionRange":{"end":{"character":13,"line":198},"start":{"character":0,"line":198}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclRedOp_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclReduceScatter","range":{"end":{"character":14,"line":199},"start":{"character":0,"line":198}},"selectionRange":{"end":{"character":45,"line":198},"start":{"character":28,"line":198}}}],"detail":"(ncclResult_t, ncclReduceScatter, const void* sendbuff, void* recvbuff, size_t recvcount ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":199},"start":{"character":0,"line":198}},"selectionRange":{"end":{"character":13,"line":198},"start":{"character":0,"line":198}}},{"children":[{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclAllGather","range":{"end":{"character":13,"line":201},"start":{"character":0,"line":201}},"selectionRange":{"end":{"character":13,"line":201},"start":{"character":0,"line":201}}},{"detail":"ncclResult_t (const void *, void *, size_t, ncclDataType_t, ncclComm_t, cudaStream_t)","kind":12,"name":"ncclAllGather","range":{"end":{"character":14,"line":203},"start":{"character":0,"line":201}},"selectionRange":{"end":{"character":41,"line":201},"start":{"character":28,"line":201}}}],"detail":"(ncclResult_t, ncclAllGather, const void* sendbuff, void* recvbuff, size_t sendcount ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":203},"start":{"character":0,"line":201}},"selectionRange":{"end":{"character":13,"line":201},"start":{"character":0,"line":201}}},{"children":[{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupStart","range":{"end":{"character":13,"line":215},"start":{"character":0,"line":215}},"selectionRange":{"end":{"character":13,"line":215},"start":{"character":0,"line":215}}},{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupStart","range":{"end":{"character":14,"line":216},"start":{"character":0,"line":215}},"selectionRange":{"end":{"character":42,"line":215},"start":{"character":28,"line":215}}}],"detail":"(ncclResult_t, ncclGroupStart)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":216},"start":{"character":0,"line":215}},"selectionRange":{"end":{"character":13,"line":215},"start":{"character":0,"line":215}}},{"children":[{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupEnd","range":{"end":{"character":13,"line":218},"start":{"character":0,"line":218}},"selectionRange":{"end":{"character":13,"line":218},"start":{"character":0,"line":218}}},{"detail":"ncclResult_t ()","kind":12,"name":"ncclGroupEnd","range":{"end":{"character":14,"line":219},"start":{"character":0,"line":218}},"selectionRange":{"end":{"character":40,"line":218},"start":{"character":28,"line":218}}}],"detail":"(ncclResult_t, ncclGroupEnd)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":219},"start":{"character":0,"line":218}},"selectionRange":{"end":{"character":13,"line":218},"start":{"character":0,"line":218}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, void *, size_t, void **)","kind":12,"name":"ncclCommRegister","range":{"end":{"character":13,"line":221},"start":{"character":0,"line":221}},"selectionRange":{"end":{"character":13,"line":221},"start":{"character":0,"line":221}}},{"detail":"ncclResult_t (const ncclComm_t, void *, size_t, void **)","kind":12,"name":"ncclCommRegister","range":{"end":{"character":14,"line":222},"start":{"character":0,"line":221}},"selectionRange":{"end":{"character":44,"line":221},"start":{"character":28,"line":221}}}],"detail":"(ncclResult_t, ncclCommRegister, const ncclComm_t comm, void* buff, size_t size, void ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":222},"start":{"character":0,"line":221}},"selectionRange":{"end":{"character":13,"line":221},"start":{"character":0,"line":221}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, void *)","kind":12,"name":"ncclCommDeregister","range":{"end":{"character":13,"line":224},"start":{"character":0,"line":224}},"selectionRange":{"end":{"character":13,"line":224},"start":{"character":0,"line":224}}},{"detail":"ncclResult_t (const ncclComm_t, void *)","kind":12,"name":"ncclCommDeregister","range":{"end":{"character":14,"line":225},"start":{"character":0,"line":224}},"selectionRange":{"end":{"character":46,"line":224},"start":{"character":28,"line":224}}}],"detail":"(ncclResult_t, ncclCommDeregister, const ncclComm_t comm, void* handle)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":225},"start":{"character":0,"line":224}},"selectionRange":{"end":{"character":13,"line":224},"start":{"character":0,"line":224}}},{"children":[{"detail":"ncclResult_t (int *)","kind":12,"name":"ncclGetVersion","range":{"end":{"character":13,"line":227},"start":{"character":0,"line":227}},"selectionRange":{"end":{"character":13,"line":227},"start":{"character":0,"line":227}}},{"detail":"ncclResult_t (int *)","kind":12,"name":"ncclGetVersion","range":{"end":{"character":14,"line":228},"start":{"character":0,"line":227}},"selectionRange":{"end":{"character":42,"line":227},"start":{"character":28,"line":227}}}],"detail":"(ncclResult_t, ncclGetVersion, int* version)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":228},"start":{"character":0,"line":227}},"selectionRange":{"end":{"character":13,"line":227},"start":{"character":0,"line":227}}},{"children":[{"detail":"ncclResult_t (ncclUniqueId *)","kind":12,"name":"ncclGetUniqueId","range":{"end":{"character":13,"line":230},"start":{"character":0,"line":230}},"selectionRange":{"end":{"character":13,"line":230},"start":{"character":0,"line":230}}},{"detail":"ncclResult_t (ncclUniqueId *)","kind":12,"name":"ncclGetUniqueId","range":{"end":{"character":14,"line":231},"start":{"character":0,"line":230}},"selectionRange":{"end":{"character":43,"line":230},"start":{"character":28,"line":230}}}],"detail":"(ncclResult_t, ncclGetUniqueId, ncclUniqueId* out)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":231},"start":{"character":0,"line":230}},"selectionRange":{"end":{"character":13,"line":230},"start":{"character":0,"line":230}}},{"children":[{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int)","kind":12,"name":"ncclCommInitRank","range":{"end":{"character":13,"line":233},"start":{"character":0,"line":233}},"selectionRange":{"end":{"character":13,"line":233},"start":{"character":0,"line":233}}},{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int)","kind":12,"name":"ncclCommInitRank","range":{"end":{"character":14,"line":234},"start":{"character":0,"line":233}},"selectionRange":{"end":{"character":44,"line":233},"start":{"character":28,"line":233}}}],"detail":"(ncclResult_t, ncclCommInitRank, ncclComm_t* newcomm, int nranks, ncclUniqueId commId ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":234},"start":{"character":0,"line":233}},"selectionRange":{"end":{"character":13,"line":233},"start":{"character":0,"line":233}}},{"children":[{"detail":"ncclResult_t (ncclComm_t *, int, const int *)","kind":12,"name":"ncclCommInitAll","range":{"end":{"character":13,"line":236},"start":{"character":0,"line":236}},"selectionRange":{"end":{"character":13,"line":236},"start":{"character":0,"line":236}}},{"detail":"ncclResult_t (ncclComm_t *, int, const int *)","kind":12,"name":"ncclCommInitAll","range":{"end":{"character":14,"line":237},"start":{"character":0,"line":236}},"selectionRange":{"end":{"character":43,"line":236},"start":{"character":28,"line":236}}}],"detail":"(ncclResult_t, ncclCommInitAll, ncclComm_t* comms, int ndev, const int* devlist)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":237},"start":{"character":0,"line":236}},"selectionRange":{"end":{"character":13,"line":236},"start":{"character":0,"line":236}}},{"children":[{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int, ncclConfig_t *)","kind":12,"name":"ncclCommInitRankConfig","range":{"end":{"character":13,"line":239},"start":{"character":0,"line":239}},"selectionRange":{"end":{"character":13,"line":239},"start":{"character":0,"line":239}}},{"detail":"ncclResult_t (ncclComm_t *, int, ncclUniqueId, int, ncclConfig_t *)","kind":12,"name":"ncclCommInitRankConfig","range":{"end":{"character":14,"line":240},"start":{"character":0,"line":239}},"selectionRange":{"end":{"character":50,"line":239},"start":{"character":28,"line":239}}}],"detail":"(ncclResult_t, ncclCommInitRankConfig, ncclComm_t* comm, int nranks, ncclUniqueId ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":240},"start":{"character":0,"line":239}},"selectionRange":{"end":{"character":13,"line":239},"start":{"character":0,"line":239}}},{"children":[{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommFinalize","range":{"end":{"character":13,"line":242},"start":{"character":0,"line":242}},"selectionRange":{"end":{"character":13,"line":242},"start":{"character":0,"line":242}}},{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommFinalize","range":{"end":{"character":14,"line":243},"start":{"character":0,"line":242}},"selectionRange":{"end":{"character":44,"line":242},"start":{"character":28,"line":242}}}],"detail":"(ncclResult_t, ncclCommFinalize, ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":243},"start":{"character":0,"line":242}},"selectionRange":{"end":{"character":13,"line":242},"start":{"character":0,"line":242}}},{"children":[{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommDestroy","range":{"end":{"character":13,"line":245},"start":{"character":0,"line":245}},"selectionRange":{"end":{"character":13,"line":245},"start":{"character":0,"line":245}}},{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommDestroy","range":{"end":{"character":14,"line":246},"start":{"character":0,"line":245}},"selectionRange":{"end":{"character":43,"line":245},"start":{"character":28,"line":245}}}],"detail":"(ncclResult_t, ncclCommDestroy, ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":246},"start":{"character":0,"line":245}},"selectionRange":{"end":{"character":13,"line":245},"start":{"character":0,"line":245}}},{"children":[{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommAbort","range":{"end":{"character":13,"line":248},"start":{"character":0,"line":248}},"selectionRange":{"end":{"character":13,"line":248},"start":{"character":0,"line":248}}},{"detail":"ncclResult_t (ncclComm_t)","kind":12,"name":"ncclCommAbort","range":{"end":{"character":14,"line":249},"start":{"character":0,"line":248}},"selectionRange":{"end":{"character":41,"line":248},"start":{"character":28,"line":248}}}],"detail":"(ncclResult_t, ncclCommAbort, ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":249},"start":{"character":0,"line":248}},"selectionRange":{"end":{"character":13,"line":248},"start":{"character":0,"line":248}}},{"children":[{"detail":"ncclResult_t (ncclComm_t, int, int, ncclComm_t *, ncclConfig_t *)","kind":12,"name":"ncclCommSplit","range":{"end":{"character":13,"line":251},"start":{"character":0,"line":251}},"selectionRange":{"end":{"character":13,"line":251},"start":{"character":0,"line":251}}},{"detail":"ncclResult_t (ncclComm_t, int, int, ncclComm_t *, ncclConfig_t *)","kind":12,"name":"ncclCommSplit","range":{"end":{"character":14,"line":252},"start":{"character":0,"line":251}},"selectionRange":{"end":{"character":41,"line":251},"start":{"character":28,"line":251}}}],"detail":"(ncclResult_t, ncclCommSplit, ncclComm_t comm, int color, int key, ncclComm_t *newcomm ...)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":252},"start":{"character":0,"line":251}},"selectionRange":{"end":{"character":13,"line":251},"start":{"character":0,"line":251}}},{"children":[{"detail":"const char *(ncclResult_t)","kind":12,"name":"ncclGetErrorString","range":{"end":{"character":13,"line":254},"start":{"character":0,"line":254}},"selectionRange":{"end":{"character":13,"line":254},"start":{"character":0,"line":254}}},{"detail":"const char *(ncclResult_t)","kind":12,"name":"ncclGetErrorString","range":{"end":{"character":14,"line":255},"start":{"character":0,"line":254}},"selectionRange":{"end":{"character":45,"line":254},"start":{"character":27,"line":254}}}],"detail":"(const char*, ncclGetErrorString, ncclResult_t code)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":255},"start":{"character":0,"line":254}},"selectionRange":{"end":{"character":13,"line":254},"start":{"character":0,"line":254}}},{"children":[{"detail":"const char *(const ncclComm_t)","kind":12,"name":"ncclGetLastError","range":{"end":{"character":13,"line":257},"start":{"character":0,"line":257}},"selectionRange":{"end":{"character":13,"line":257},"start":{"character":0,"line":257}}},{"detail":"const char *(const ncclComm_t)","kind":12,"name":"ncclGetLastError","range":{"end":{"character":14,"line":258},"start":{"character":0,"line":257}},"selectionRange":{"end":{"character":43,"line":257},"start":{"character":27,"line":257}}}],"detail":"(const char*, ncclGetLastError, const ncclComm_t comm)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":258},"start":{"character":0,"line":257}},"selectionRange":{"end":{"character":13,"line":257},"start":{"character":0,"line":257}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCount","range":{"end":{"character":13,"line":263},"start":{"character":0,"line":263}},"selectionRange":{"end":{"character":13,"line":263},"start":{"character":0,"line":263}}},{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCount","range":{"end":{"character":14,"line":264},"start":{"character":0,"line":263}},"selectionRange":{"end":{"character":41,"line":263},"start":{"character":28,"line":263}}}],"detail":"(ncclResult_t, ncclCommCount, const ncclComm_t comm, int* count)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":264},"start":{"character":0,"line":263}},"selectionRange":{"end":{"character":13,"line":263},"start":{"character":0,"line":263}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCuDevice","range":{"end":{"character":13,"line":266},"start":{"character":0,"line":266}},"selectionRange":{"end":{"character":13,"line":266},"start":{"character":0,"line":266}}},{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommCuDevice","range":{"end":{"character":14,"line":267},"start":{"character":0,"line":266}},"selectionRange":{"end":{"character":44,"line":266},"start":{"character":28,"line":266}}}],"detail":"(ncclResult_t, ncclCommCuDevice, const ncclComm_t comm, int* devid)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":267},"start":{"character":0,"line":266}},"selectionRange":{"end":{"character":13,"line":266},"start":{"character":0,"line":266}}},{"children":[{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommUserRank","range":{"end":{"character":13,"line":269},"start":{"character":0,"line":269}},"selectionRange":{"end":{"character":13,"line":269},"start":{"character":0,"line":269}}},{"detail":"ncclResult_t (const ncclComm_t, int *)","kind":12,"name":"ncclCommUserRank","range":{"end":{"character":14,"line":270},"start":{"character":0,"line":269}},"selectionRange":{"end":{"character":44,"line":269},"start":{"character":28,"line":269}}}],"detail":"(ncclResult_t, ncclCommUserRank, const ncclComm_t comm, int* rank)","kind":21,"name":"KWAI_NCCL_API","range":{"end":{"character":14,"line":270},"start":{"character":0,"line":269}},"selectionRange":{"end":{"character":13,"line":269},"start":{"character":0,"line":269}}}]}

I[13:46:33.623] --> textDocument/clangd.fileStatus
V[13:46:33.623] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/code/multi/nccl/src/profile.cc"}}

V[13:46:33.745] Build dynamic index for header symbols with estimated memory usage of 16737718 bytes
V[13:46:33.751] indexed preamble AST for /root/code/multi/nccl/src/graph/paths.cc version 3:
  symbol slab: 17980 symbols, 6689774 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 365 relations, 8728 bytes
V[13:46:33.804] Dropped diagnostic: /root/code/multi/nccl/src/init.cc: in included file: definition of builtin function '_mm_pause'
I[13:46:33.810] Built preamble of size 11223160 for file /root/code/multi/nccl/src/init.cc version 1 in 2.07 seconds
I[13:46:33.810] --> workspace/semanticTokens/refresh(7)
V[13:46:33.810] >>> {"id":7,"jsonrpc":"2.0","method":"workspace/semanticTokens/refresh","params":null}

V[13:46:33.820] indexed preamble AST for /root/code/multi/nccl/src/collectives.cc version 1:
  symbol slab: 17912 symbols, 6673998 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 365 relations, 8728 bytes
V[13:46:33.828] <<< {"id":7,"jsonrpc":"2.0","result":null}

I[13:46:33.830] <-- reply(7)
V[13:46:33.907] <<< {"id":8,"jsonrpc":"2.0","method":"textDocument/semanticTokens/full/delta","params":{"previousResultId":"1","textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

I[13:46:33.907] <-- textDocument/semanticTokens/full/delta(8)
V[13:46:33.908] <<< {"id":9,"jsonrpc":"2.0","method":"textDocument/codeAction","params":{"context":{"diagnostics":[],"triggerKind":2},"range":{"end":{"character":17,"line":4},"start":{"character":17,"line":4}},"textDocument":{"uri":"file:///root/code/multi/nccl/src/profile.cc"}}}

V[13:46:33.908] ASTWorker running SemanticHighlights on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.908] <-- textDocument/codeAction(9)
I[13:46:33.911] --> reply:textDocument/semanticTokens/full/delta(8) 3 ms
V[13:46:33.911] >>> {"id":8,"jsonrpc":"2.0","result":{"edits":[],"resultId":"2"}}

V[13:46:33.911] ASTWorker running codeAction on version 1 of /root/code/multi/nccl/src/profile.cc
I[13:46:33.911] --> reply:textDocument/codeAction(9) 3 ms
V[13:46:33.911] >>> {"id":9,"jsonrpc":"2.0","result":[]}

I[13:46:33.911] --> textDocument/clangd.fileStatus
V[13:46:33.911] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/code/multi/nccl/src/profile.cc"}}

V[13:46:33.943] Build dynamic index for header symbols with estimated memory usage of 18397240 bytes
V[13:46:33.999] Build dynamic index for header symbols with estimated memory usage of 18441379 bytes
V[13:46:34.123] indexed preamble AST for /root/code/multi/nccl/src/profile.cc version 1:
  symbol slab: 19939 symbols, 7155107 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 332 relations, 8728 bytes
V[13:46:34.325] indexed file AST for /root/code/multi/nccl/src/init.cc version 1:
  symbol slab: 133 symbols, 39168 bytes
  ref slab: 717 symbols, 4911 refs, 192408 bytes
  relations slab: 0 relations, 24 bytes
V[13:46:34.328] Build dynamic index for main-file symbols with estimated memory usage of 845424 bytes
I[13:46:34.328] --> textDocument/publishDiagnostics
V[13:46:34.328] >>> {"jsonrpc":"2.0","method":"textDocument/publishDiagnostics","params":{"diagnostics":[{"code":"builtin_definition","message":"In included file: definition of builtin function '_mm_getcsr'","range":{"end":{"character":20,"line":9},"start":{"character":9,"line":9}},"relatedInformation":[{"location":{"range":{"end":{"character":10,"line":820},"start":{"character":0,"line":820}},"uri":"file:///usr/lib/gcc/x86_64-linux-gnu/9/include/xmmintrin.h"},"message":"Error occurred here"}],"severity":1,"source":"clang"},{"code":"unused-includes","codeDescription":{"href":"https://clangd.llvm.org/guides/include-cleaner"},"message":"Included header errno.h is not used directly (fix available)","range":{"end":{"character":18,"line":21},"start":{"character":0,"line":21}},"relatedInformation":[],"severity":2,"source":"clangd","tags":[1]}],"uri":"file:///root/code/multi/nccl/src/init.cc","version":1}}

I[13:46:34.328] --> textDocument/inactiveRegions
V[13:46:34.328] >>> {"jsonrpc":"2.0","method":"textDocument/inactiveRegions","params":{"regions":[{"end":{"character":90,"line":37},"start":{"character":0,"line":37}},{"end":{"character":56,"line":115},"start":{"character":0,"line":115}},{"end":{"character":1,"line":891},"start":{"character":0,"line":889}}],"textDocument":{"uri":"file:///root/code/multi/nccl/src/init.cc"}}}

I[13:46:34.352] --> textDocument/clangd.fileStatus
V[13:46:34.352] >>> {"jsonrpc":"2.0","method":"textDocument/clangd.fileStatus","params":{"state":"idle","uri":"file:///root/code/multi/nccl/src/init.cc"}}

V[13:46:34.369] Build dynamic index for header symbols with estimated memory usage of 20969145 bytes
V[13:46:34.567] indexed preamble AST for /root/code/multi/nccl/src/init.cc version 1:
  symbol slab: 24743 symbols, 8579265 bytes
  ref slab: 0 symbols, 0 refs, 128 bytes
  relations slab: 365 relations, 8728 bytes
V[13:46:34.801] Build dynamic index for header symbols with estimated memory usage of 21062687 bytes
V[13:46:35.415] Ignored diagnostic. /usr/lib/gcc/x86_64-linux-gnu/9/include/stdatomic.h:40:17:unknown type name '_Bool'
V[13:46:35.425] Ignored diagnostic. /usr/lib/gcc/x86_64-linux-gnu/9/include/stdatomic.h:221:3:unknown type name '_Bool'
V[13:46:35.437] Ignored diagnostic. /usr/lib/gcc/x86_64-linux-gnu/9/include/stdatomic.h:230:8:unknown type name '_Bool'
V[13:46:35.447] Ignored diagnostic. /usr/lib/gcc/x86_64-linux-gnu/9/include/stdatomic.h:233:8:unknown type name '_Bool'
V[13:46:36.179] Ignored diagnostic. /usr/include/c++/9/pstl/parallel_backend_tbb.h:19:10:'tbb/blocked_range.h' file not found
I[13:46:36.555] Indexed c++17 standard library (incomplete due to errors): 13705 symbols, 991 filtered
V[13:46:36.761] Build dynamic index for header symbols with estimated memory usage of 23718395 bytes
```
